# Comparing `tmp/apache-airflow-providers-google-8.9.0rc1.tar.gz` & `tmp/apache-airflow-providers-google-9.0.0rc1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/apache-airflow-providers-google-8.9.0rc1.tar", last modified: Wed Feb  8 08:28:17 2023, max compression
+gzip compressed data, was "dist/apache-airflow-providers-google-9.0.0rc1.tar", last modified: Sun Apr  9 13:49:09 2023, max compression
```

## Comparing `apache-airflow-providers-google-8.9.0rc1.tar` & `apache-airflow-providers-google-9.0.0rc1.tar`

### file list

```diff
@@ -1,345 +1,1874 @@
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/
--rw-r--r--   0 root         (0) root         (0)    10850 2022-10-05 12:15:16.000000 apache-airflow-providers-google-8.9.0rc1/LICENSE
--rw-r--r--   0 root         (0) root         (0)     1240 2023-02-08 08:28:08.000000 apache-airflow-providers-google-8.9.0rc1/MANIFEST.in
--rw-r--r--   0 root         (0) root         (0)      240 2022-10-05 12:15:16.000000 apache-airflow-providers-google-8.9.0rc1/NOTICE
--rw-r--r--   0 root         (0) root         (0)    70442 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)    68456 2023-02-08 08:28:08.000000 apache-airflow-providers-google-8.9.0rc1/README.rst
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/airflow/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/
--rw-r--r--   0 root         (0) root         (0)     1578 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/hooks/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/hooks/__init__.py
--rw-r--r--   0 root         (0) root         (0)    11312 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/hooks/ads.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/operators/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/operators/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4743 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/operators/ads.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/transfers/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/transfers/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5228 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/transfers/ads_to_gcs.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/_internal_client/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/_internal_client/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3730 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/_internal_client/secret_manager_client.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3574 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_nl_text_classification.py
--rw-r--r--   0 root         (0) root         (0)     3666 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_nl_text_sentiment.py
--rw-r--r--   0 root         (0) root         (0)     3726 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_translation.py
--rw-r--r--   0 root         (0) root         (0)     3666 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_video_intelligence_classification.py
--rw-r--r--   0 root         (0) root         (0)     3719 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_video_intelligence_tracking.py
--rw-r--r--   0 root         (0) root         (0)     3693 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_vision_object_detection.py
--rw-r--r--   0 root         (0) root         (0)    10890 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py
--rw-r--r--   0 root         (0) root         (0)     7927 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_storage_transfer_service_aws.py
--rw-r--r--   0 root         (0) root         (0)     1896 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_task.py
--rw-r--r--   0 root         (0) root         (0)     4274 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_compute.py
--rw-r--r--   0 root         (0) root         (0)     3165 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_compute_ssh.py
--rw-r--r--   0 root         (0) root         (0)    10681 2023-02-02 18:37:35.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow.py
--rw-r--r--   0 root         (0) root         (0)     2801 2023-02-02 18:37:35.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow_flex_template.py
--rw-r--r--   0 root         (0) root         (0)     2586 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow_sql.py
--rw-r--r--   0 root         (0) root         (0)     4823 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_facebook_ads_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     2320 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_looker.py
--rw-r--r--   0 root         (0) root         (0)     1785 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_postgres_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     7363 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_presto_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     4891 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_salesforce_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)    28718 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_vertex_ai.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/__init__.py
--rw-r--r--   0 root         (0) root         (0)    27055 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/automl.py
--rw-r--r--   0 root         (0) root         (0)   136373 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/bigquery.py
--rw-r--r--   0 root         (0) root         (0)    14391 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/bigquery_dts.py
--rw-r--r--   0 root         (0) root         (0)    12410 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/bigtable.py
--rw-r--r--   0 root         (0) root         (0)    25856 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_build.py
--rw-r--r--   0 root         (0) root         (0)    17570 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_composer.py
--rw-r--r--   0 root         (0) root         (0)    40873 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_memorystore.py
--rw-r--r--   0 root         (0) root         (0)    42574 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_sql.py
--rw-r--r--   0 root         (0) root         (0)    19106 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_storage_transfer_service.py
--rw-r--r--   0 root         (0) root         (0)    39903 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/compute.py
--rw-r--r--   0 root         (0) root         (0)    12939 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/compute_ssh.py
--rw-r--r--   0 root         (0) root         (0)    54442 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/datacatalog.py
--rw-r--r--   0 root         (0) root         (0)    49406 2023-02-02 18:37:35.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataflow.py
--rw-r--r--   0 root         (0) root         (0)    24996 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataform.py
--rw-r--r--   0 root         (0) root         (0)    22363 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/datafusion.py
--rw-r--r--   0 root         (0) root         (0)    15517 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataplex.py
--rw-r--r--   0 root         (0) root         (0)     8214 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataprep.py
--rw-r--r--   0 root         (0) root         (0)    76786 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataproc.py
--rw-r--r--   0 root         (0) root         (0)    29423 2023-01-11 12:48:25.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataproc_metastore.py
--rw-r--r--   0 root         (0) root         (0)    12124 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/datastore.py
--rw-r--r--   0 root         (0) root         (0)    64796 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dlp.py
--rw-r--r--   0 root         (0) root         (0)     9389 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/functions.py
--rw-r--r--   0 root         (0) root         (0)    49610 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/gcs.py
--rw-r--r--   0 root         (0) root         (0)     4061 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/gdm.py
--rw-r--r--   0 root         (0) root         (0)     6717 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/kms.py
--rw-r--r--   0 root         (0) root         (0)    11423 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/kubernetes_engine.py
--rw-r--r--   0 root         (0) root         (0)     6245 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/life_sciences.py
--rw-r--r--   0 root         (0) root         (0)     8902 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/looker.py
--rw-r--r--   0 root         (0) root         (0)    24449 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/mlengine.py
--rw-r--r--   0 root         (0) root         (0)    11233 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/natural_language.py
--rw-r--r--   0 root         (0) root         (0)     3986 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/os_login.py
--rw-r--r--   0 root         (0) root         (0)    26808 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/pubsub.py
--rw-r--r--   0 root         (0) root         (0)     3734 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/secret_manager.py
--rw-r--r--   0 root         (0) root         (0)    15516 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/spanner.py
--rw-r--r--   0 root         (0) root         (0)     4487 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/speech_to_text.py
--rw-r--r--   0 root         (0) root         (0)    25828 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/stackdriver.py
--rw-r--r--   0 root         (0) root         (0)    26769 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/tasks.py
--rw-r--r--   0 root         (0) root         (0)     5346 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/text_to_speech.py
--rw-r--r--   0 root         (0) root         (0)     4373 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/translate.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/__init__.py
--rw-r--r--   0 root         (0) root         (0)    78059 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/auto_ml.py
--rw-r--r--   0 root         (0) root         (0)    18893 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/batch_prediction_job.py
--rw-r--r--   0 root         (0) root         (0)   109539 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/custom_job.py
--rw-r--r--   0 root         (0) root         (0)    18266 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/dataset.py
--rw-r--r--   0 root         (0) root         (0)    15811 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/endpoint_service.py
--rw-r--r--   0 root         (0) root         (0)    20790 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/hyperparameter_tuning_job.py
--rw-r--r--   0 root         (0) root         (0)     9235 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/model_service.py
--rw-r--r--   0 root         (0) root         (0)     5879 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/video_intelligence.py
--rw-r--r--   0 root         (0) root         (0)    24951 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vision.py
--rw-r--r--   0 root         (0) root         (0)    16183 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/workflows.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4775 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/automl.py
--rw-r--r--   0 root         (0) root         (0)     1614 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/base.py
--rw-r--r--   0 root         (0) root         (0)     2525 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/bigquery.py
--rw-r--r--   0 root         (0) root         (0)     1870 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/bigquery_dts.py
--rw-r--r--   0 root         (0) root         (0)     3069 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/bigtable.py
--rw-r--r--   0 root         (0) root         (0)     3606 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_build.py
--rw-r--r--   0 root         (0) root         (0)     2527 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_functions.py
--rw-r--r--   0 root         (0) root         (0)     3862 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_memorystore.py
--rw-r--r--   0 root         (0) root         (0)     2527 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_sql.py
--rw-r--r--   0 root         (0) root         (0)     3990 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_storage_transfer.py
--rw-r--r--   0 root         (0) root         (0)     2766 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_tasks.py
--rw-r--r--   0 root         (0) root         (0)     3657 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/compute.py
--rw-r--r--   0 root         (0) root         (0)     9280 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/data_loss_prevention.py
--rw-r--r--   0 root         (0) root         (0)     3632 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/datacatalog.py
--rw-r--r--   0 root         (0) root         (0)     1781 2023-02-02 18:37:35.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataflow.py
--rw-r--r--   0 root         (0) root         (0)     3926 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataform.py
--rw-r--r--   0 root         (0) root         (0)     3891 2023-01-24 18:52:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/datafusion.py
--rw-r--r--   0 root         (0) root         (0)     3226 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataplex.py
--rw-r--r--   0 root         (0) root         (0)     2233 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataprep.py
--rw-r--r--   0 root         (0) root         (0)     3740 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataproc.py
--rw-r--r--   0 root         (0) root         (0)     2372 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/datastore.py
--rw-r--r--   0 root         (0) root         (0)     2881 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/kubernetes_engine.py
--rw-r--r--   0 root         (0) root         (0)     1628 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/life_sciences.py
--rw-r--r--   0 root         (0) root         (0)     4217 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/mlengine.py
--rw-r--r--   0 root         (0) root         (0)     2416 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/pubsub.py
--rw-r--r--   0 root         (0) root         (0)     2503 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/spanner.py
--rw-r--r--   0 root         (0) root         (0)     2406 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/stackdriver.py
--rw-r--r--   0 root         (0) root         (0)     9684 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/vertex_ai.py
--rw-r--r--   0 root         (0) root         (0)     3294 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/workflows.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/log/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/log/__init__.py
--rw-r--r--   0 root         (0) root         (0)    10254 2023-02-05 09:48:53.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/log/gcs_task_handler.py
--rw-r--r--   0 root         (0) root         (0)    15285 2023-02-05 09:48:53.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/log/stackdriver_task_handler.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/__init__.py
--rw-r--r--   0 root         (0) root         (0)    50423 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/automl.py
--rw-r--r--   0 root         (0) root         (0)   117648 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/bigquery.py
--rw-r--r--   0 root         (0) root         (0)    17103 2023-01-24 18:52:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/bigquery_dts.py
--rw-r--r--   0 root         (0) root         (0)    26677 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/bigtable.py
--rw-r--r--   0 root         (0) root         (0)    46643 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_build.py
--rw-r--r--   0 root         (0) root         (0)    29674 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_composer.py
--rw-r--r--   0 root         (0) root         (0)    70593 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_memorystore.py
--rw-r--r--   0 root         (0) root         (0)    45246 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_sql.py
--rw-r--r--   0 root         (0) root         (0)    45233 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_storage_transfer_service.py
--rw-r--r--   0 root         (0) root         (0)    74295 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/compute.py
--rw-r--r--   0 root         (0) root         (0)    92453 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/datacatalog.py
--rw-r--r--   0 root         (0) root         (0)    61714 2023-02-02 18:37:35.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataflow.py
--rw-r--r--   0 root         (0) root         (0)    51175 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataform.py
--rw-r--r--   0 root         (0) root         (0)    45215 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/datafusion.py
--rw-r--r--   0 root         (0) root         (0)    29272 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataplex.py
--rw-r--r--   0 root         (0) root         (0)    10242 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataprep.py
--rw-r--r--   0 root         (0) root         (0)   114746 2023-02-05 09:48:53.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataproc.py
--rw-r--r--   0 root         (0) root         (0)    49383 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataproc_metastore.py
--rw-r--r--   0 root         (0) root         (0)    28972 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/datastore.py
--rw-r--r--   0 root         (0) root         (0)   119898 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dlp.py
--rw-r--r--   0 root         (0) root         (0)    19966 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/functions.py
--rw-r--r--   0 root         (0) root         (0)    43410 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/gcs.py
--rw-r--r--   0 root         (0) root         (0)    18082 2023-01-13 19:37:41.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/kubernetes_engine.py
--rw-r--r--   0 root         (0) root         (0)     4110 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/life_sciences.py
--rw-r--r--   0 root         (0) root         (0)     4004 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/looker.py
--rw-r--r--   0 root         (0) root         (0)    63267 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/mlengine.py
--rw-r--r--   0 root         (0) root         (0)    13646 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/natural_language.py
--rw-r--r--   0 root         (0) root         (0)    37069 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/pubsub.py
--rw-r--r--   0 root         (0) root         (0)    24831 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/spanner.py
--rw-r--r--   0 root         (0) root         (0)     5485 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/speech_to_text.py
--rw-r--r--   0 root         (0) root         (0)    44068 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/stackdriver.py
--rw-r--r--   0 root         (0) root         (0)    48085 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/tasks.py
--rw-r--r--   0 root         (0) root         (0)     6798 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/text_to_speech.py
--rw-r--r--   0 root         (0) root         (0)     4947 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/translate.py
--rw-r--r--   0 root         (0) root         (0)     7660 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/translate_speech.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/__init__.py
--rw-r--r--   0 root         (0) root         (0)    28245 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/auto_ml.py
--rw-r--r--   0 root         (0) root         (0)    27607 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/batch_prediction_job.py
--rw-r--r--   0 root         (0) root         (0)    80183 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/custom_job.py
--rw-r--r--   0 root         (0) root         (0)    26523 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/dataset.py
--rw-r--r--   0 root         (0) root         (0)    30405 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/endpoint_service.py
--rw-r--r--   0 root         (0) root         (0)    25299 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/hyperparameter_tuning_job.py
--rw-r--r--   0 root         (0) root         (0)    17019 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/model_service.py
--rw-r--r--   0 root         (0) root         (0)    14112 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/video_intelligence.py
--rw-r--r--   0 root         (0) root         (0)    66925 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vision.py
--rw-r--r--   0 root         (0) root         (0)    28528 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/workflows.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/secrets/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/secrets/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7770 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/secrets/secret_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/__init__.py
--rw-r--r--   0 root         (0) root         (0)    10663 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/bigquery.py
--rw-r--r--   0 root         (0) root         (0)     6303 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/bigquery_dts.py
--rw-r--r--   0 root         (0) root         (0)     5080 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/bigtable.py
--rw-r--r--   0 root         (0) root         (0)     4596 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/cloud_composer.py
--rw-r--r--   0 root         (0) root         (0)     4774 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/cloud_storage_transfer_service.py
--rw-r--r--   0 root         (0) root         (0)    16546 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataflow.py
--rw-r--r--   0 root         (0) root         (0)     5350 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataform.py
--rw-r--r--   0 root         (0) root         (0)     5905 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/datafusion.py
--rw-r--r--   0 root         (0) root         (0)     5092 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataplex.py
--rw-r--r--   0 root         (0) root         (0)     1912 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataprep.py
--rw-r--r--   0 root         (0) root         (0)     7188 2023-01-24 18:52:14.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataproc.py
--rw-r--r--   0 root         (0) root         (0)    19999 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/gcs.py
--rw-r--r--   0 root         (0) root         (0)     3579 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/looker.py
--rw-r--r--   0 root         (0) root         (0)     7100 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/pubsub.py
--rw-r--r--   0 root         (0) root         (0)     3410 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/tasks.py
--rw-r--r--   0 root         (0) root         (0)     5009 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/workflows.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7119 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/adls_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     7754 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/azure_fileshare_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     6812 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_bigquery.py
--rw-r--r--   0 root         (0) root         (0)    11841 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     6452 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_mssql.py
--rw-r--r--   0 root         (0) root         (0)     5863 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_mysql.py
--rw-r--r--   0 root         (0) root         (0)     8932 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/calendar_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)    16404 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/cassandra_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)    10435 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/facebook_ads_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)    33823 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py
--rw-r--r--   0 root         (0) root         (0)    21593 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gcs_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     6250 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gcs_to_local.py
--rw-r--r--   0 root         (0) root         (0)     8630 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gcs_to_sftp.py
--rw-r--r--   0 root         (0) root         (0)     4720 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gdrive_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     4163 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gdrive_to_local.py
--rw-r--r--   0 root         (0) root         (0)     5062 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/local_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     3344 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/mssql_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     5266 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/mysql_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     4921 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/oracle_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     5692 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/postgres_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     7204 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/presto_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     9103 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/s3_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     4793 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/salesforce_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     7547 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/sftp_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     5888 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/sheets_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)    20842 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/sql_to_gcs.py
--rw-r--r--   0 root         (0) root         (0)     7163 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/trino_to_gcs.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/__init__.py
--rw-r--r--   0 root         (0) root         (0)    22682 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/bigquery.py
--rw-r--r--   0 root         (0) root         (0)     6835 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/bigquery_dts.py
--rw-r--r--   0 root         (0) root         (0)     5893 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/cloud_build.py
--rw-r--r--   0 root         (0) root         (0)     3382 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/cloud_composer.py
--rw-r--r--   0 root         (0) root         (0)     6520 2023-02-02 18:37:35.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/dataflow.py
--rw-r--r--   0 root         (0) root         (0)     6190 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/datafusion.py
--rw-r--r--   0 root         (0) root         (0)    13046 2023-02-05 09:48:53.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/dataproc.py
--rw-r--r--   0 root         (0) root         (0)     3912 2023-01-11 16:59:28.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/gcs.py
--rw-r--r--   0 root         (0) root         (0)     5258 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/mlengine.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/
--rw-r--r--   0 root         (0) root         (0)      787 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1492 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/bigquery.py
--rw-r--r--   0 root         (0) root         (0)     1808 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/bigquery_get_data.py
--rw-r--r--   0 root         (0) root         (0)    15853 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/credentials_provider.py
--rw-r--r--   0 root         (0) root         (0)     7028 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/dataform.py
--rw-r--r--   0 root         (0) root         (0)     6086 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/field_sanitizer.py
--rw-r--r--   0 root         (0) root         (0)    22272 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/field_validator.py
--rw-r--r--   0 root         (0) root         (0)     1116 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/helpers.py
--rw-r--r--   0 root         (0) root         (0)    11222 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/mlengine_operator_utils.py
--rw-r--r--   0 root         (0) root         (0)     7672 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/mlengine_prediction_summary.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/auth_backend/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/auth_backend/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4517 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/auth_backend/google_openid.py
--rw-r--r--   0 root         (0) root         (0)     1050 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/consts.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/hooks/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/hooks/__init__.py
--rw-r--r--   0 root         (0) root         (0)    26380 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/hooks/base_google.py
--rw-r--r--   0 root         (0) root         (0)     6967 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/hooks/discovery_api.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/links/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/links/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2258 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/links/storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/utils/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7902 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/utils/id_token_credentials.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/config_templates/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/config_templates/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/hooks/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/hooks/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6121 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/hooks/firestore.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/operators/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/operators/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3818 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/operators/firestore.py
--rw-r--r--   0 root         (0) root         (0)    70584 2023-02-08 08:28:08.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/get_provider_info.py
--rw-r--r--   0 root         (0) root         (0)     1794 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/go_module_utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/hooks/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/hooks/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5752 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/hooks/leveldb.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/operators/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/operators/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3791 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/operators/leveldb.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/example_dags/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/example_dags/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8618 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/example_dags/example_display_video.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7791 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/analytics.py
--rw-r--r--   0 root         (0) root         (0)    11587 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/campaign_manager.py
--rw-r--r--   0 root         (0) root         (0)     7350 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/display_video.py
--rw-r--r--   0 root         (0) root         (0)     3085 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/search_ads.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:16.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/__init__.py
--rw-r--r--   0 root         (0) root         (0)    21219 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/analytics.py
--rw-r--r--   0 root         (0) root         (0)    24934 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/campaign_manager.py
--rw-r--r--   0 root         (0) root         (0)    27706 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/display_video.py
--rw-r--r--   0 root         (0) root         (0)     9293 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/search_ads.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/sensors/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/sensors/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4162 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/sensors/campaign_manager.py
--rw-r--r--   0 root         (0) root         (0)     6454 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/sensors/display_video.py
--rw-r--r--   0 root         (0) root         (0)     3795 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/sensors/search_ads.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/
--rw-r--r--   0 root         (0) root         (0)      787 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/
--rw-r--r--   0 root         (0) root         (0)      787 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/__init__.py
--rw-r--r--   0 root         (0) root         (0)     9303 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/calendar.py
--rw-r--r--   0 root         (0) root         (0)    10043 2023-01-26 14:58:03.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/drive.py
--rw-r--r--   0 root         (0) root         (0)    16744 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/sheets.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/operators/
--rw-r--r--   0 root         (0) root         (0)      787 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/operators/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3394 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/operators/sheets.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/sensors/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/sensors/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3616 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/sensors/drive.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/
--rw-r--r--   0 root         (0) root         (0)      785 2022-10-05 12:15:15.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7255 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/gcs_to_gdrive.py
--rw-r--r--   0 root         (0) root         (0)     4356 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/gcs_to_sheets.py
--rw-r--r--   0 root         (0) root         (0)     5521 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/local_to_drive.py
--rw-r--r--   0 root         (0) root         (0)     5210 2023-01-11 12:48:26.000000 apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/sql_to_sheets.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/
--rw-r--r--   0 root         (0) root         (0)    70442 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)    16511 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0) root         (0)        1 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0) root         (0)      104 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/entry_points.txt
--rw-r--r--   0 root         (0) root         (0)        1 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/not-zip-safe
--rw-r--r--   0 root         (0) root         (0)     2414 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/requires.txt
--rw-r--r--   0 root         (0) root         (0)        8 2023-02-08 08:28:13.000000 apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/top_level.txt
--rw-r--r--   0 root         (0) root         (0)     3814 2023-01-13 19:37:41.000000 apache-airflow-providers-google-8.9.0rc1/pyproject.toml
--rw-r--r--   0 root         (0) root         (0)     3446 2023-02-08 08:28:17.000000 apache-airflow-providers-google-8.9.0rc1/setup.cfg
--rw-r--r--   0 root         (0) root         (0)     2587 2023-02-08 08:28:07.000000 apache-airflow-providers-google-8.9.0rc1/setup.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:09.000000 apache-airflow-providers-google-9.0.0rc1/
+-rw-r--r--   0 root         (0) root         (0)    10850 2023-02-24 18:43:54.000000 apache-airflow-providers-google-9.0.0rc1/LICENSE
+-rw-r--r--   0 root         (0) root         (0)     1104 2023-04-09 13:48:30.000000 apache-airflow-providers-google-9.0.0rc1/MANIFEST.in
+-rw-r--r--   0 root         (0) root         (0)      240 2023-02-24 18:43:54.000000 apache-airflow-providers-google-9.0.0rc1/NOTICE
+-rw-r--r--   0 root         (0) root         (0)    75675 2023-04-09 13:49:09.000000 apache-airflow-providers-google-9.0.0rc1/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    73709 2023-04-09 13:48:30.000000 apache-airflow-providers-google-9.0.0rc1/README.rst
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:52.000000 apache-airflow-providers-google-9.0.0rc1/airflow/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/
+-rw-r--r--   0 root         (0) root         (0)     1578 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/hooks/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/hooks/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    11322 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/hooks/ads.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/operators/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/operators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4743 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/operators/ads.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/transfers/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/transfers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5228 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/transfers/ads_to_gcs.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/_internal_client/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/_internal_client/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3730 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/_internal_client/secret_manager_client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3574 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_nl_text_classification.py
+-rw-r--r--   0 root         (0) root         (0)     3666 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_nl_text_sentiment.py
+-rw-r--r--   0 root         (0) root         (0)     3726 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_translation.py
+-rw-r--r--   0 root         (0) root         (0)     3666 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_video_intelligence_classification.py
+-rw-r--r--   0 root         (0) root         (0)     3719 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_video_intelligence_tracking.py
+-rw-r--r--   0 root         (0) root         (0)     3693 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_vision_object_detection.py
+-rw-r--r--   0 root         (0) root         (0)    10862 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py
+-rw-r--r--   0 root         (0) root         (0)     7927 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_storage_transfer_service_aws.py
+-rw-r--r--   0 root         (0) root         (0)     1896 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_task.py
+-rw-r--r--   0 root         (0) root         (0)     4274 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_compute.py
+-rw-r--r--   0 root         (0) root         (0)     3165 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_compute_ssh.py
+-rw-r--r--   0 root         (0) root         (0)    10681 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow.py
+-rw-r--r--   0 root         (0) root         (0)     2801 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow_flex_template.py
+-rw-r--r--   0 root         (0) root         (0)     2586 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow_sql.py
+-rw-r--r--   0 root         (0) root         (0)     4823 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_facebook_ads_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     2320 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_looker.py
+-rw-r--r--   0 root         (0) root         (0)     1785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_postgres_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     7363 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_presto_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     4891 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_salesforce_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)    28718 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_vertex_ai.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    27055 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/automl.py
+-rw-r--r--   0 root         (0) root         (0)   138041 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/bigquery.py
+-rw-r--r--   0 root         (0) root         (0)    14799 2023-03-16 20:46:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/bigquery_dts.py
+-rw-r--r--   0 root         (0) root         (0)    12415 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/bigtable.py
+-rw-r--r--   0 root         (0) root         (0)    27760 2023-04-07 12:28:58.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_build.py
+-rw-r--r--   0 root         (0) root         (0)    17570 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_composer.py
+-rw-r--r--   0 root         (0) root         (0)    40873 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_memorystore.py
+-rw-r--r--   0 root         (0) root         (0)    44374 2023-03-05 08:19:18.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_sql.py
+-rw-r--r--   0 root         (0) root         (0)    19106 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_storage_transfer_service.py
+-rw-r--r--   0 root         (0) root         (0)    39903 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/compute.py
+-rw-r--r--   0 root         (0) root         (0)    12939 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/compute_ssh.py
+-rw-r--r--   0 root         (0) root         (0)    54442 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/datacatalog.py
+-rw-r--r--   0 root         (0) root         (0)    49406 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataflow.py
+-rw-r--r--   0 root         (0) root         (0)    24996 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataform.py
+-rw-r--r--   0 root         (0) root         (0)    22363 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/datafusion.py
+-rw-r--r--   0 root         (0) root         (0)    15517 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataplex.py
+-rw-r--r--   0 root         (0) root         (0)     8214 2023-02-27 20:04:59.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataprep.py
+-rw-r--r--   0 root         (0) root         (0)    79962 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataproc.py
+-rw-r--r--   0 root         (0) root         (0)    29423 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataproc_metastore.py
+-rw-r--r--   0 root         (0) root         (0)    12124 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/datastore.py
+-rw-r--r--   0 root         (0) root         (0)    67666 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dlp.py
+-rw-r--r--   0 root         (0) root         (0)     9403 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/functions.py
+-rw-r--r--   0 root         (0) root         (0)    49993 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/gcs.py
+-rw-r--r--   0 root         (0) root         (0)     4061 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/gdm.py
+-rw-r--r--   0 root         (0) root         (0)     6717 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/kms.py
+-rw-r--r--   0 root         (0) root         (0)    20145 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/kubernetes_engine.py
+-rw-r--r--   0 root         (0) root         (0)     6259 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/life_sciences.py
+-rw-r--r--   0 root         (0) root         (0)     8902 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/looker.py
+-rw-r--r--   0 root         (0) root         (0)    24449 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/mlengine.py
+-rw-r--r--   0 root         (0) root         (0)    11233 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/natural_language.py
+-rw-r--r--   0 root         (0) root         (0)     3986 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/os_login.py
+-rw-r--r--   0 root         (0) root         (0)    26808 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/pubsub.py
+-rw-r--r--   0 root         (0) root         (0)     3734 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/secret_manager.py
+-rw-r--r--   0 root         (0) root         (0)    15516 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/spanner.py
+-rw-r--r--   0 root         (0) root         (0)     4487 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/speech_to_text.py
+-rw-r--r--   0 root         (0) root         (0)    25828 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/stackdriver.py
+-rw-r--r--   0 root         (0) root         (0)    26769 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/tasks.py
+-rw-r--r--   0 root         (0) root         (0)     5346 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/text_to_speech.py
+-rw-r--r--   0 root         (0) root         (0)     4373 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/translate.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:54.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    78059 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/auto_ml.py
+-rw-r--r--   0 root         (0) root         (0)    18893 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/batch_prediction_job.py
+-rw-r--r--   0 root         (0) root         (0)   109539 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/custom_job.py
+-rw-r--r--   0 root         (0) root         (0)    18266 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/dataset.py
+-rw-r--r--   0 root         (0) root         (0)    15811 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/endpoint_service.py
+-rw-r--r--   0 root         (0) root         (0)    20790 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/hyperparameter_tuning_job.py
+-rw-r--r--   0 root         (0) root         (0)     9235 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/model_service.py
+-rw-r--r--   0 root         (0) root         (0)     5879 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/video_intelligence.py
+-rw-r--r--   0 root         (0) root         (0)    24951 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vision.py
+-rw-r--r--   0 root         (0) root         (0)    16183 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/workflows.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:55.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4775 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/automl.py
+-rw-r--r--   0 root         (0) root         (0)     1614 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/base.py
+-rw-r--r--   0 root         (0) root         (0)     2525 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/bigquery.py
+-rw-r--r--   0 root         (0) root         (0)     1870 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/bigquery_dts.py
+-rw-r--r--   0 root         (0) root         (0)     3069 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/bigtable.py
+-rw-r--r--   0 root         (0) root         (0)     3898 2023-03-10 19:32:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_build.py
+-rw-r--r--   0 root         (0) root         (0)     2527 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_functions.py
+-rw-r--r--   0 root         (0) root         (0)     3862 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_memorystore.py
+-rw-r--r--   0 root         (0) root         (0)     2527 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_sql.py
+-rw-r--r--   0 root         (0) root         (0)     3990 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_storage_transfer.py
+-rw-r--r--   0 root         (0) root         (0)     2766 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_tasks.py
+-rw-r--r--   0 root         (0) root         (0)     3657 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/compute.py
+-rw-r--r--   0 root         (0) root         (0)     9280 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/data_loss_prevention.py
+-rw-r--r--   0 root         (0) root         (0)     3632 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/datacatalog.py
+-rw-r--r--   0 root         (0) root         (0)     1781 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataflow.py
+-rw-r--r--   0 root         (0) root         (0)     3926 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataform.py
+-rw-r--r--   0 root         (0) root         (0)     3891 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/datafusion.py
+-rw-r--r--   0 root         (0) root         (0)     3226 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataplex.py
+-rw-r--r--   0 root         (0) root         (0)     2233 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataprep.py
+-rw-r--r--   0 root         (0) root         (0)     3740 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataproc.py
+-rw-r--r--   0 root         (0) root         (0)     2372 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/datastore.py
+-rw-r--r--   0 root         (0) root         (0)     2881 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/kubernetes_engine.py
+-rw-r--r--   0 root         (0) root         (0)     1628 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/life_sciences.py
+-rw-r--r--   0 root         (0) root         (0)     4217 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/mlengine.py
+-rw-r--r--   0 root         (0) root         (0)     2416 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/pubsub.py
+-rw-r--r--   0 root         (0) root         (0)     2503 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/spanner.py
+-rw-r--r--   0 root         (0) root         (0)     2406 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/stackdriver.py
+-rw-r--r--   0 root         (0) root         (0)     9684 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/vertex_ai.py
+-rw-r--r--   0 root         (0) root         (0)     3294 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/workflows.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:55.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/log/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/log/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    11276 2023-03-10 19:31:58.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/log/gcs_task_handler.py
+-rw-r--r--   0 root         (0) root         (0)    15285 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/log/stackdriver_task_handler.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:55.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    50614 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/automl.py
+-rw-r--r--   0 root         (0) root         (0)   121152 2023-03-16 20:46:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/bigquery.py
+-rw-r--r--   0 root         (0) root         (0)    17535 2023-03-16 20:46:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/bigquery_dts.py
+-rw-r--r--   0 root         (0) root         (0)    26782 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/bigtable.py
+-rw-r--r--   0 root         (0) root         (0)     1546 2023-03-06 20:52:28.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_base.py
+-rw-r--r--   0 root         (0) root         (0)    48926 2023-03-10 19:32:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_build.py
+-rw-r--r--   0 root         (0) root         (0)    29788 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_composer.py
+-rw-r--r--   0 root         (0) root         (0)    70839 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_memorystore.py
+-rw-r--r--   0 root         (0) root         (0)    49440 2023-03-05 08:19:18.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_sql.py
+-rw-r--r--   0 root         (0) root         (0)    45391 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_storage_transfer_service.py
+-rw-r--r--   0 root         (0) root         (0)    74354 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/compute.py
+-rw-r--r--   0 root         (0) root         (0)    92732 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/datacatalog.py
+-rw-r--r--   0 root         (0) root         (0)    61828 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataflow.py
+-rw-r--r--   0 root         (0) root         (0)    51377 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataform.py
+-rw-r--r--   0 root         (0) root         (0)    45373 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/datafusion.py
+-rw-r--r--   0 root         (0) root         (0)    29386 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataplex.py
+-rw-r--r--   0 root         (0) root         (0)    10356 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataprep.py
+-rw-r--r--   0 root         (0) root         (0)   117798 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataproc.py
+-rw-r--r--   0 root         (0) root         (0)    49581 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataproc_metastore.py
+-rw-r--r--   0 root         (0) root         (0)    29119 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/datastore.py
+-rw-r--r--   0 root         (0) root         (0)   120580 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dlp.py
+-rw-r--r--   0 root         (0) root         (0)    20047 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/functions.py
+-rw-r--r--   0 root         (0) root         (0)    43557 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/gcs.py
+-rw-r--r--   0 root         (0) root         (0)    22594 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/kubernetes_engine.py
+-rw-r--r--   0 root         (0) root         (0)     4169 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/life_sciences.py
+-rw-r--r--   0 root         (0) root         (0)     4063 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/looker.py
+-rw-r--r--   0 root         (0) root         (0)    63447 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/mlengine.py
+-rw-r--r--   0 root         (0) root         (0)    13738 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/natural_language.py
+-rw-r--r--   0 root         (0) root         (0)    37183 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/pubsub.py
+-rw-r--r--   0 root         (0) root         (0)    24945 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/spanner.py
+-rw-r--r--   0 root         (0) root         (0)     5544 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/speech_to_text.py
+-rw-r--r--   0 root         (0) root         (0)    44226 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/stackdriver.py
+-rw-r--r--   0 root         (0) root         (0)    48276 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/tasks.py
+-rw-r--r--   0 root         (0) root         (0)     6857 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/text_to_speech.py
+-rw-r--r--   0 root         (0) root         (0)     5006 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/translate.py
+-rw-r--r--   0 root         (0) root         (0)     7719 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/translate_speech.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:55.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    28326 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/auto_ml.py
+-rw-r--r--   0 root         (0) root         (0)    27699 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/batch_prediction_job.py
+-rw-r--r--   0 root         (0) root         (0)    80264 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/custom_job.py
+-rw-r--r--   0 root         (0) root         (0)    26648 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/dataset.py
+-rw-r--r--   0 root         (0) root         (0)    30530 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/endpoint_service.py
+-rw-r--r--   0 root         (0) root         (0)    25391 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/hyperparameter_tuning_job.py
+-rw-r--r--   0 root         (0) root         (0)    17111 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/model_service.py
+-rw-r--r--   0 root         (0) root         (0)    14193 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/video_intelligence.py
+-rw-r--r--   0 root         (0) root         (0)    67160 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vision.py
+-rw-r--r--   0 root         (0) root         (0)    28675 2023-02-25 13:25:11.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/workflows.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:55.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/secrets/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/secrets/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7770 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/secrets/secret_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:55.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    15279 2023-03-30 19:12:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/bigquery.py
+-rw-r--r--   0 root         (0) root         (0)     6303 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/bigquery_dts.py
+-rw-r--r--   0 root         (0) root         (0)     5058 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/bigtable.py
+-rw-r--r--   0 root         (0) root         (0)     4596 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/cloud_composer.py
+-rw-r--r--   0 root         (0) root         (0)     4793 2023-03-15 08:58:48.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/cloud_storage_transfer_service.py
+-rw-r--r--   0 root         (0) root         (0)    16546 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataflow.py
+-rw-r--r--   0 root         (0) root         (0)     5350 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataform.py
+-rw-r--r--   0 root         (0) root         (0)     5905 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/datafusion.py
+-rw-r--r--   0 root         (0) root         (0)     5092 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataplex.py
+-rw-r--r--   0 root         (0) root         (0)     1912 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataprep.py
+-rw-r--r--   0 root         (0) root         (0)     7188 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataproc.py
+-rw-r--r--   0 root         (0) root         (0)    20777 2023-03-27 08:32:49.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/gcs.py
+-rw-r--r--   0 root         (0) root         (0)     3579 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/looker.py
+-rw-r--r--   0 root         (0) root         (0)     7100 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/pubsub.py
+-rw-r--r--   0 root         (0) root         (0)     3410 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/tasks.py
+-rw-r--r--   0 root         (0) root         (0)     5009 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/workflows.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7119 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/adls_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     7754 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/azure_fileshare_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     6970 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_bigquery.py
+-rw-r--r--   0 root         (0) root         (0)    12060 2023-03-27 08:32:49.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     6607 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_mssql.py
+-rw-r--r--   0 root         (0) root         (0)     6117 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_mysql.py
+-rw-r--r--   0 root         (0) root         (0)     8932 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/calendar_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)    16404 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/cassandra_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)    10435 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/facebook_ads_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)    33969 2023-03-27 08:32:49.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py
+-rw-r--r--   0 root         (0) root         (0)    21622 2023-04-07 12:28:58.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gcs_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     6250 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gcs_to_local.py
+-rw-r--r--   0 root         (0) root         (0)     8630 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gcs_to_sftp.py
+-rw-r--r--   0 root         (0) root         (0)     4720 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gdrive_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     4163 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gdrive_to_local.py
+-rw-r--r--   0 root         (0) root         (0)     5062 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/local_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     3919 2023-03-06 20:52:28.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/mssql_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     5266 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/mysql_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     4921 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/oracle_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     5692 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/postgres_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     7204 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/presto_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     9103 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/s3_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     4793 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/salesforce_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     7547 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/sftp_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     5888 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/sheets_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)    20842 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/sql_to_gcs.py
+-rw-r--r--   0 root         (0) root         (0)     7163 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/trino_to_gcs.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    25935 2023-03-01 07:06:45.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/bigquery.py
+-rw-r--r--   0 root         (0) root         (0)     6879 2023-03-16 20:46:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/bigquery_dts.py
+-rw-r--r--   0 root         (0) root         (0)     6097 2023-03-10 19:32:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/cloud_build.py
+-rw-r--r--   0 root         (0) root         (0)     3382 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/cloud_composer.py
+-rw-r--r--   0 root         (0) root         (0)     6520 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/dataflow.py
+-rw-r--r--   0 root         (0) root         (0)     6190 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/datafusion.py
+-rw-r--r--   0 root         (0) root         (0)    15908 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/dataproc.py
+-rw-r--r--   0 root         (0) root         (0)     3912 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/gcs.py
+-rw-r--r--   0 root         (0) root         (0)     8498 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/kubernetes_engine.py
+-rw-r--r--   0 root         (0) root         (0)     5258 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/mlengine.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/
+-rw-r--r--   0 root         (0) root         (0)      787 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1492 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/bigquery.py
+-rw-r--r--   0 root         (0) root         (0)     1808 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/bigquery_get_data.py
+-rw-r--r--   0 root         (0) root         (0)    15853 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/credentials_provider.py
+-rw-r--r--   0 root         (0) root         (0)     7028 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/dataform.py
+-rw-r--r--   0 root         (0) root         (0)     6086 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/field_sanitizer.py
+-rw-r--r--   0 root         (0) root         (0)    22279 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/field_validator.py
+-rw-r--r--   0 root         (0) root         (0)     1116 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/helpers.py
+-rw-r--r--   0 root         (0) root         (0)    11222 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/mlengine_operator_utils.py
+-rw-r--r--   0 root         (0) root         (0)     7672 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/mlengine_prediction_summary.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/auth_backend/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/auth_backend/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4517 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/auth_backend/google_openid.py
+-rw-r--r--   0 root         (0) root         (0)     1050 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/consts.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/hooks/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/hooks/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26380 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/hooks/base_google.py
+-rw-r--r--   0 root         (0) root         (0)     6967 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/hooks/discovery_api.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/links/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/links/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2258 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/links/storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/utils/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8858 2023-03-05 08:19:18.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/utils/id_token_credentials.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/config_templates/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/config_templates/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/hooks/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/hooks/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6135 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/hooks/firestore.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/operators/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/operators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3818 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/operators/firestore.py
+-rw-r--r--   0 root         (0) root         (0)    73721 2023-04-09 13:48:30.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/get_provider_info.py
+-rw-r--r--   0 root         (0) root         (0)     1794 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/go_module_utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/hooks/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/hooks/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5752 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/hooks/leveldb.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/operators/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/operators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3791 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/operators/leveldb.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/example_dags/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/example_dags/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    11018 2023-04-09 10:16:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/example_dags/example_display_video.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7791 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/analytics.py
+-rw-r--r--   0 root         (0) root         (0)    11587 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/campaign_manager.py
+-rw-r--r--   0 root         (0) root         (0)     9013 2023-04-09 10:16:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/display_video.py
+-rw-r--r--   0 root         (0) root         (0)     3099 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/search_ads.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21219 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/analytics.py
+-rw-r--r--   0 root         (0) root         (0)    24934 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/campaign_manager.py
+-rw-r--r--   0 root         (0) root         (0)    39703 2023-04-09 10:16:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/display_video.py
+-rw-r--r--   0 root         (0) root         (0)     9293 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/search_ads.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4162 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/campaign_manager.py
+-rw-r--r--   0 root         (0) root         (0)     9436 2023-04-09 10:16:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/display_video.py
+-rw-r--r--   0 root         (0) root         (0)     3795 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/search_ads.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/
+-rw-r--r--   0 root         (0) root         (0)      787 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/
+-rw-r--r--   0 root         (0) root         (0)      787 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     9303 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/calendar.py
+-rw-r--r--   0 root         (0) root         (0)    12904 2023-03-06 20:52:28.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/drive.py
+-rw-r--r--   0 root         (0) root         (0)    16744 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/sheets.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/operators/
+-rw-r--r--   0 root         (0) root         (0)      787 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/operators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3394 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/operators/sheets.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/sensors/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/sensors/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3616 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/sensors/drive.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/
+-rw-r--r--   0 root         (0) root         (0)      785 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7255 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/gcs_to_gdrive.py
+-rw-r--r--   0 root         (0) root         (0)     4356 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/gcs_to_sheets.py
+-rw-r--r--   0 root         (0) root         (0)     6073 2023-03-06 20:52:28.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/local_to_drive.py
+-rw-r--r--   0 root         (0) root         (0)     5210 2023-02-24 18:43:53.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/sql_to_sheets.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:56.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:57.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/
+-rw-r--r--   0 root         (0) root         (0)      762 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    16299 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/client.py
+-rw-r--r--   0 root         (0) root         (0)    14993 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/config.py
+-rw-r--r--   0 root         (0) root         (0)     1305 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/errors.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:57.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/interceptors/
+-rw-r--r--   0 root         (0) root         (0)      809 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/interceptors/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5621 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/interceptors/exception_interceptor.py
+-rw-r--r--   0 root         (0) root         (0)     6562 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/interceptors/helpers.py
+-rw-r--r--   0 root         (0) root         (0)     9321 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/interceptors/interceptor.py
+-rw-r--r--   0 root         (0) root         (0)    14000 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/interceptors/logging_interceptor.py
+-rw-r--r--   0 root         (0) root         (0)     7307 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/interceptors/metadata_interceptor.py
+-rw-r--r--   0 root         (0) root         (0)     5706 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/interceptors/response_wrappers.py
+-rw-r--r--   0 root         (0) root         (0)     4698 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/oauth2.py
+-rw-r--r--   0 root         (0) root         (0)     6466 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/util.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:57.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/
+-rw-r--r--   0 root         (0) root         (0)   212210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:57.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/
+-rw-r--r--   0 root         (0) root         (0)     8052 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:57.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/services/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/services/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:57.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4063 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/ad_asset.py
+-rw-r--r--   0 root         (0) root         (0)    50618 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/ad_type_infos.py
+-rw-r--r--   0 root         (0) root         (0)     2270 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/asset_policy.py
+-rw-r--r--   0 root         (0) root         (0)    11435 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/asset_set_types.py
+-rw-r--r--   0 root         (0) root         (0)    63691 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/asset_types.py
+-rw-r--r--   0 root         (0) root         (0)     1551 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/asset_usage.py
+-rw-r--r--   0 root         (0) root         (0)    12243 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/audiences.py
+-rw-r--r--   0 root         (0) root         (0)    12476 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/bidding.py
+-rw-r--r--   0 root         (0) root         (0)     2158 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/click_location.py
+-rw-r--r--   0 root         (0) root         (0)    48964 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/criteria.py
+-rw-r--r--   0 root         (0) root         (0)     5857 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/criterion_category_availability.py
+-rw-r--r--   0 root         (0) root         (0)     1436 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/custom_parameter.py
+-rw-r--r--   0 root         (0) root         (0)     1861 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/customizer_value.py
+-rw-r--r--   0 root         (0) root         (0)     2554 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/dates.py
+-rw-r--r--   0 root         (0) root         (0)     1336 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/explorer_auto_optimizer_setting.py
+-rw-r--r--   0 root         (0) root         (0)    25186 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/extensions.py
+-rw-r--r--   0 root         (0) root         (0)     1423 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/feed_common.py
+-rw-r--r--   0 root         (0) root         (0)     2968 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/feed_item_set_filter_type_infos.py
+-rw-r--r--   0 root         (0) root         (0)     2101 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/final_app_url.py
+-rw-r--r--   0 root         (0) root         (0)     3397 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/frequency_cap.py
+-rw-r--r--   0 root         (0) root         (0)     9786 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/keyword_plan_common.py
+-rw-r--r--   0 root         (0) root         (0)     8798 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/matching_function.py
+-rw-r--r--   0 root         (0) root         (0)     1864 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/metric_goal.py
+-rw-r--r--   0 root         (0) root         (0)    66075 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/metrics.py
+-rw-r--r--   0 root         (0) root         (0)    22431 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/offline_user_data.py
+-rw-r--r--   0 root         (0) root         (0)    16560 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/policy.py
+-rw-r--r--   0 root         (0) root         (0)     2214 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/policy_summary.py
+-rw-r--r--   0 root         (0) root         (0)     1278 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/real_time_bidding_setting.py
+-rw-r--r--   0 root         (0) root         (0)    33648 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/segments.py
+-rw-r--r--   0 root         (0) root         (0)    24784 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/simulation.py
+-rw-r--r--   0 root         (0) root         (0)     2516 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/tag_snippet.py
+-rw-r--r--   0 root         (0) root         (0)     4113 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/targeting_setting.py
+-rw-r--r--   0 root         (0) root         (0)     1665 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/text_label.py
+-rw-r--r--   0 root         (0) root         (0)     1794 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/url_collection.py
+-rw-r--r--   0 root         (0) root         (0)    22148 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/user_lists.py
+-rw-r--r--   0 root         (0) root         (0)     2166 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/common/types/value.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:57.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/
+-rw-r--r--   0 root         (0) root         (0)    10647 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:48:57.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/services/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/services/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:00.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1214 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/access_invitation_status.py
+-rw-r--r--   0 root         (0) root         (0)     1228 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/access_reason.py
+-rw-r--r--   0 root         (0) root         (0)     1178 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/access_role.py
+-rw-r--r--   0 root         (0) root         (0)     1264 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/account_budget_proposal_status.py
+-rw-r--r--   0 root         (0) root         (0)     1215 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/account_budget_proposal_type.py
+-rw-r--r--   0 root         (0) root         (0)     1177 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/account_budget_status.py
+-rw-r--r--   0 root         (0) root         (0)     1338 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/account_link_status.py
+-rw-r--r--   0 root         (0) root         (0)     1229 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_customizer_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1398 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_destination_type.py
+-rw-r--r--   0 root         (0) root         (0)     1218 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_group_ad_rotation_mode.py
+-rw-r--r--   0 root         (0) root         (0)     1184 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_group_ad_status.py
+-rw-r--r--   0 root         (0) root         (0)     1285 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_group_criterion_approval_status.py
+-rw-r--r--   0 root         (0) root         (0)     1188 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_group_criterion_status.py
+-rw-r--r--   0 root         (0) root         (0)     1176 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_group_status.py
+-rw-r--r--   0 root         (0) root         (0)     1751 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_group_type.py
+-rw-r--r--   0 root         (0) root         (0)     1240 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_network_type.py
+-rw-r--r--   0 root         (0) root         (0)     1267 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_serving_optimization_status.py
+-rw-r--r--   0 root         (0) root         (0)     1209 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_strength.py
+-rw-r--r--   0 root         (0) root         (0)     1984 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/ad_type.py
+-rw-r--r--   0 root         (0) root         (0)     1690 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/advertising_channel_sub_type.py
+-rw-r--r--   0 root         (0) root         (0)     1382 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/advertising_channel_type.py
+-rw-r--r--   0 root         (0) root         (0)     1307 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/affiliate_location_feed_relationship_type.py
+-rw-r--r--   0 root         (0) root         (0)     1444 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/affiliate_location_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1412 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/age_range_type.py
+-rw-r--r--   0 root         (0) root         (0)     1185 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/app_campaign_app_store.py
+-rw-r--r--   0 root         (0) root         (0)     1567 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/app_campaign_bidding_strategy_goal_type.py
+-rw-r--r--   0 root         (0) root         (0)     1139 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/app_payment_model_type.py
+-rw-r--r--   0 root         (0) root         (0)     1285 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/app_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1151 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/app_store.py
+-rw-r--r--   0 root         (0) root         (0)     1144 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/app_url_operating_system_type.py
+-rw-r--r--   0 root         (0) root         (0)     1780 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_field_type.py
+-rw-r--r--   0 root         (0) root         (0)     1191 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_group_status.py
+-rw-r--r--   0 root         (0) root         (0)     1189 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_link_status.py
+-rw-r--r--   0 root         (0) root         (0)     1319 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_performance_label.py
+-rw-r--r--   0 root         (0) root         (0)     1189 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_set_asset_status.py
+-rw-r--r--   0 root         (0) root         (0)     1261 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_set_link_status.py
+-rw-r--r--   0 root         (0) root         (0)     1162 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_set_status.py
+-rw-r--r--   0 root         (0) root         (0)     1549 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_set_type.py
+-rw-r--r--   0 root         (0) root         (0)     1222 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_source.py
+-rw-r--r--   0 root         (0) root         (0)     1760 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/asset_type.py
+-rw-r--r--   0 root         (0) root         (0)     1260 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/async_action_status.py
+-rw-r--r--   0 root         (0) root         (0)     1669 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/attribution_model.py
+-rw-r--r--   0 root         (0) root         (0)     1512 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/audience_insights_dimension.py
+-rw-r--r--   0 root         (0) root         (0)     1125 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/audience_status.py
+-rw-r--r--   0 root         (0) root         (0)     1153 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/batch_job_status.py
+-rw-r--r--   0 root         (0) root         (0)     1172 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/bid_modifier_source.py
+-rw-r--r--   0 root         (0) root         (0)     1340 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/bidding_source.py
+-rw-r--r--   0 root         (0) root         (0)     1163 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/bidding_strategy_status.py
+-rw-r--r--   0 root         (0) root         (0)     2033 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/bidding_strategy_system_status.py
+-rw-r--r--   0 root         (0) root         (0)     1603 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/bidding_strategy_type.py
+-rw-r--r--   0 root         (0) root         (0)     1197 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/billing_setup_status.py
+-rw-r--r--   0 root         (0) root         (0)     1240 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/brand_safety_suitability.py
+-rw-r--r--   0 root         (0) root         (0)     1286 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/budget_campaign_association_status.py
+-rw-r--r--   0 root         (0) root         (0)     1232 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/budget_delivery_method.py
+-rw-r--r--   0 root         (0) root         (0)     1114 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/budget_period.py
+-rw-r--r--   0 root         (0) root         (0)     1113 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/budget_status.py
+-rw-r--r--   0 root         (0) root         (0)     1145 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/budget_type.py
+-rw-r--r--   0 root         (0) root         (0)     1331 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/call_conversion_reporting_state.py
+-rw-r--r--   0 root         (0) root         (0)     1252 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/call_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1321 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/call_to_action_type.py
+-rw-r--r--   0 root         (0) root         (0)     1211 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/call_tracking_display_location.py
+-rw-r--r--   0 root         (0) root         (0)     1207 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/call_type.py
+-rw-r--r--   0 root         (0) root         (0)     1152 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/callout_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1192 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_criterion_status.py
+-rw-r--r--   0 root         (0) root         (0)     1252 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_draft_status.py
+-rw-r--r--   0 root         (0) root         (0)     1262 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_experiment_type.py
+-rw-r--r--   0 root         (0) root         (0)     1149 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_group_status.py
+-rw-r--r--   0 root         (0) root         (0)     1564 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_primary_status.py
+-rw-r--r--   0 root         (0) root         (0)     2515 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_primary_status_reason.py
+-rw-r--r--   0 root         (0) root         (0)     1218 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_serving_status.py
+-rw-r--r--   0 root         (0) root         (0)     1210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_shared_set_status.py
+-rw-r--r--   0 root         (0) root         (0)     1173 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/campaign_status.py
+-rw-r--r--   0 root         (0) root         (0)     1192 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/chain_relationship_type.py
+-rw-r--r--   0 root         (0) root         (0)     1555 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/change_client_type.py
+-rw-r--r--   0 root         (0) root         (0)     1703 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/change_event_resource_type.py
+-rw-r--r--   0 root         (0) root         (0)     1200 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/change_status_operation.py
+-rw-r--r--   0 root         (0) root         (0)     1638 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/change_status_resource_type.py
+-rw-r--r--   0 root         (0) root         (0)     3044 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/click_type.py
+-rw-r--r--   0 root         (0) root         (0)     1167 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/combined_audience_status.py
+-rw-r--r--   0 root         (0) root         (0)     1596 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/content_label_type.py
+-rw-r--r--   0 root         (0) root         (0)     1772 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_action_category.py
+-rw-r--r--   0 root         (0) root         (0)     1367 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_action_counting_type.py
+-rw-r--r--   0 root         (0) root         (0)     1215 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_action_status.py
+-rw-r--r--   0 root         (0) root         (0)     2464 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_action_type.py
+-rw-r--r--   0 root         (0) root         (0)     1375 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_adjustment_type.py
+-rw-r--r--   0 root         (0) root         (0)     1245 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_attribution_event_type.py
+-rw-r--r--   0 root         (0) root         (0)     1267 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_custom_variable_status.py
+-rw-r--r--   0 root         (0) root         (0)     1246 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_environment_enum.py
+-rw-r--r--   0 root         (0) root         (0)     1844 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_lag_bucket.py
+-rw-r--r--   0 root         (0) root         (0)     3220 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_or_adjustment_lag_bucket.py
+-rw-r--r--   0 root         (0) root         (0)     1261 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_origin.py
+-rw-r--r--   0 root         (0) root         (0)     1370 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_tracking_status_enum.py
+-rw-r--r--   0 root         (0) root         (0)     1403 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_value_rule_primary_dimension.py
+-rw-r--r--   0 root         (0) root         (0)     1249 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_value_rule_set_status.py
+-rw-r--r--   0 root         (0) root         (0)     1232 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/conversion_value_rule_status.py
+-rw-r--r--   0 root         (0) root         (0)     1557 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/criterion_category_channel_availability_mode.py
+-rw-r--r--   0 root         (0) root         (0)     1538 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/criterion_category_locale_availability_mode.py
+-rw-r--r--   0 root         (0) root         (0)     1227 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/criterion_system_serving_status.py
+-rw-r--r--   0 root         (0) root         (0)     1957 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/criterion_type.py
+-rw-r--r--   0 root         (0) root         (0)     1213 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/custom_audience_member_type.py
+-rw-r--r--   0 root         (0) root         (0)     1153 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/custom_audience_status.py
+-rw-r--r--   0 root         (0) root         (0)     1188 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/custom_audience_type.py
+-rw-r--r--   0 root         (0) root         (0)     1222 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/custom_conversion_goal_status.py
+-rw-r--r--   0 root         (0) root         (0)     1194 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/custom_interest_member_type.py
+-rw-r--r--   0 root         (0) root         (0)     1150 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/custom_interest_status.py
+-rw-r--r--   0 root         (0) root         (0)     1157 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/custom_interest_type.py
+-rw-r--r--   0 root         (0) root         (0)     1756 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/custom_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1260 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/customer_match_upload_key_type.py
+-rw-r--r--   0 root         (0) root         (0)     1579 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/customer_pay_per_conversion_eligibility_failure_reason.py
+-rw-r--r--   0 root         (0) root         (0)     1196 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/customer_status.py
+-rw-r--r--   0 root         (0) root         (0)     1215 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/customizer_attribute_status.py
+-rw-r--r--   0 root         (0) root         (0)     1237 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/customizer_attribute_type.py
+-rw-r--r--   0 root         (0) root         (0)     1195 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/customizer_value_status.py
+-rw-r--r--   0 root         (0) root         (0)     1217 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/data_driven_model_status.py
+-rw-r--r--   0 root         (0) root         (0)     1266 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/day_of_week.py
+-rw-r--r--   0 root         (0) root         (0)     1223 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/device.py
+-rw-r--r--   0 root         (0) root         (0)     1184 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/display_ad_format_setting.py
+-rw-r--r--   0 root         (0) root         (0)     1812 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/display_upload_product_type.py
+-rw-r--r--   0 root         (0) root         (0)     1907 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/distance_bucket.py
+-rw-r--r--   0 root         (0) root         (0)     1225 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/dsa_page_feed_criterion_field.py
+-rw-r--r--   0 root         (0) root         (0)     1742 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/education_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1485 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/experiment_metric.py
+-rw-r--r--   0 root         (0) root         (0)     1295 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/experiment_metric_direction.py
+-rw-r--r--   0 root         (0) root         (0)     1244 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/experiment_status.py
+-rw-r--r--   0 root         (0) root         (0)     1430 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/experiment_type.py
+-rw-r--r--   0 root         (0) root         (0)     1186 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/extension_setting_device.py
+-rw-r--r--   0 root         (0) root         (0)     1453 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/extension_type.py
+-rw-r--r--   0 root         (0) root         (0)     2060 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/external_conversion_source.py
+-rw-r--r--   0 root         (0) root         (0)     1422 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_attribute_type.py
+-rw-r--r--   0 root         (0) root         (0)     1283 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_quality_approval_status.py
+-rw-r--r--   0 root         (0) root         (0)     2146 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_quality_disapproval_reason.py
+-rw-r--r--   0 root         (0) root         (0)     1173 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_set_status.py
+-rw-r--r--   0 root         (0) root         (0)     1207 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_set_string_filter_type.py
+-rw-r--r--   0 root         (0) root         (0)     1156 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_status.py
+-rw-r--r--   0 root         (0) root         (0)     1187 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_target_device.py
+-rw-r--r--   0 root         (0) root         (0)     1188 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_target_status.py
+-rw-r--r--   0 root         (0) root         (0)     1199 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_target_type.py
+-rw-r--r--   0 root         (0) root         (0)     1230 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_item_validation_status.py
+-rw-r--r--   0 root         (0) root         (0)     1159 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_link_status.py
+-rw-r--r--   0 root         (0) root         (0)     1237 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_mapping_criterion_type.py
+-rw-r--r--   0 root         (0) root         (0)     1171 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_mapping_status.py
+-rw-r--r--   0 root         (0) root         (0)     1142 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_origin.py
+-rw-r--r--   0 root         (0) root         (0)     1129 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/feed_status.py
+-rw-r--r--   0 root         (0) root         (0)     1720 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/flight_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1244 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/frequency_cap_event_type.py
+-rw-r--r--   0 root         (0) root         (0)     1309 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/frequency_cap_level.py
+-rw-r--r--   0 root         (0) root         (0)     1218 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/frequency_cap_time_unit.py
+-rw-r--r--   0 root         (0) root         (0)     1188 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/gender_type.py
+-rw-r--r--   0 root         (0) root         (0)     1198 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/geo_target_constant_status.py
+-rw-r--r--   0 root         (0) root         (0)     1226 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/geo_targeting_restriction.py
+-rw-r--r--   0 root         (0) root         (0)     1175 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/geo_targeting_type.py
+-rw-r--r--   0 root         (0) root         (0)     1328 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/goal_config_level.py
+-rw-r--r--   0 root         (0) root         (0)     1300 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/google_ads_field_category.py
+-rw-r--r--   0 root         (0) root         (0)     1379 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/google_ads_field_data_type.py
+-rw-r--r--   0 root         (0) root         (0)     1193 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/google_voice_call_status.py
+-rw-r--r--   0 root         (0) root         (0)     1219 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/hotel_date_selection_type.py
+-rw-r--r--   0 root         (0) root         (0)     1768 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/hotel_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1246 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/hotel_price_bucket.py
+-rw-r--r--   0 root         (0) root         (0)     1210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/hotel_rate_type.py
+-rw-r--r--   0 root         (0) root         (0)     1241 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/hotel_reconciliation_status.py
+-rw-r--r--   0 root         (0) root         (0)     1195 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/image_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1437 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/income_range_type.py
+-rw-r--r--   0 root         (0) root         (0)     1269 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/interaction_event_type.py
+-rw-r--r--   0 root         (0) root         (0)     1139 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/interaction_type.py
+-rw-r--r--   0 root         (0) root         (0)     1131 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/invoice_type.py
+-rw-r--r--   0 root         (0) root         (0)     1646 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/job_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1144 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/keyword_match_type.py
+-rw-r--r--   0 root         (0) root         (0)     1154 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/keyword_plan_aggregate_metric_type.py
+-rw-r--r--   0 root         (0) root         (0)     1506 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/keyword_plan_competition_level.py
+-rw-r--r--   0 root         (0) root         (0)     1230 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/keyword_plan_concept_group_type.py
+-rw-r--r--   0 root         (0) root         (0)     1191 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/keyword_plan_forecast_interval.py
+-rw-r--r--   0 root         (0) root         (0)     1210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/keyword_plan_keyword_annotation.py
+-rw-r--r--   0 root         (0) root         (0)     1217 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/keyword_plan_network.py
+-rw-r--r--   0 root         (0) root         (0)     1132 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/label_status.py
+-rw-r--r--   0 root         (0) root         (0)     1502 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/lead_form_call_to_action_type.py
+-rw-r--r--   0 root         (0) root         (0)     1218 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/lead_form_desired_intent.py
+-rw-r--r--   0 root         (0) root         (0)     4577 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/lead_form_field_user_input_type.py
+-rw-r--r--   0 root         (0) root         (0)     1337 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/lead_form_post_submit_call_to_action_type.py
+-rw-r--r--   0 root         (0) root         (0)     1305 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/legacy_app_install_ad_app_store.py
+-rw-r--r--   0 root         (0) root         (0)     1338 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/linked_account_type.py
+-rw-r--r--   0 root         (0) root         (0)     1339 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/listing_group_filter_bidding_category_level.py
+-rw-r--r--   0 root         (0) root         (0)     1318 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/listing_group_filter_custom_attribute_index.py
+-rw-r--r--   0 root         (0) root         (0)     1182 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/listing_group_filter_product_channel.py
+-rw-r--r--   0 root         (0) root         (0)     1210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/listing_group_filter_product_condition.py
+-rw-r--r--   0 root         (0) root         (0)     1264 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/listing_group_filter_product_type_level.py
+-rw-r--r--   0 root         (0) root         (0)     1229 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/listing_group_filter_type_enum.py
+-rw-r--r--   0 root         (0) root         (0)     1217 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/listing_group_filter_vertical.py
+-rw-r--r--   0 root         (0) root         (0)     1152 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/listing_group_type.py
+-rw-r--r--   0 root         (0) root         (0)     1723 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/local_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1374 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/location_extension_targeting_criterion_field.py
+-rw-r--r--   0 root         (0) root         (0)     1257 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/location_group_radius_units.py
+-rw-r--r--   0 root         (0) root         (0)     1198 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/location_ownership_type.py
+-rw-r--r--   0 root         (0) root         (0)     1324 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/location_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1165 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/location_source_type.py
+-rw-r--r--   0 root         (0) root         (0)     1184 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/location_string_filter_type.py
+-rw-r--r--   0 root         (0) root         (0)     1233 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/manager_link_status.py
+-rw-r--r--   0 root         (0) root         (0)     1264 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/matching_function_context_type.py
+-rw-r--r--   0 root         (0) root         (0)     1240 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/matching_function_operator.py
+-rw-r--r--   0 root         (0) root         (0)     1189 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/media_type.py
+-rw-r--r--   0 root         (0) root         (0)     1298 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/merchant_center_link_status.py
+-rw-r--r--   0 root         (0) root         (0)     1263 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/message_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1306 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/mime_type.py
+-rw-r--r--   0 root         (0) root         (0)     1183 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/minute_of_hour.py
+-rw-r--r--   0 root         (0) root         (0)     1177 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/mobile_app_vendor.py
+-rw-r--r--   0 root         (0) root         (0)     1142 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/mobile_device_type.py
+-rw-r--r--   0 root         (0) root         (0)     1371 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/month_of_year.py
+-rw-r--r--   0 root         (0) root         (0)     1199 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/negative_geo_target_type.py
+-rw-r--r--   0 root         (0) root         (0)     1418 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/offline_user_data_job_failure_reason.py
+-rw-r--r--   0 root         (0) root         (0)     1515 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/offline_user_data_job_match_rate_range.py
+-rw-r--r--   0 root         (0) root         (0)     1233 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/offline_user_data_job_status.py
+-rw-r--r--   0 root         (0) root         (0)     1311 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/offline_user_data_job_type.py
+-rw-r--r--   0 root         (0) root         (0)     1224 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/operating_system_version_operator_type.py
+-rw-r--r--   0 root         (0) root         (0)     1210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/optimization_goal_type.py
+-rw-r--r--   0 root         (0) root         (0)     1237 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/parental_status_type.py
+-rw-r--r--   0 root         (0) root         (0)     1193 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/payment_mode.py
+-rw-r--r--   0 root         (0) root         (0)     1264 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/performance_max_upgrade_status.py
+-rw-r--r--   0 root         (0) root         (0)     1637 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/placeholder_type.py
+-rw-r--r--   0 root         (0) root         (0)     1248 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/placement_type.py
+-rw-r--r--   0 root         (0) root         (0)     1458 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/policy_approval_status.py
+-rw-r--r--   0 root         (0) root         (0)     1238 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/policy_review_status.py
+-rw-r--r--   0 root         (0) root         (0)     1290 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/policy_topic_entry_type.py
+-rw-r--r--   0 root         (0) root         (0)     1420 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/policy_topic_evidence_destination_mismatch_url_type.py
+-rw-r--r--   0 root         (0) root         (0)     1349 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/policy_topic_evidence_destination_not_working_device.py
+-rw-r--r--   0 root         (0) root         (0)     1395 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/policy_topic_evidence_destination_not_working_dns_error_type.py
+-rw-r--r--   0 root         (0) root         (0)     1227 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/positive_geo_target_type.py
+-rw-r--r--   0 root         (0) root         (0)     1178 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/preferred_content_type.py
+-rw-r--r--   0 root         (0) root         (0)     1222 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/price_extension_price_qualifier.py
+-rw-r--r--   0 root         (0) root         (0)     1253 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/price_extension_price_unit.py
+-rw-r--r--   0 root         (0) root         (0)     1328 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/price_extension_type.py
+-rw-r--r--   0 root         (0) root         (0)     2722 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/price_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1243 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/product_bidding_category_level.py
+-rw-r--r--   0 root         (0) root         (0)     1195 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/product_bidding_category_status.py
+-rw-r--r--   0 root         (0) root         (0)     1128 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/product_channel.py
+-rw-r--r--   0 root         (0) root         (0)     1185 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/product_channel_exclusivity.py
+-rw-r--r--   0 root         (0) root         (0)     1156 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/product_condition.py
+-rw-r--r--   0 root         (0) root         (0)     1270 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/product_custom_attribute_index.py
+-rw-r--r--   0 root         (0) root         (0)     1212 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/product_type_level.py
+-rw-r--r--   0 root         (0) root         (0)     1217 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/promotion_extension_discount_modifier.py
+-rw-r--r--   0 root         (0) root         (0)     2149 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/promotion_extension_occasion.py
+-rw-r--r--   0 root         (0) root         (0)     1516 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/promotion_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1193 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/proximity_radius_units.py
+-rw-r--r--   0 root         (0) root         (0)     1202 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/quality_score_bucket.py
+-rw-r--r--   0 root         (0) root         (0)     1888 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/reach_plan_age_range.py
+-rw-r--r--   0 root         (0) root         (0)     1204 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/reach_plan_network.py
+-rw-r--r--   0 root         (0) root         (0)     1733 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/real_estate_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     2056 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/recommendation_type.py
+-rw-r--r--   0 root         (0) root         (0)     1252 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/resource_change_operation.py
+-rw-r--r--   0 root         (0) root         (0)     7526 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/resource_limit_type.py
+-rw-r--r--   0 root         (0) root         (0)     1148 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/response_content_type.py
+-rw-r--r--   0 root         (0) root         (0)     1214 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/search_engine_results_page_type.py
+-rw-r--r--   0 root         (0) root         (0)     1299 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/search_term_match_type.py
+-rw-r--r--   0 root         (0) root         (0)     1329 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/search_term_targeting_status.py
+-rw-r--r--   0 root         (0) root         (0)     1291 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/seasonality_event_scope.py
+-rw-r--r--   0 root         (0) root         (0)     1276 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/seasonality_event_status.py
+-rw-r--r--   0 root         (0) root         (0)     1242 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/served_asset_field_type.py
+-rw-r--r--   0 root         (0) root         (0)     1163 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/shared_set_status.py
+-rw-r--r--   0 root         (0) root         (0)     1168 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/shared_set_type.py
+-rw-r--r--   0 root         (0) root         (0)     1285 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/simulation_modification_method.py
+-rw-r--r--   0 root         (0) root         (0)     1325 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/simulation_type.py
+-rw-r--r--   0 root         (0) root         (0)     1294 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/sitelink_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1197 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/sk_ad_network_ad_event_type.py
+-rw-r--r--   0 root         (0) root         (0)     1225 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/sk_ad_network_attribution_credit.py
+-rw-r--r--   0 root         (0) root         (0)     1189 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/sk_ad_network_user_type.py
+-rw-r--r--   0 root         (0) root         (0)     1257 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/slot.py
+-rw-r--r--   0 root         (0) root         (0)     1215 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/spending_limit_type.py
+-rw-r--r--   0 root         (0) root         (0)     1219 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/structured_snippet_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1212 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/summary_row_setting.py
+-rw-r--r--   0 root         (0) root         (0)     1210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/system_managed_entity_source.py
+-rw-r--r--   0 root         (0) root         (0)     1278 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/target_cpa_opt_in_recommendation_goal.py
+-rw-r--r--   0 root         (0) root         (0)     1357 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/target_impression_share_location.py
+-rw-r--r--   0 root         (0) root         (0)     1284 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/targeting_dimension.py
+-rw-r--r--   0 root         (0) root         (0)     1171 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/time_type.py
+-rw-r--r--   0 root         (0) root         (0)     1284 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/tracking_code_page_format.py
+-rw-r--r--   0 root         (0) root         (0)     1300 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/tracking_code_type.py
+-rw-r--r--   0 root         (0) root         (0)     1780 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/travel_placeholder_field.py
+-rw-r--r--   0 root         (0) root         (0)     1360 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_identifier_source.py
+-rw-r--r--   0 root         (0) root         (0)     1283 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_interest_taxonomy_type.py
+-rw-r--r--   0 root         (0) root         (0)     1179 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_access_status.py
+-rw-r--r--   0 root         (0) root         (0)     1225 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_closing_reason.py
+-rw-r--r--   0 root         (0) root         (0)     1190 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_combined_rule_operator.py
+-rw-r--r--   0 root         (0) root         (0)     1237 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_crm_data_source_type.py
+-rw-r--r--   0 root         (0) root         (0)     1234 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_date_rule_item_operator.py
+-rw-r--r--   0 root         (0) root         (0)     1185 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_flexible_rule_operator.py
+-rw-r--r--   0 root         (0) root         (0)     1194 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_logical_rule_operator.py
+-rw-r--r--   0 root         (0) root         (0)     1308 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_membership_status.py
+-rw-r--r--   0 root         (0) root         (0)     1336 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_number_rule_item_operator.py
+-rw-r--r--   0 root         (0) root         (0)     1224 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_prepopulation_status.py
+-rw-r--r--   0 root         (0) root         (0)     1144 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_rule_type.py
+-rw-r--r--   0 root         (0) root         (0)     1829 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_size_range.py
+-rw-r--r--   0 root         (0) root         (0)     1370 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_string_rule_item_operator.py
+-rw-r--r--   0 root         (0) root         (0)     1212 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/user_list_type.py
+-rw-r--r--   0 root         (0) root         (0)     1229 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/value_rule_device_type.py
+-rw-r--r--   0 root         (0) root         (0)     1264 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/value_rule_geo_location_match_type.py
+-rw-r--r--   0 root         (0) root         (0)     1256 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/value_rule_operation.py
+-rw-r--r--   0 root         (0) root         (0)     1213 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/value_rule_set_attachment_type.py
+-rw-r--r--   0 root         (0) root         (0)     1263 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/value_rule_set_dimension.py
+-rw-r--r--   0 root         (0) root         (0)     1239 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/vanity_pharma_display_url_mode.py
+-rw-r--r--   0 root         (0) root         (0)     1737 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/vanity_pharma_text.py
+-rw-r--r--   0 root         (0) root         (0)     1352 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/video_thumbnail.py
+-rw-r--r--   0 root         (0) root         (0)     1285 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/webpage_condition_operand.py
+-rw-r--r--   0 root         (0) root         (0)     1220 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/enums/types/webpage_condition_operator.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:00.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/
+-rw-r--r--   0 root         (0) root         (0)     5069 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:00.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/services/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/services/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:01.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1498 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/access_invitation_error.py
+-rw-r--r--   0 root         (0) root         (0)     2240 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/account_budget_proposal_error.py
+-rw-r--r--   0 root         (0) root         (0)     1183 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/account_link_error.py
+-rw-r--r--   0 root         (0) root         (0)     1323 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_customizer_error.py
+-rw-r--r--   0 root         (0) root         (0)     7457 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_error.py
+-rw-r--r--   0 root         (0) root         (0)     1556 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_group_ad_error.py
+-rw-r--r--   0 root         (0) root         (0)     1279 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_group_bid_modifier_error.py
+-rw-r--r--   0 root         (0) root         (0)     1264 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_group_criterion_customizer_error.py
+-rw-r--r--   0 root         (0) root         (0)     2539 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_group_criterion_error.py
+-rw-r--r--   0 root         (0) root         (0)     1163 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_group_customizer_error.py
+-rw-r--r--   0 root         (0) root         (0)     1793 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_group_error.py
+-rw-r--r--   0 root         (0) root         (0)     1452 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_group_feed_error.py
+-rw-r--r--   0 root         (0) root         (0)     1215 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_parameter_error.py
+-rw-r--r--   0 root         (0) root         (0)     1237 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/ad_sharing_error.py
+-rw-r--r--   0 root         (0) root         (0)     1116 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/adx_error.py
+-rw-r--r--   0 root         (0) root         (0)     2712 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/asset_error.py
+-rw-r--r--   0 root         (0) root         (0)     1279 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/asset_group_asset_error.py
+-rw-r--r--   0 root         (0) root         (0)     1568 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/asset_group_error.py
+-rw-r--r--   0 root         (0) root         (0)     1813 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/asset_group_listing_group_filter_error.py
+-rw-r--r--   0 root         (0) root         (0)     2093 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/asset_link_error.py
+-rw-r--r--   0 root         (0) root         (0)     1286 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/asset_set_asset_error.py
+-rw-r--r--   0 root         (0) root         (0)     1502 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/asset_set_error.py
+-rw-r--r--   0 root         (0) root         (0)     1356 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/asset_set_link_error.py
+-rw-r--r--   0 root         (0) root         (0)     1391 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/audience_error.py
+-rw-r--r--   0 root         (0) root         (0)     1259 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/audience_insights_error.py
+-rw-r--r--   0 root         (0) root         (0)     1816 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/authentication_error.py
+-rw-r--r--   0 root         (0) root         (0)     1662 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/authorization_error.py
+-rw-r--r--   0 root         (0) root         (0)     1328 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/batch_job_error.py
+-rw-r--r--   0 root         (0) root         (0)     2647 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/bidding_error.py
+-rw-r--r--   0 root         (0) root         (0)     1388 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/bidding_strategy_error.py
+-rw-r--r--   0 root         (0) root         (0)     2013 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/billing_setup_error.py
+-rw-r--r--   0 root         (0) root         (0)     2039 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_budget_error.py
+-rw-r--r--   0 root         (0) root         (0)     1261 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_conversion_goal_error.py
+-rw-r--r--   0 root         (0) root         (0)     2425 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_criterion_error.py
+-rw-r--r--   0 root         (0) root         (0)     1166 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_customizer_error.py
+-rw-r--r--   0 root         (0) root         (0)     1587 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_draft_error.py
+-rw-r--r--   0 root         (0) root         (0)     3575 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_error.py
+-rw-r--r--   0 root         (0) root         (0)     1663 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_experiment_error.py
+-rw-r--r--   0 root         (0) root         (0)     1509 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_feed_error.py
+-rw-r--r--   0 root         (0) root         (0)     1200 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/campaign_shared_set_error.py
+-rw-r--r--   0 root         (0) root         (0)     1300 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/change_event_error.py
+-rw-r--r--   0 root         (0) root         (0)     1305 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/change_status_error.py
+-rw-r--r--   0 root         (0) root         (0)     1187 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/collection_size_error.py
+-rw-r--r--   0 root         (0) root         (0)     1209 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/context_error.py
+-rw-r--r--   0 root         (0) root         (0)     1566 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/conversion_action_error.py
+-rw-r--r--   0 root         (0) root         (0)     2256 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/conversion_adjustment_upload_error.py
+-rw-r--r--   0 root         (0) root         (0)     1276 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/conversion_custom_variable_error.py
+-rw-r--r--   0 root         (0) root         (0)     1430 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/conversion_goal_campaign_config_error.py
+-rw-r--r--   0 root         (0) root         (0)     3093 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/conversion_upload_error.py
+-rw-r--r--   0 root         (0) root         (0)     1689 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/conversion_value_rule_error.py
+-rw-r--r--   0 root         (0) root         (0)     1810 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/conversion_value_rule_set_error.py
+-rw-r--r--   0 root         (0) root         (0)     1141 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/country_code_error.py
+-rw-r--r--   0 root         (0) root         (0)     7700 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/criterion_error.py
+-rw-r--r--   0 root         (0) root         (0)     1155 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/currency_code_error.py
+-rw-r--r--   0 root         (0) root         (0)     1448 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/custom_audience_error.py
+-rw-r--r--   0 root         (0) root         (0)     1398 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/custom_conversion_goal_error.py
+-rw-r--r--   0 root         (0) root         (0)     1461 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/custom_interest_error.py
+-rw-r--r--   0 root         (0) root         (0)     1531 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/customer_client_link_error.py
+-rw-r--r--   0 root         (0) root         (0)     1166 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/customer_customizer_error.py
+-rw-r--r--   0 root         (0) root         (0)     1218 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/customer_error.py
+-rw-r--r--   0 root         (0) root         (0)     1480 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/customer_feed_error.py
+-rw-r--r--   0 root         (0) root         (0)     1608 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/customer_manager_link_error.py
+-rw-r--r--   0 root         (0) root         (0)     1347 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/customer_user_access_error.py
+-rw-r--r--   0 root         (0) root         (0)     1219 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/customizer_attribute_error.py
+-rw-r--r--   0 root         (0) root         (0)     1213 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/database_error.py
+-rw-r--r--   0 root         (0) root         (0)     1550 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/date_error.py
+-rw-r--r--   0 root         (0) root         (0)     1312 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/date_range_error.py
+-rw-r--r--   0 root         (0) root         (0)     1166 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/distinct_error.py
+-rw-r--r--   0 root         (0) root         (0)     1126 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/enum_error.py
+-rw-r--r--   0 root         (0) root         (0)    88760 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/errors.py
+-rw-r--r--   0 root         (0) root         (0)     1851 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/experiment_arm_error.py
+-rw-r--r--   0 root         (0) root         (0)     2195 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/experiment_error.py
+-rw-r--r--   0 root         (0) root         (0)     3211 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/extension_feed_item_error.py
+-rw-r--r--   0 root         (0) root         (0)     4197 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/extension_setting_error.py
+-rw-r--r--   0 root         (0) root         (0)     1300 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/feed_attribute_reference_error.py
+-rw-r--r--   0 root         (0) root         (0)     2081 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/feed_error.py
+-rw-r--r--   0 root         (0) root         (0)     1539 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/feed_item_error.py
+-rw-r--r--   0 root         (0) root         (0)     1392 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/feed_item_set_error.py
+-rw-r--r--   0 root         (0) root         (0)     1230 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/feed_item_set_link_error.py
+-rw-r--r--   0 root         (0) root         (0)     1505 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/feed_item_target_error.py
+-rw-r--r--   0 root         (0) root         (0)     5485 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/feed_item_validation_error.py
+-rw-r--r--   0 root         (0) root         (0)     2002 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/feed_mapping_error.py
+-rw-r--r--   0 root         (0) root         (0)     1337 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/field_error.py
+-rw-r--r--   0 root         (0) root         (0)     1242 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/field_mask_error.py
+-rw-r--r--   0 root         (0) root         (0)     1739 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/function_error.py
+-rw-r--r--   0 root         (0) root         (0)     1536 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/function_parsing_error.py
+-rw-r--r--   0 root         (0) root         (0)     1371 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/geo_target_constant_suggestion_error.py
+-rw-r--r--   0 root         (0) root         (0)     1176 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/header_error.py
+-rw-r--r--   0 root         (0) root         (0)     1101 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/id_error.py
+-rw-r--r--   0 root         (0) root         (0)     2427 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/image_error.py
+-rw-r--r--   0 root         (0) root         (0)     1231 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/internal_error.py
+-rw-r--r--   0 root         (0) root         (0)     1292 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/invoice_error.py
+-rw-r--r--   0 root         (0) root         (0)     1271 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/keyword_plan_ad_group_error.py
+-rw-r--r--   0 root         (0) root         (0)     1614 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/keyword_plan_ad_group_keyword_error.py
+-rw-r--r--   0 root         (0) root         (0)     1394 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/keyword_plan_campaign_error.py
+-rw-r--r--   0 root         (0) root         (0)     1300 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/keyword_plan_campaign_keyword_error.py
+-rw-r--r--   0 root         (0) root         (0)     1778 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/keyword_plan_error.py
+-rw-r--r--   0 root         (0) root         (0)     1227 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/keyword_plan_idea_error.py
+-rw-r--r--   0 root         (0) root         (0)     1503 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/label_error.py
+-rw-r--r--   0 root         (0) root         (0)     1183 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/language_code_error.py
+-rw-r--r--   0 root         (0) root         (0)     1200 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/list_operation_error.py
+-rw-r--r--   0 root         (0) root         (0)     1848 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/manager_link_error.py
+-rw-r--r--   0 root         (0) root         (0)     1918 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/media_bundle_error.py
+-rw-r--r--   0 root         (0) root         (0)     2014 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/media_file_error.py
+-rw-r--r--   0 root         (0) root         (0)     2478 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/media_upload_error.py
+-rw-r--r--   0 root         (0) root         (0)     1242 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/merchant_center_error.py
+-rw-r--r--   0 root         (0) root         (0)     1727 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/multiplier_error.py
+-rw-r--r--   0 root         (0) root         (0)     1459 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/mutate_error.py
+-rw-r--r--   0 root         (0) root         (0)     1281 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/new_resource_creation_error.py
+-rw-r--r--   0 root         (0) root         (0)     1200 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/not_allowlisted_error.py
+-rw-r--r--   0 root         (0) root         (0)     1134 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/not_empty_error.py
+-rw-r--r--   0 root         (0) root         (0)     1114 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/null_error.py
+-rw-r--r--   0 root         (0) root         (0)     2725 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/offline_user_data_job_error.py
+-rw-r--r--   0 root         (0) root         (0)     1653 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/operation_access_denied_error.py
+-rw-r--r--   0 root         (0) root         (0)     1144 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/operator_error.py
+-rw-r--r--   0 root         (0) root         (0)     1188 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/partial_failure_error.py
+-rw-r--r--   0 root         (0) root         (0)     1220 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/payments_account_error.py
+-rw-r--r--   0 root         (0) root         (0)     1198 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/policy_finding_error.py
+-rw-r--r--   0 root         (0) root         (0)     1437 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/policy_validation_parameter_error.py
+-rw-r--r--   0 root         (0) root         (0)     1176 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/policy_violation_error.py
+-rw-r--r--   0 root         (0) root         (0)     3276 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/query_error.py
+-rw-r--r--   0 root         (0) root         (0)     1198 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/quota_error.py
+-rw-r--r--   0 root         (0) root         (0)     1135 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/range_error.py
+-rw-r--r--   0 root         (0) root         (0)     1198 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/reach_plan_error.py
+-rw-r--r--   0 root         (0) root         (0)     1692 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/recommendation_error.py
+-rw-r--r--   0 root         (0) root         (0)     1153 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/region_code_error.py
+-rw-r--r--   0 root         (0) root         (0)     2043 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/request_error.py
+-rw-r--r--   0 root         (0) root         (0)     1210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/resource_access_denied_error.py
+-rw-r--r--   0 root         (0) root         (0)     1506 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/resource_count_limit_exceeded_error.py
+-rw-r--r--   0 root         (0) root         (0)     2023 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/setting_error.py
+-rw-r--r--   0 root         (0) root         (0)     1210 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/shared_criterion_error.py
+-rw-r--r--   0 root         (0) root         (0)     1263 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/shared_set_error.py
+-rw-r--r--   0 root         (0) root         (0)     1197 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/size_limit_error.py
+-rw-r--r--   0 root         (0) root         (0)     1426 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/smart_campaign_error.py
+-rw-r--r--   0 root         (0) root         (0)     1184 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/string_format_error.py
+-rw-r--r--   0 root         (0) root         (0)     1192 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/string_length_error.py
+-rw-r--r--   0 root         (0) root         (0)     1408 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/third_party_app_analytics_link_error.py
+-rw-r--r--   0 root         (0) root         (0)     1145 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/time_zone_error.py
+-rw-r--r--   0 root         (0) root         (0)     3347 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/url_field_error.py
+-rw-r--r--   0 root         (0) root         (0)     1238 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/user_data_error.py
+-rw-r--r--   0 root         (0) root         (0)     2249 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/user_list_error.py
+-rw-r--r--   0 root         (0) root         (0)     1272 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/errors/types/youtube_video_registration_error.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:01.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/
+-rw-r--r--   0 root         (0) root         (0)     5345 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:01.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/services/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/services/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    11233 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/accessible_bidding_strategy.py
+-rw-r--r--   0 root         (0) root         (0)    16198 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/account_budget.py
+-rw-r--r--   0 root         (0) root         (0)     9890 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/account_budget_proposal.py
+-rw-r--r--   0 root         (0) root         (0)     8888 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/account_link.py
+-rw-r--r--   0 root         (0) root         (0)    15724 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad.py
+-rw-r--r--   0 root         (0) root         (0)    13410 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group.py
+-rw-r--r--   0 root         (0) root         (0)     4668 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_ad.py
+-rw-r--r--   0 root         (0) root         (0)     2629 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_ad_asset_combination_view.py
+-rw-r--r--   0 root         (0) root         (0)     5762 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_ad_asset_view.py
+-rw-r--r--   0 root         (0) root         (0)     1747 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_ad_label.py
+-rw-r--r--   0 root         (0) root         (0)     2709 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_asset.py
+-rw-r--r--   0 root         (0) root         (0)     2118 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_asset_set.py
+-rw-r--r--   0 root         (0) root         (0)     1481 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_audience_view.py
+-rw-r--r--   0 root         (0) root         (0)     6414 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_bid_modifier.py
+-rw-r--r--   0 root         (0) root         (0)    22768 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_criterion.py
+-rw-r--r--   0 root         (0) root         (0)     2863 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_criterion_customizer.py
+-rw-r--r--   0 root         (0) root         (0)     1843 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_criterion_label.py
+-rw-r--r--   0 root         (0) root         (0)     4990 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_criterion_simulation.py
+-rw-r--r--   0 root         (0) root         (0)     2598 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_customizer.py
+-rw-r--r--   0 root         (0) root         (0)     2957 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_extension_setting.py
+-rw-r--r--   0 root         (0) root         (0)     3074 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_feed.py
+-rw-r--r--   0 root         (0) root         (0)     1709 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_label.py
+-rw-r--r--   0 root         (0) root         (0)     5433 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_group_simulation.py
+-rw-r--r--   0 root         (0) root         (0)     3179 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_parameter.py
+-rw-r--r--   0 root         (0) root         (0)     1315 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/ad_schedule_view.py
+-rw-r--r--   0 root         (0) root         (0)     1237 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/age_range_view.py
+-rw-r--r--   0 root         (0) root         (0)    15021 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset.py
+-rw-r--r--   0 root         (0) root         (0)     1781 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_field_type_view.py
+-rw-r--r--   0 root         (0) root         (0)     3690 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_group.py
+-rw-r--r--   0 root         (0) root         (0)     3415 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_group_asset.py
+-rw-r--r--   0 root         (0) root         (0)    11283 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_group_listing_group_filter.py
+-rw-r--r--   0 root         (0) root         (0)     1750 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_group_product_group_view.py
+-rw-r--r--   0 root         (0) root         (0)     2081 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_group_signal.py
+-rw-r--r--   0 root         (0) root         (0)     5574 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_set.py
+-rw-r--r--   0 root         (0) root         (0)     2094 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_set_asset.py
+-rw-r--r--   0 root         (0) root         (0)     1883 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/asset_set_type_view.py
+-rw-r--r--   0 root         (0) root         (0)     2965 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/audience.py
+-rw-r--r--   0 root         (0) root         (0)     5442 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/batch_job.py
+-rw-r--r--   0 root         (0) root         (0)     5045 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/bidding_data_exclusion.py
+-rw-r--r--   0 root         (0) root         (0)     5597 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/bidding_seasonality_adjustment.py
+-rw-r--r--   0 root         (0) root         (0)     8735 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/bidding_strategy.py
+-rw-r--r--   0 root         (0) root         (0)     4254 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/bidding_strategy_simulation.py
+-rw-r--r--   0 root         (0) root         (0)     7428 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/billing_setup.py
+-rw-r--r--   0 root         (0) root         (0)     3463 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/call_view.py
+-rw-r--r--   0 root         (0) root         (0)    43116 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign.py
+-rw-r--r--   0 root         (0) root         (0)     2846 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_asset.py
+-rw-r--r--   0 root         (0) root         (0)     2121 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_asset_set.py
+-rw-r--r--   0 root         (0) root         (0)     1570 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_audience_view.py
+-rw-r--r--   0 root         (0) root         (0)     2694 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_bid_modifier.py
+-rw-r--r--   0 root         (0) root         (0)     9479 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_budget.py
+-rw-r--r--   0 root         (0) root         (0)     2582 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_conversion_goal.py
+-rw-r--r--   0 root         (0) root         (0)    13561 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_criterion.py
+-rw-r--r--   0 root         (0) root         (0)     4136 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_criterion_simulation.py
+-rw-r--r--   0 root         (0) root         (0)     2602 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_customizer.py
+-rw-r--r--   0 root         (0) root         (0)     3834 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_draft.py
+-rw-r--r--   0 root         (0) root         (0)     2962 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_extension_setting.py
+-rw-r--r--   0 root         (0) root         (0)     3091 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_feed.py
+-rw-r--r--   0 root         (0) root         (0)     2206 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_group.py
+-rw-r--r--   0 root         (0) root         (0)     1703 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_label.py
+-rw-r--r--   0 root         (0) root         (0)     2714 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_shared_set.py
+-rw-r--r--   0 root         (0) root         (0)     5892 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/campaign_simulation.py
+-rw-r--r--   0 root         (0) root         (0)     1975 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/carrier_constant.py
+-rw-r--r--   0 root         (0) root         (0)    13165 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/change_event.py
+-rw-r--r--   0 root         (0) root         (0)     6115 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/change_status.py
+-rw-r--r--   0 root         (0) root         (0)     4090 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/click_view.py
+-rw-r--r--   0 root         (0) root         (0)     2281 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/combined_audience.py
+-rw-r--r--   0 root         (0) root         (0)    13621 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/conversion_action.py
+-rw-r--r--   0 root         (0) root         (0)     3242 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/conversion_custom_variable.py
+-rw-r--r--   0 root         (0) root         (0)     2170 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/conversion_goal_campaign_config.py
+-rw-r--r--   0 root         (0) root         (0)     6674 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/conversion_value_rule.py
+-rw-r--r--   0 root         (0) root         (0)     4736 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/conversion_value_rule_set.py
+-rw-r--r--   0 root         (0) root         (0)     2250 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/currency_constant.py
+-rw-r--r--   0 root         (0) root         (0)     5508 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/custom_audience.py
+-rw-r--r--   0 root         (0) root         (0)     2222 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/custom_conversion_goal.py
+-rw-r--r--   0 root         (0) root         (0)     4399 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/custom_interest.py
+-rw-r--r--   0 root         (0) root         (0)    12153 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer.py
+-rw-r--r--   0 root         (0) root         (0)     2531 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_asset.py
+-rw-r--r--   0 root         (0) root         (0)     2107 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_asset_set.py
+-rw-r--r--   0 root         (0) root         (0)     4681 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_client.py
+-rw-r--r--   0 root         (0) root         (0)     2524 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_client_link.py
+-rw-r--r--   0 root         (0) root         (0)     2563 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_conversion_goal.py
+-rw-r--r--   0 root         (0) root         (0)     2429 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_customizer.py
+-rw-r--r--   0 root         (0) root         (0)     2544 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_extension_setting.py
+-rw-r--r--   0 root         (0) root         (0)     2837 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_feed.py
+-rw-r--r--   0 root         (0) root         (0)     2075 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_label.py
+-rw-r--r--   0 root         (0) root         (0)     2220 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_manager_link.py
+-rw-r--r--   0 root         (0) root         (0)     4316 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_negative_criterion.py
+-rw-r--r--   0 root         (0) root         (0)     2772 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_user_access.py
+-rw-r--r--   0 root         (0) root         (0)     2819 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customer_user_access_invitation.py
+-rw-r--r--   0 root         (0) root         (0)     2869 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/customizer_attribute.py
+-rw-r--r--   0 root         (0) root         (0)     3198 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/detail_placement_view.py
+-rw-r--r--   0 root         (0) root         (0)     2533 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/detailed_demographic.py
+-rw-r--r--   0 root         (0) root         (0)     1272 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/display_keyword_view.py
+-rw-r--r--   0 root         (0) root         (0)     2248 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/distance_view.py
+-rw-r--r--   0 root         (0) root         (0)     4272 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/domain_category.py
+-rw-r--r--   0 root         (0) root         (0)     3465 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/dynamic_search_ads_search_term_view.py
+-rw-r--r--   0 root         (0) root         (0)     1636 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/expanded_landing_page_view.py
+-rw-r--r--   0 root         (0) root         (0)     5438 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/experiment.py
+-rw-r--r--   0 root         (0) root         (0)     2644 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/experiment_arm.py
+-rw-r--r--   0 root         (0) root         (0)     9925 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/extension_feed_item.py
+-rw-r--r--   0 root         (0) root         (0)    11634 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/feed.py
+-rw-r--r--   0 root         (0) root         (0)    14659 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/feed_item.py
+-rw-r--r--   0 root         (0) root         (0)     3884 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/feed_item_set.py
+-rw-r--r--   0 root         (0) root         (0)     1558 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/feed_item_set_link.py
+-rw-r--r--   0 root         (0) root         (0)     4934 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/feed_item_target.py
+-rw-r--r--   0 root         (0) root         (0)    16964 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/feed_mapping.py
+-rw-r--r--   0 root         (0) root         (0)     1731 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/feed_placeholder_view.py
+-rw-r--r--   0 root         (0) root         (0)     1221 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/gender_view.py
+-rw-r--r--   0 root         (0) root         (0)     3292 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/geo_target_constant.py
+-rw-r--r--   0 root         (0) root         (0)     2195 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/geographic_view.py
+-rw-r--r--   0 root         (0) root         (0)     5394 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/google_ads_field.py
+-rw-r--r--   0 root         (0) root         (0)     2679 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/group_placement_view.py
+-rw-r--r--   0 root         (0) root         (0)     1248 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/hotel_group_view.py
+-rw-r--r--   0 root         (0) root         (0)     1254 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/hotel_performance_view.py
+-rw-r--r--   0 root         (0) root         (0)     5109 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/hotel_reconciliation.py
+-rw-r--r--   0 root         (0) root         (0)     1255 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/income_range_view.py
+-rw-r--r--   0 root         (0) root         (0)    21651 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/invoice.py
+-rw-r--r--   0 root         (0) root         (0)     3805 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/keyword_plan.py
+-rw-r--r--   0 root         (0) root         (0)     2491 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/keyword_plan_ad_group.py
+-rw-r--r--   0 root         (0) root         (0)     3126 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/keyword_plan_ad_group_keyword.py
+-rw-r--r--   0 root         (0) root         (0)     3876 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/keyword_plan_campaign.py
+-rw-r--r--   0 root         (0) root         (0)     2733 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/keyword_plan_campaign_keyword.py
+-rw-r--r--   0 root         (0) root         (0)     2311 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/keyword_theme_constant.py
+-rw-r--r--   0 root         (0) root         (0)     1227 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/keyword_view.py
+-rw-r--r--   0 root         (0) root         (0)     2386 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/label.py
+-rw-r--r--   0 root         (0) root         (0)     1585 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/landing_page_view.py
+-rw-r--r--   0 root         (0) root         (0)     2159 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/language_constant.py
+-rw-r--r--   0 root         (0) root         (0)     4563 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/lead_form_submission_data.py
+-rw-r--r--   0 root         (0) root         (0)     2394 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/life_event.py
+-rw-r--r--   0 root         (0) root         (0)     1298 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/location_view.py
+-rw-r--r--   0 root         (0) root         (0)     1284 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/managed_placement_view.py
+-rw-r--r--   0 root         (0) root         (0)     7876 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/media_file.py
+-rw-r--r--   0 root         (0) root         (0)     2325 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/merchant_center_link.py
+-rw-r--r--   0 root         (0) root         (0)     1718 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/mobile_app_category_constant.py
+-rw-r--r--   0 root         (0) root         (0)     2571 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/mobile_device_constant.py
+-rw-r--r--   0 root         (0) root         (0)     5782 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/offline_user_data_job.py
+-rw-r--r--   0 root         (0) root         (0)     2976 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/operating_system_version_constant.py
+-rw-r--r--   0 root         (0) root         (0)     1645 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/paid_organic_search_term_view.py
+-rw-r--r--   0 root         (0) root         (0)     1272 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/parental_status_view.py
+-rw-r--r--   0 root         (0) root         (0)     3179 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/payments_account.py
+-rw-r--r--   0 root         (0) root         (0)     1473 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/per_store_view.py
+-rw-r--r--   0 root         (0) root         (0)     3796 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/product_bidding_category_constant.py
+-rw-r--r--   0 root         (0) root         (0)     1260 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/product_group_view.py
+-rw-r--r--   0 root         (0) root         (0)    38925 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/recommendation.py
+-rw-r--r--   0 root         (0) root         (0)     2321 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/remarketing_action.py
+-rw-r--r--   0 root         (0) root         (0)     2292 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/search_term_view.py
+-rw-r--r--   0 root         (0) root         (0)     4545 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/shared_criterion.py
+-rw-r--r--   0 root         (0) root         (0)     3285 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/shared_set.py
+-rw-r--r--   0 root         (0) root         (0)     1612 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/shopping_performance_view.py
+-rw-r--r--   0 root         (0) root         (0)     1637 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/smart_campaign_search_term_view.py
+-rw-r--r--   0 root         (0) root         (0)     5330 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/smart_campaign_setting.py
+-rw-r--r--   0 root         (0) root         (0)     1846 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/third_party_app_analytics_link.py
+-rw-r--r--   0 root         (0) root         (0)     2313 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/topic_constant.py
+-rw-r--r--   0 root         (0) root         (0)     1215 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/topic_view.py
+-rw-r--r--   0 root         (0) root         (0)     3166 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/user_interest.py
+-rw-r--r--   0 root         (0) root         (0)    11505 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/user_list.py
+-rw-r--r--   0 root         (0) root         (0)     2078 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/user_location_view.py
+-rw-r--r--   0 root         (0) root         (0)     2032 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/video.py
+-rw-r--r--   0 root         (0) root         (0)     1227 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/resources/types/webpage_view.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_budget_proposal_service/
+-rw-r--r--   0 root         (0) root         (0)      706 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_budget_proposal_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22274 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_budget_proposal_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_budget_proposal_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1109 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_budget_proposal_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6141 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_budget_proposal_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12747 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_budget_proposal_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_link_service/
+-rw-r--r--   0 root         (0) root         (0)      686 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_link_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    24816 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_link_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_link_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1049 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_link_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6502 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_link_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    13746 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/account_link_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_label_service/
+-rw-r--r--   0 root         (0) root         (0)      692 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_label_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21614 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_label_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_label_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1067 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_label_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6024 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_label_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12231 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_label_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_service/
+-rw-r--r--   0 root         (0) root         (0)      682 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22744 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1037 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5952 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12949 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_ad_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_service/
+-rw-r--r--   0 root         (0) root         (0)      688 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21459 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1055 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5991 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12190 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_set_service/
+-rw-r--r--   0 root         (0) root         (0)      694 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_set_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21371 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_set_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_set_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_set_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6067 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_set_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11965 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_asset_set_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_bid_modifier_service/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_bid_modifier_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21559 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_bid_modifier_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_bid_modifier_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1091 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_bid_modifier_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6115 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_bid_modifier_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12693 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_bid_modifier_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_customizer_service/
+-rw-r--r--   0 root         (0) root         (0)      716 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_customizer_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22510 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_customizer_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_customizer_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1139 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_customizer_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6241 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_customizer_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12306 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_customizer_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_label_service/
+-rw-r--r--   0 root         (0) root         (0)      706 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_label_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22141 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_label_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_label_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1109 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_label_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6154 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_label_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12368 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_label_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_service/
+-rw-r--r--   0 root         (0) root         (0)      696 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22497 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1079 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6031 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12848 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_criterion_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_customizer_service/
+-rw-r--r--   0 root         (0) root         (0)      698 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_customizer_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21672 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_customizer_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_customizer_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_customizer_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6086 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_customizer_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12011 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_customizer_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_extension_setting_service/
+-rw-r--r--   0 root         (0) root         (0)      710 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_extension_setting_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22700 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_extension_setting_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:03.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_extension_setting_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1121 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_extension_setting_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6202 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_extension_setting_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12992 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_extension_setting_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_feed_service/
+-rw-r--r--   0 root         (0) root         (0)      686 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_feed_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21513 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_feed_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_feed_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1049 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_feed_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5978 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_feed_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12434 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_feed_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_label_service/
+-rw-r--r--   0 root         (0) root         (0)      688 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_label_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21317 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_label_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_label_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1055 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_label_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5991 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_label_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12187 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_label_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_service/
+-rw-r--r--   0 root         (0) root         (0)      678 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21574 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1025 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5919 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12550 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_group_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_parameter_service/
+-rw-r--r--   0 root         (0) root         (0)      686 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_parameter_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21054 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_parameter_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_parameter_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1049 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_parameter_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5971 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_parameter_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12141 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_parameter_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_service/
+-rw-r--r--   0 root         (0) root         (0)      668 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    23394 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_service/transports/
+-rw-r--r--   0 root         (0) root         (0)      987 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6196 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    13852 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/ad_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_asset_service/
+-rw-r--r--   0 root         (0) root         (0)      694 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_asset_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21419 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_asset_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_asset_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_asset_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6030 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_asset_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11962 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_asset_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_listing_group_filter_service/
+-rw-r--r--   0 root         (0) root         (0)      720 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_listing_group_filter_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21722 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_listing_group_filter_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_listing_group_filter_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1151 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_listing_group_filter_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6274 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_listing_group_filter_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12369 2023-04-08 17:35:35.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_listing_group_filter_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_service/
+-rw-r--r--   0 root         (0) root         (0)      684 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20268 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1043 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5958 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11794 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_signal_service/
+-rw-r--r--   0 root         (0) root         (0)      696 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_signal_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20846 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_signal_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_signal_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1079 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_signal_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_signal_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11978 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_group_signal_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_service/
+-rw-r--r--   0 root         (0) root         (0)      674 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20826 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1013 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5886 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12496 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_asset_service/
+-rw-r--r--   0 root         (0) root         (0)      690 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_asset_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21169 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_asset_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_asset_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1061 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_asset_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6004 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_asset_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11912 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_asset_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_service/
+-rw-r--r--   0 root         (0) root         (0)      680 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19507 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5932 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11744 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/asset_set_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_insights_service/
+-rw-r--r--   0 root         (0) root         (0)      696 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_insights_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    33548 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_insights_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_insights_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1079 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_insights_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8088 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_insights_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    17710 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_insights_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_service/
+-rw-r--r--   0 root         (0) root         (0)      680 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19488 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5925 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11759 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/audience_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/batch_job_service/
+-rw-r--r--   0 root         (0) root         (0)      680 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/batch_job_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    91987 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/batch_job_service/client.py
+-rw-r--r--   0 root         (0) root         (0)     3349 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/batch_job_service/pagers.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/batch_job_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/batch_job_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7678 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/batch_job_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    17331 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/batch_job_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_data_exclusion_service/
+-rw-r--r--   0 root         (0) root         (0)      704 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_data_exclusion_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20943 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_data_exclusion_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_data_exclusion_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1103 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_data_exclusion_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6134 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_data_exclusion_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12096 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_data_exclusion_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_seasonality_adjustment_service/
+-rw-r--r--   0 root         (0) root         (0)      720 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_seasonality_adjustment_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21406 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_seasonality_adjustment_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_seasonality_adjustment_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1151 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_seasonality_adjustment_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6260 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_seasonality_adjustment_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12339 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_seasonality_adjustment_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_strategy_service/
+-rw-r--r--   0 root         (0) root         (0)      694 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_strategy_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20761 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_strategy_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_strategy_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_strategy_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6029 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_strategy_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12649 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/bidding_strategy_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/billing_setup_service/
+-rw-r--r--   0 root         (0) root         (0)      688 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/billing_setup_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20909 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/billing_setup_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/billing_setup_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1055 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/billing_setup_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5978 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/billing_setup_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12475 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/billing_setup_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_service/
+-rw-r--r--   0 root         (0) root         (0)      690 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21544 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:04.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1061 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5997 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12224 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_set_service/
+-rw-r--r--   0 root         (0) root         (0)      696 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_set_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21419 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_set_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_set_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1079 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_set_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_set_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11986 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_asset_set_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_bid_modifier_service/
+-rw-r--r--   0 root         (0) root         (0)      702 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_bid_modifier_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21557 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_bid_modifier_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_bid_modifier_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1097 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_bid_modifier_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6121 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_bid_modifier_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12640 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_bid_modifier_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_budget_service/
+-rw-r--r--   0 root         (0) root         (0)      692 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_budget_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20456 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_budget_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_budget_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_budget_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6010 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_budget_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12422 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_budget_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_conversion_goal_service/
+-rw-r--r--   0 root         (0) root         (0)      708 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_conversion_goal_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21171 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_conversion_goal_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_conversion_goal_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1115 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_conversion_goal_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6160 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_conversion_goal_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12160 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_conversion_goal_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_criterion_service/
+-rw-r--r--   0 root         (0) root         (0)      698 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_criterion_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21536 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_criterion_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_criterion_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_criterion_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_criterion_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12753 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_criterion_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_customizer_service/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_customizer_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21720 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_customizer_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_customizer_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1091 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_customizer_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6092 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_customizer_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12030 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_customizer_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_draft_service/
+-rw-r--r--   0 root         (0) root         (0)      690 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_draft_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    30460 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_draft_service/client.py
+-rw-r--r--   0 root         (0) root         (0)     3579 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_draft_service/pagers.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_draft_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1061 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_draft_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7337 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_draft_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    16737 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_draft_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_extension_setting_service/
+-rw-r--r--   0 root         (0) root         (0)      712 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_extension_setting_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22687 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_extension_setting_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_extension_setting_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1127 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_extension_setting_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6208 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_extension_setting_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12958 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_extension_setting_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_feed_service/
+-rw-r--r--   0 root         (0) root         (0)      688 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_feed_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21612 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_feed_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_feed_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1055 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_feed_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5984 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_feed_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12490 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_feed_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_group_service/
+-rw-r--r--   0 root         (0) root         (0)      690 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_group_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19904 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_group_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_group_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1061 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_group_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5997 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_group_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11902 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_group_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_label_service/
+-rw-r--r--   0 root         (0) root         (0)      690 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_label_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21436 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_label_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_label_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1061 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_label_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5997 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_label_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12213 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_label_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_service/
+-rw-r--r--   0 root         (0) root         (0)      680 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    25178 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5925 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12676 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_shared_set_service/
+-rw-r--r--   0 root         (0) root         (0)      698 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_shared_set_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22049 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_shared_set_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_shared_set_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_shared_set_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6086 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_shared_set_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12573 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/campaign_shared_set_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_action_service/
+-rw-r--r--   0 root         (0) root         (0)      696 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_action_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21138 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_action_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_action_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1079 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_action_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6066 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_action_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12435 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_action_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_adjustment_upload_service/
+-rw-r--r--   0 root         (0) root         (0)      716 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_adjustment_upload_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21053 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_adjustment_upload_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_adjustment_upload_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1139 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_adjustment_upload_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6195 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_adjustment_upload_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12362 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_adjustment_upload_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_custom_variable_service/
+-rw-r--r--   0 root         (0) root         (0)      712 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_custom_variable_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21490 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_custom_variable_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_custom_variable_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1127 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_custom_variable_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6208 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_custom_variable_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12469 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_custom_variable_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_goal_campaign_config_service/
+-rw-r--r--   0 root         (0) root         (0)      720 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_goal_campaign_config_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21911 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_goal_campaign_config_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_goal_campaign_config_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1151 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_goal_campaign_config_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6267 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_goal_campaign_config_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12356 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_goal_campaign_config_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_upload_service/
+-rw-r--r--   0 root         (0) root         (0)      696 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_upload_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26513 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_upload_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_upload_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1079 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_upload_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6606 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_upload_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    13717 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_upload_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_service/
+-rw-r--r--   0 root         (0) root         (0)      702 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22738 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1097 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6121 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12079 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_set_service/
+-rw-r--r--   0 root         (0) root         (0)      708 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_set_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22528 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_set_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_set_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1115 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_set_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6189 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_set_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12195 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/conversion_value_rule_set_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:05.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_audience_service/
+-rw-r--r--   0 root         (0) root         (0)      692 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_audience_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20287 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_audience_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_audience_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_audience_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6010 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_audience_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12303 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_audience_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_conversion_goal_service/
+-rw-r--r--   0 root         (0) root         (0)      704 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_conversion_goal_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20992 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_conversion_goal_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_conversion_goal_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1103 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_conversion_goal_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6134 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_conversion_goal_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12102 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_conversion_goal_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_interest_service/
+-rw-r--r--   0 root         (0) root         (0)      692 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_interest_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20225 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_interest_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_interest_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_interest_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6010 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_interest_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12241 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/custom_interest_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_service/
+-rw-r--r--   0 root         (0) root         (0)      690 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20751 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1061 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5997 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12148 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_set_service/
+-rw-r--r--   0 root         (0) root         (0)      696 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_set_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21140 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_set_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_set_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1079 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_set_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_set_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11978 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_asset_set_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_client_link_service/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_client_link_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20992 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_client_link_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_client_link_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1091 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_client_link_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6093 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_client_link_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12363 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_client_link_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_conversion_goal_service/
+-rw-r--r--   0 root         (0) root         (0)      708 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_conversion_goal_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20454 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_conversion_goal_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_conversion_goal_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1115 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_conversion_goal_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6160 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_conversion_goal_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12160 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_conversion_goal_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_customizer_service/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_customizer_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21028 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_customizer_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_customizer_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1091 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_customizer_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6092 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_customizer_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12030 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_customizer_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_extension_setting_service/
+-rw-r--r--   0 root         (0) root         (0)      712 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_extension_setting_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21918 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_extension_setting_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_extension_setting_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1127 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_extension_setting_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6208 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_extension_setting_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12894 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_extension_setting_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_feed_service/
+-rw-r--r--   0 root         (0) root         (0)      688 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_feed_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20888 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_feed_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_feed_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1055 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_feed_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5984 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_feed_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12461 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_feed_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_label_service/
+-rw-r--r--   0 root         (0) root         (0)      690 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_label_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21131 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_label_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_label_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1061 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_label_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5997 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_label_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12155 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_label_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_manager_link_service/
+-rw-r--r--   0 root         (0) root         (0)      702 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_manager_link_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26355 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_manager_link_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_manager_link_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1097 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_manager_link_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6667 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_manager_link_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    14139 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_manager_link_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_negative_criterion_service/
+-rw-r--r--   0 root         (0) root         (0)      714 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_negative_criterion_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20765 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_negative_criterion_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_negative_criterion_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1133 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_negative_criterion_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6209 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_negative_criterion_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12470 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_negative_criterion_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_service/
+-rw-r--r--   0 root         (0) root         (0)      680 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26949 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7023 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    15180 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_invitation_service/
+-rw-r--r--   0 root         (0) root         (0)      720 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_invitation_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20715 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_invitation_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_invitation_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1151 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_invitation_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6261 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_invitation_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12535 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_invitation_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_service/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20280 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1091 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6093 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12330 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customer_user_access_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customizer_attribute_service/
+-rw-r--r--   0 root         (0) root         (0)      702 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customizer_attribute_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20320 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customizer_attribute_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customizer_attribute_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1097 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customizer_attribute_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6105 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customizer_attribute_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12055 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/customizer_attribute_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_arm_service/
+-rw-r--r--   0 root         (0) root         (0)      690 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_arm_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21375 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_arm_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_arm_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1061 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_arm_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5997 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_arm_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12115 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_arm_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_service/
+-rw-r--r--   0 root         (0) root         (0)      684 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    42557 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_service/client.py
+-rw-r--r--   0 root         (0) root         (0)     3518 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_service/pagers.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1043 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8578 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    21152 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/experiment_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/extension_feed_item_service/
+-rw-r--r--   0 root         (0) root         (0)      698 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/extension_feed_item_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    23071 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/extension_feed_item_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/extension_feed_item_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/extension_feed_item_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6086 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/extension_feed_item_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12643 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/extension_feed_item_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:06.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_service/
+-rw-r--r--   0 root         (0) root         (0)      680 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20770 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5932 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12389 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_link_service/
+-rw-r--r--   0 root         (0) root         (0)      694 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_link_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21859 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_link_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_link_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_link_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_link_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12114 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_link_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_service/
+-rw-r--r--   0 root         (0) root         (0)      686 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20594 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1049 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5978 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_set_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_target_service/
+-rw-r--r--   0 root         (0) root         (0)      692 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_target_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    23260 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_target_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_target_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_target_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6017 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_target_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12423 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_item_target_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_mapping_service/
+-rw-r--r--   0 root         (0) root         (0)      686 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_mapping_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20867 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_mapping_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_mapping_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1049 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_mapping_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5971 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_mapping_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12323 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_mapping_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_service/
+-rw-r--r--   0 root         (0) root         (0)      672 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19847 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1007 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5873 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12267 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/feed_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/geo_target_constant_service/
+-rw-r--r--   0 root         (0) root         (0)      698 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/geo_target_constant_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    18433 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/geo_target_constant_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/geo_target_constant_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/geo_target_constant_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6092 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/geo_target_constant_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12244 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/geo_target_constant_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_field_service/
+-rw-r--r--   0 root         (0) root         (0)      692 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_field_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    23189 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_field_service/client.py
+-rw-r--r--   0 root         (0) root         (0)     3564 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_field_service/pagers.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_field_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_field_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6622 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_field_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    13597 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_field_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_service/
+-rw-r--r--   0 root         (0) root         (0)      682 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)   149138 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_service/client.py
+-rw-r--r--   0 root         (0) root         (0)     3276 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_service/pagers.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1037 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6853 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    18934 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/google_ads_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/invoice_service/
+-rw-r--r--   0 root         (0) root         (0)      678 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/invoice_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20835 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/invoice_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/invoice_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1025 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/invoice_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5900 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/invoice_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    11965 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/invoice_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_keyword_service/
+-rw-r--r--   0 root         (0) root         (0)      714 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_keyword_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22248 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_keyword_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_keyword_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1133 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_keyword_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6235 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_keyword_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12980 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_keyword_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_service/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21507 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1091 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6115 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12483 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_ad_group_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_keyword_service/
+-rw-r--r--   0 root         (0) root         (0)      716 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_keyword_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22183 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_keyword_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_keyword_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1139 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_keyword_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6241 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_keyword_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12919 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_keyword_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_service/
+-rw-r--r--   0 root         (0) root         (0)      702 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    22507 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1097 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6121 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12509 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_campaign_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_idea_service/
+-rw-r--r--   0 root         (0) root         (0)      694 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_idea_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    24370 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_idea_service/client.py
+-rw-r--r--   0 root         (0) root         (0)     3495 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_idea_service/pagers.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_idea_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_idea_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7267 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_idea_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    15490 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_idea_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_service/
+-rw-r--r--   0 root         (0) root         (0)      686 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    35756 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1049 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8284 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    19115 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_plan_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_theme_constant_service/
+-rw-r--r--   0 root         (0) root         (0)      704 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_theme_constant_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    18795 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_theme_constant_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_theme_constant_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1103 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_theme_constant_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6140 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_theme_constant_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12273 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/keyword_theme_constant_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/label_service/
+-rw-r--r--   0 root         (0) root         (0)      674 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/label_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19854 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/label_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/label_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1013 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/label_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5886 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/label_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12257 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/label_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/media_file_service/
+-rw-r--r--   0 root         (0) root         (0)      682 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/media_file_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20082 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/media_file_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/media_file_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1037 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/media_file_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5945 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/media_file_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12290 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/media_file_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/merchant_center_link_service/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/merchant_center_link_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    27901 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/merchant_center_link_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/merchant_center_link_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1091 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/merchant_center_link_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7368 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/merchant_center_link_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    15453 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/merchant_center_link_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:07.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/offline_user_data_job_service/
+-rw-r--r--   0 root         (0) root         (0)      700 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/offline_user_data_job_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    29949 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/offline_user_data_job_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/offline_user_data_job_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1091 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/offline_user_data_job_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7508 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/offline_user_data_job_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    16517 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/offline_user_data_job_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/payments_account_service/
+-rw-r--r--   0 root         (0) root         (0)      694 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/payments_account_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20198 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/payments_account_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/payments_account_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/payments_account_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6011 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/payments_account_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12272 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/payments_account_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/reach_plan_service/
+-rw-r--r--   0 root         (0) root         (0)      682 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/reach_plan_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    25901 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/reach_plan_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/reach_plan_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1037 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/reach_plan_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7091 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/reach_plan_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    15495 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/reach_plan_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/recommendation_service/
+-rw-r--r--   0 root         (0) root         (0)      692 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/recommendation_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    25428 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/recommendation_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/recommendation_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1067 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/recommendation_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6555 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/recommendation_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    13693 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/recommendation_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/remarketing_action_service/
+-rw-r--r--   0 root         (0) root         (0)      698 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/remarketing_action_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20399 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/remarketing_action_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/remarketing_action_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/remarketing_action_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6079 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/remarketing_action_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12208 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/remarketing_action_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_criterion_service/
+-rw-r--r--   0 root         (0) root         (0)      694 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_criterion_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21234 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_criterion_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_criterion_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_criterion_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6011 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_criterion_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12445 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_criterion_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_set_service/
+-rw-r--r--   0 root         (0) root         (0)      682 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_set_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20176 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_set_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_set_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1037 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_set_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5945 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_set_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12382 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/shared_set_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_setting_service/
+-rw-r--r--   0 root         (0) root         (0)      704 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_setting_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20783 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_setting_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_setting_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1103 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_setting_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6134 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_setting_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12056 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_setting_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_suggest_service/
+-rw-r--r--   0 root         (0) root         (0)      704 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_suggest_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    24911 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_suggest_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_suggest_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1103 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_suggest_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7440 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_suggest_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    15038 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/smart_campaign_suggest_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/third_party_app_analytics_link_service/
+-rw-r--r--   0 root         (0) root         (0)      716 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/third_party_app_analytics_link_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    19335 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/third_party_app_analytics_link_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/third_party_app_analytics_link_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1139 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/third_party_app_analytics_link_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6194 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/third_party_app_analytics_link_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12472 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/third_party_app_analytics_link_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_data_service/
+-rw-r--r--   0 root         (0) root         (0)      680 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_data_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    18209 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_data_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_data_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_data_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5926 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_data_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12370 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_data_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_list_service/
+-rw-r--r--   0 root         (0) root         (0)      680 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_list_service/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20047 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_list_service/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:08.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_list_service/transports/
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_list_service/transports/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5932 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_list_service/transports/base.py
+-rw-r--r--   0 root         (0) root         (0)    12287 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/services/user_list_service/transports/grpc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:09.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4923 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/account_budget_proposal_service.py
+-rw-r--r--   0 root         (0) root         (0)     6039 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/account_link_service.py
+-rw-r--r--   0 root         (0) root         (0)     4777 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_ad_label_service.py
+-rw-r--r--   0 root         (0) root         (0)     6684 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_ad_service.py
+-rw-r--r--   0 root         (0) root         (0)     6474 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_asset_service.py
+-rw-r--r--   0 root         (0) root         (0)     5864 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_asset_set_service.py
+-rw-r--r--   0 root         (0) root         (0)     6713 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_bid_modifier_service.py
+-rw-r--r--   0 root         (0) root         (0)     6304 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_criterion_customizer_service.py
+-rw-r--r--   0 root         (0) root         (0)     4974 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_criterion_label_service.py
+-rw-r--r--   0 root         (0) root         (0)     7400 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_criterion_service.py
+-rw-r--r--   0 root         (0) root         (0)     5941 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_customizer_service.py
+-rw-r--r--   0 root         (0) root         (0)     6937 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_extension_setting_service.py
+-rw-r--r--   0 root         (0) root         (0)     6421 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_feed_service.py
+-rw-r--r--   0 root         (0) root         (0)     4704 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_label_service.py
+-rw-r--r--   0 root         (0) root         (0)     6226 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_group_service.py
+-rw-r--r--   0 root         (0) root         (0)     6450 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_parameter_service.py
+-rw-r--r--   0 root         (0) root         (0)     5891 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/ad_service.py
+-rw-r--r--   0 root         (0) root         (0)     5546 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/asset_group_asset_service.py
+-rw-r--r--   0 root         (0) root         (0)     6596 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/asset_group_listing_group_filter_service.py
+-rw-r--r--   0 root         (0) root         (0)     4990 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/asset_group_service.py
+-rw-r--r--   0 root         (0) root         (0)     5894 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/asset_group_signal_service.py
+-rw-r--r--   0 root         (0) root         (0)     5976 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/asset_service.py
+-rw-r--r--   0 root         (0) root         (0)     5768 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/asset_set_asset_service.py
+-rw-r--r--   0 root         (0) root         (0)     6256 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/asset_set_service.py
+-rw-r--r--   0 root         (0) root         (0)    30535 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/audience_insights_service.py
+-rw-r--r--   0 root         (0) root         (0)     5909 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/audience_service.py
+-rw-r--r--   0 root         (0) root         (0)     9858 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/batch_job_service.py
+-rw-r--r--   0 root         (0) root         (0)     6716 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/bidding_data_exclusion_service.py
+-rw-r--r--   0 root         (0) root         (0)     7069 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/bidding_seasonality_adjustment_service.py
+-rw-r--r--   0 root         (0) root         (0)     6564 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/bidding_strategy_service.py
+-rw-r--r--   0 root         (0) root         (0)     3638 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/billing_setup_service.py
+-rw-r--r--   0 root         (0) root         (0)     6495 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_asset_service.py
+-rw-r--r--   0 root         (0) root         (0)     5891 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_asset_set_service.py
+-rw-r--r--   0 root         (0) root         (0)     6735 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_bid_modifier_service.py
+-rw-r--r--   0 root         (0) root         (0)     6488 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_budget_service.py
+-rw-r--r--   0 root         (0) root         (0)     3835 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_conversion_goal_service.py
+-rw-r--r--   0 root         (0) root         (0)     6584 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_criterion_service.py
+-rw-r--r--   0 root         (0) root         (0)     5963 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_customizer_service.py
+-rw-r--r--   0 root         (0) root         (0)     9221 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_draft_service.py
+-rw-r--r--   0 root         (0) root         (0)     6961 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_extension_setting_service.py
+-rw-r--r--   0 root         (0) root         (0)     6442 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_feed_service.py
+-rw-r--r--   0 root         (0) root         (0)     6485 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_group_service.py
+-rw-r--r--   0 root         (0) root         (0)     4801 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_label_service.py
+-rw-r--r--   0 root         (0) root         (0)     6245 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_service.py
+-rw-r--r--   0 root         (0) root         (0)     5933 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/campaign_shared_set_service.py
+-rw-r--r--   0 root         (0) root         (0)     6723 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/conversion_action_service.py
+-rw-r--r--   0 root         (0) root         (0)    12121 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/conversion_adjustment_upload_service.py
+-rw-r--r--   0 root         (0) root         (0)     6704 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/conversion_custom_variable_service.py
+-rw-r--r--   0 root         (0) root         (0)     5076 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/conversion_goal_campaign_config_service.py
+-rw-r--r--   0 root         (0) root         (0)    22236 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/conversion_upload_service.py
+-rw-r--r--   0 root         (0) root         (0)     6868 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/conversion_value_rule_service.py
+-rw-r--r--   0 root         (0) root         (0)     7013 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/conversion_value_rule_set_service.py
+-rw-r--r--   0 root         (0) root         (0)     4583 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/custom_audience_service.py
+-rw-r--r--   0 root         (0) root         (0)     5903 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/custom_conversion_goal_service.py
+-rw-r--r--   0 root         (0) root         (0)     4232 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/custom_interest_service.py
+-rw-r--r--   0 root         (0) root         (0)     6481 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_asset_service.py
+-rw-r--r--   0 root         (0) root         (0)     5869 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_asset_set_service.py
+-rw-r--r--   0 root         (0) root         (0)     4325 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_client_link_service.py
+-rw-r--r--   0 root         (0) root         (0)     3835 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_conversion_goal_service.py
+-rw-r--r--   0 root         (0) root         (0)     5951 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_customizer_service.py
+-rw-r--r--   0 root         (0) root         (0)     6945 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_extension_setting_service.py
+-rw-r--r--   0 root         (0) root         (0)     6428 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_feed_service.py
+-rw-r--r--   0 root         (0) root         (0)     4787 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_label_service.py
+-rw-r--r--   0 root         (0) root         (0)     5755 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_manager_link_service.py
+-rw-r--r--   0 root         (0) root         (0)     6073 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_negative_criterion_service.py
+-rw-r--r--   0 root         (0) root         (0)     7195 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_service.py
+-rw-r--r--   0 root         (0) root         (0)     3842 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_user_access_invitation_service.py
+-rw-r--r--   0 root         (0) root         (0)     3998 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customer_user_access_service.py
+-rw-r--r--   0 root         (0) root         (0)     6309 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/customizer_attribute_service.py
+-rw-r--r--   0 root         (0) root         (0)     6376 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/experiment_arm_service.py
+-rw-r--r--   0 root         (0) root         (0)    11413 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/experiment_service.py
+-rw-r--r--   0 root         (0) root         (0)     6662 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/extension_feed_item_service.py
+-rw-r--r--   0 root         (0) root         (0)     6276 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/feed_item_service.py
+-rw-r--r--   0 root         (0) root         (0)     4847 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/feed_item_set_link_service.py
+-rw-r--r--   0 root         (0) root         (0)     5398 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/feed_item_set_service.py
+-rw-r--r--   0 root         (0) root         (0)     5850 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/feed_item_target_service.py
+-rw-r--r--   0 root         (0) root         (0)     5686 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/feed_mapping_service.py
+-rw-r--r--   0 root         (0) root         (0)     6027 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/feed_service.py
+-rw-r--r--   0 root         (0) root         (0)     5934 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/geo_target_constant_service.py
+-rw-r--r--   0 root         (0) root         (0)     3490 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/google_ads_field_service.py
+-rw-r--r--   0 root         (0) root         (0)   146398 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/google_ads_service.py
+-rw-r--r--   0 root         (0) root         (0)     2632 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/invoice_service.py
+-rw-r--r--   0 root         (0) root         (0)     5948 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/keyword_plan_ad_group_keyword_service.py
+-rw-r--r--   0 root         (0) root         (0)     5761 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/keyword_plan_ad_group_service.py
+-rw-r--r--   0 root         (0) root         (0)     5926 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/keyword_plan_campaign_keyword_service.py
+-rw-r--r--   0 root         (0) root         (0)     5674 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/keyword_plan_campaign_service.py
+-rw-r--r--   0 root         (0) root         (0)    19940 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/keyword_plan_idea_service.py
+-rw-r--r--   0 root         (0) root         (0)    19732 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/keyword_plan_service.py
+-rw-r--r--   0 root         (0) root         (0)     2638 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/keyword_theme_constant_service.py
+-rw-r--r--   0 root         (0) root         (0)     6043 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/label_service.py
+-rw-r--r--   0 root         (0) root         (0)     5063 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/media_file_service.py
+-rw-r--r--   0 root         (0) root         (0)     5770 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/merchant_center_link_service.py
+-rw-r--r--   0 root         (0) root         (0)     7756 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/offline_user_data_job_service.py
+-rw-r--r--   0 root         (0) root         (0)     1846 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/payments_account_service.py
+-rw-r--r--   0 root         (0) root         (0)    35934 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/reach_plan_service.py
+-rw-r--r--   0 root         (0) root         (0)    23652 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/recommendation_service.py
+-rw-r--r--   0 root         (0) root         (0)     5219 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/remarketing_action_service.py
+-rw-r--r--   0 root         (0) root         (0)     5812 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/shared_criterion_service.py
+-rw-r--r--   0 root         (0) root         (0)     6314 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/shared_set_service.py
+-rw-r--r--   0 root         (0) root         (0)     5463 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/smart_campaign_setting_service.py
+-rw-r--r--   0 root         (0) root         (0)    13397 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/smart_campaign_suggest_service.py
+-rw-r--r--   0 root         (0) root         (0)     1626 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/third_party_app_analytics_link_service.py
+-rw-r--r--   0 root         (0) root         (0)     4388 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/user_data_service.py
+-rw-r--r--   0 root         (0) root         (0)     5234 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/services/types/user_list_service.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:09.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/types/
+-rw-r--r--   0 root         (0) root         (0)      600 2023-04-08 17:35:36.000000 apache-airflow-providers-google-9.0.0rc1/airflow/providers/google_vendor/googleads/v12/types/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-09 13:49:09.000000 apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/
+-rw-r--r--   0 root         (0) root         (0)    75675 2023-04-09 13:48:52.000000 apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)   137926 2023-04-09 13:48:52.000000 apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2023-04-09 13:48:52.000000 apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)      103 2023-04-09 13:48:52.000000 apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/entry_points.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2023-04-09 13:48:52.000000 apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/not-zip-safe
+-rw-r--r--   0 root         (0) root         (0)     2542 2023-04-09 13:48:52.000000 apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)        8 2023-04-09 13:48:52.000000 apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/top_level.txt
+-rw-r--r--   0 root         (0) root         (0)     5246 2023-04-07 12:28:58.000000 apache-airflow-providers-google-9.0.0rc1/pyproject.toml
+-rw-r--r--   0 root         (0) root         (0)     3578 2023-04-09 13:49:09.000000 apache-airflow-providers-google-9.0.0rc1/setup.cfg
+-rw-r--r--   0 root         (0) root         (0)     2761 2023-04-09 13:48:30.000000 apache-airflow-providers-google-9.0.0rc1/setup.py
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/LICENSE` & `apache-airflow-providers-google-9.0.0rc1/LICENSE`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/MANIFEST.in` & `apache-airflow-providers-google-9.0.0rc1/MANIFEST.in`

 * *Files 23% similar despite different names*

```diff
@@ -20,16 +20,12 @@
 # OVERWRITTEN WHEN PREPARING PACKAGES.
 
 # IF YOU WANT TO MODIFY IT, YOU SHOULD MODIFY THE TEMPLATE
 # `MANIFEST_TEMPLATE.py.jinja2` IN the `provider_packages` DIRECTORY
 
 
 
-include airflow/providers/google/cloud/example_dags/*.yaml
-include airflow/providers/google/cloud/example_dags/*.sql
-
 
 include NOTICE
 include LICENSE
-include CHANGELOG.txt
-include README.md
+include CHANGELOG.rst
 global-exclude __pycache__  *.pyc
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/PKG-INFO` & `apache-airflow-providers-google-9.0.0rc1/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,23 +1,22 @@
 Metadata-Version: 2.1
 Name: apache-airflow-providers-google
-Version: 8.9.0rc1
+Version: 9.0.0rc1
 Summary: Provider for Apache Airflow. Implements apache-airflow-providers-google package
 Home-page: https://airflow.apache.org/
+Download-URL: https://archive.apache.org/dist/airflow/providers
 Author: Apache Software Foundation
 Author-email: dev@airflow.apache.org
 License: Apache License 2.0
-Download-URL: https://archive.apache.org/dist/airflow/providers
-Project-URL: Documentation, https://airflow.apache.org/docs/apache-airflow-providers-google/8.9.0/
+Project-URL: Documentation, https://airflow.apache.org/docs/apache-airflow-providers-google/9.0.0/
 Project-URL: Bug Tracker, https://github.com/apache/airflow/issues
 Project-URL: Source Code, https://github.com/apache/airflow
 Project-URL: Slack Chat, https://s.apache.org/airflow-slack
 Project-URL: Twitter, https://twitter.com/ApacheAirflow
 Project-URL: YouTube, https://www.youtube.com/channel/UCSXwxpWZQ7XZ1WL3wqevChA/
-Platform: UNKNOWN
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Environment :: Console
 Classifier: Environment :: Web Environment
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: System Administrators
 Classifier: Framework :: Apache Airflow
 Classifier: Framework :: Apache Airflow :: Provider
@@ -66,15 +65,15 @@
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.
 
 
 Package ``apache-airflow-providers-google``
 
-Release: ``8.9.0rc1``
+Release: ``9.0.0rc1``
 
 
 Google services including:
 
   - `Google Ads <https://ads.google.com/>`__
   - `Google Cloud (GCP) <https://cloud.google.com/>`__
   - `Google Firebase <https://firebase.google.com/>`__
@@ -86,58 +85,64 @@
 Provider package
 ----------------
 
 This is a provider package for ``google`` provider. All classes for this provider package
 are in ``airflow.providers.google`` python package.
 
 You can find package information and changelog for the provider
-in the `documentation <https://airflow.apache.org/docs/apache-airflow-providers-google/8.9.0/>`_.
+in the `documentation <https://airflow.apache.org/docs/apache-airflow-providers-google/9.0.0/>`_.
 
 
 Installation
 ------------
 
 You can install this package on top of an existing Airflow 2 installation (see ``Requirements`` below
 for the minimum Airflow version supported) via
 ``pip install apache-airflow-providers-google``
 
 The package supports the following python versions: 3.7,3.8,3.9,3.10
 
 Requirements
 ------------
 
-=======================================  ===================
+=======================================  ======================================
 PIP package                              Version required
-=======================================  ===================
+=======================================  ======================================
 ``apache-airflow``                       ``>=2.3.0``
 ``apache-airflow-providers-common-sql``  ``>=1.3.1``
 ``PyOpenSSL``
 ``asgiref``                              ``>=3.5.2``
 ``gcloud-aio-auth``                      ``>=4.0.0,<5.0.0``
 ``gcloud-aio-bigquery``                  ``>=6.1.2``
 ``gcloud-aio-storage``
-``google-ads``                           ``>=15.1.1``
-``google-api-core``                      ``>=2.7.0,<3.0.0``
+``googleapis-common-protos``             ``<2.0.0,>=1.5.8``
+``google-api-core``                      ``==2.8.2``
+``google-auth-oauthlib``                 ``<1.0.0,>=0.3.0``
+``grpcio``                               ``<2.0.0,>=1.38.1``
+``grpcio-status``                        ``<2.0.0,>=1.38.1``
+``PyYAML``                               ``<7.0,>=5.1``
+``proto-plus``                           ``==1.19.6``
+``protobuf!``                            ``=3.18.*,!=3.19.*,<=3.20.0,>=3.12.0``
 ``google-api-python-client``             ``>=1.6.0,<2.0.0``
 ``google-auth``                          ``>=1.0.0``
 ``google-auth-httplib2``                 ``>=0.0.1``
 ``google-cloud-aiplatform``              ``>=1.7.1,<2.0.0``
 ``google-cloud-automl``                  ``>=2.1.0``
 ``google-cloud-bigquery-datatransfer``   ``>=3.0.0``
-``google-cloud-bigtable``                ``>=1.0.0,<2.0.0``
+``google-cloud-bigtable``                ``>=2.0.0,<3.0.0``
 ``google-cloud-build``                   ``>=3.0.0``
 ``google-cloud-compute``                 ``>=0.1.0,<2.0.0``
 ``google-cloud-container``               ``>=2.2.0,<3.0.0``
-``google-cloud-dataflow-client``         ``>=0.5.2,<0.5.5``
+``google-cloud-dataflow-client``         ``>=0.5.2``
 ``google-cloud-dataform``                ``>=0.2.0``
 ``google-cloud-datacatalog``             ``>=3.0.0``
 ``google-cloud-dataplex``                ``>=0.1.0``
 ``google-cloud-dataproc``                ``>=3.1.0``
 ``google-cloud-dataproc-metastore``      ``>=1.2.0,<2.0.0``
-``google-cloud-dlp``                     ``>=0.11.0,<2.0.0``
+``google-cloud-dlp``                     ``>=3.0.0``
 ``google-cloud-kms``                     ``>=2.0.0``
 ``google-cloud-language``                ``>=1.1.1,<2.0.0``
 ``google-cloud-logging``                 ``>=2.1.1``
 ``google-cloud-memcache``                ``>=0.2.0``
 ``google-cloud-monitoring``              ``>=2.0.0``
 ``google-cloud-os-login``                ``>=2.0.0``
 ``google-cloud-orchestration-airflow``   ``>=1.0.0,<2.0.0``
@@ -156,17 +161,15 @@
 ``grpcio-gcp``                           ``>=0.2.2``
 ``httpx``
 ``json-merge-patch``                     ``>=0.2``
 ``looker-sdk``                           ``>=22.2.0``
 ``pandas-gbq``
 ``pandas``                               ``>=0.17.1``
 ``sqlalchemy-bigquery``                  ``>=1.2.1``
-``proto-plus``                           ``>=1.19.6``
-``protobuf``                             ``<=3.20.0``
-=======================================  ===================
+=======================================  ======================================
 
 Cross provider package dependencies
 -----------------------------------
 
 Those are dependencies that might be needed in order to use all the features of the package.
 You need to install the specified provider packages in order to use them.
 
@@ -219,14 +222,146 @@
    Please, only add notes to the Changelog just below the "Changelog" header when there are some breaking changes
    and you want to add an explanation to the users on how they are supposed to deal with them.
    The changelog is updated and maintained semi-automatically by release manager.
 
 Changelog
 ---------
 
+9.0.0
+.....
+
+Breaking changes
+~~~~~~~~~~~~~~~~
+
+Google  announced sunset of Bid manager API v1 and v1.1 by April 27, 2023 for more information
+please check: `docs <https://developers.google.com/bid-manager/v1.1>`_  As a result default value of api_version
+in GoogleDisplayVideo360Hook and related operators updated to v2
+
+This version of provider contains a temporary workaround to issue with ``v11`` version of
+google-ads API being discontinued, while the google provider dependencies preventing installing
+any google-ads client supporting ``v12`` API. This version contains vendored-in version of google-ads
+library ``20.0.0`` v12 support only. The workaround (and vendored-in library) will be removed
+as soon as dependencies of the provider will allow to use google-ads supporting newer
+API versions of google-ads.
+
+.. note::
+
+  ONLY v12 version of google ads is supported. You should set v12 when your create an operator or client.
+
+* ``Update DV360 operators to use API v2 (#30326)``
+* ``Fix dynamic imports in google ads vendored in library (#30544)``
+
+Features
+~~~~~~~~
+
+* ``Add deferrable mode to GKEStartPodOperator (#29266)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``BigQueryHook list_rows/get_datasets_list can return iterator (#30543)``
+* ``Fix cloud build async credentials (#30441)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``Add mechanism to suspend providers (#30422)``
+   * ``Small quotation fix (#30448)``
+
+8.12.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add missing 'poll_interval' in Bigquery operator (#30132)``
+* ``Add poll_interval param in BigQueryInsertJobOperator (#30091)``
+* ``Add 'job_id' to 'BigQueryToGCSOperator' templated_fields (#30006)``
+* ``Support deleting the local log files when using remote logging (#29772)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``fix setting project_id for gs to bq and bq to gs (#30053)``
+* ``Fix location on cloud build operators (#29937)``
+* ``'GoogleDriveHook': Fixing log message + adding more verbose documentation (#29694)``
+* ``Add "BOOLEAN" to type_map of MSSQLToGCSOperator, fix incorrect bit->int type conversion by specifying BIT fields explicitly (#29902)``
+* ``Google Cloud Providers - Fix _MethodDefault deepcopy failure (#29518)``
+* ``Handling project location param on async BigQuery dts trigger (#29786)``
+* ``Support CloudDataTransferServiceJobStatusSensor without specifying a project_id (#30035)``
+* ``Wait insert_job result in normal mode (#29925)``
+
+Misc
+~~~~
+
+* ``merge BigQueryTableExistenceAsyncSensor into BigQueryTableExistenceSensor (#30235)``
+* ``Remove  unnecessary upper constraints from google provider (#29915)``
+* ``Merge BigQueryTableExistencePartitionAsyncSensor into BigQueryTableExistencePartitionSensor (#30231)``
+* ``Merge GCSObjectExistenceAsyncSensor logic to GCSObjectExistenceSensor (#30014)``
+* ``Align cncf provider file names with AIP-21 (#29905)``
+* ``Switch to using vendored-in google ads. (#30410)``
+* ``Merging of the google ads vendored-in code. (#30399)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``adding trigger info to provider yaml (#29950)``
+
+8.11.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add deferrable mode to BigQueryTablePartitionExistenceSensor. (#29735)``
+* ``Add a new param for BigQuery operators to support additional actions when resource exists (#29394)``
+* ``Add deferrable mode to DataprocInstantiateWorkflowTemplateOperator (#28618)``
+* ``Dataproc batches (#29136)``
+* ``Add 'CloudSQLCloneInstanceOperator' (#29726)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``Fix 'NoneType' object is not subscriptable. (#29820)``
+* ``Fix and augment 'check-for-inclusive-language' CI check (#29549)``
+* ``Don't push secret in XCOM in BigQueryCreateDataTransferOperator (#29348)``
+
+Misc
+~~~~
+
+* ``Google Cloud Providers - Introduce GoogleCloudBaseOperator (#29680)``
+* ``Update google cloud dlp package and adjust hook and operators (#29234)``
+* ``Refactor Dataproc Trigger (#29364)``
+* ``Remove <2.0.0 limit on google-cloud-bigtable (#29644)``
+* ``Move help message to the google auth code (#29888)``
+
+8.10.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add defer mode to GKECreateClusterOperator and GKEDeleteClusterOperator (#28406)``
+
+Bug Fixes
+~~~~~~~~~
+* ``Move cloud_sql_binary_path from connection to Hook (#29499)``
+* ``Check that cloud sql provider version is valid (#29497)``
+* ``'GoogleDriveHook': Add folder_id param to upload_file (#29477)``
+
+Misc
+~~~~
+* ``Add documentation for BigQuery transfer operators (#29466)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``Upgrade Mypy to 1.0 (#29468)``
+   * ``Restore trigger logging (#29482)``
+   * ``Revert "Enable individual trigger logging (#27758)" (#29472)``
+   * ``Revert "Upgrade mypy to 0.991 (#28926)" (#29470)``
+   * ``Upgrade mypy to 0.991 (#28926)``
+
 8.9.0
 .....
 
 Features
 ~~~~~~~~
 
 * ``Add deferrable capability to existing ''DataprocDeleteClusterOperator'' (#29349)``
@@ -1464,9 +1599,7 @@
 * ``Fix Data Catalog operators (#13096)``
 
 
 1.0.0
 .....
 
 Initial version of the provider.
-
-
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/README.rst` & `apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,7 +1,57 @@
+Metadata-Version: 2.1
+Name: apache-airflow-providers-google
+Version: 9.0.0rc1
+Summary: Provider for Apache Airflow. Implements apache-airflow-providers-google package
+Home-page: https://airflow.apache.org/
+Download-URL: https://archive.apache.org/dist/airflow/providers
+Author: Apache Software Foundation
+Author-email: dev@airflow.apache.org
+License: Apache License 2.0
+Project-URL: Documentation, https://airflow.apache.org/docs/apache-airflow-providers-google/9.0.0/
+Project-URL: Bug Tracker, https://github.com/apache/airflow/issues
+Project-URL: Source Code, https://github.com/apache/airflow
+Project-URL: Slack Chat, https://s.apache.org/airflow-slack
+Project-URL: Twitter, https://twitter.com/ApacheAirflow
+Project-URL: YouTube, https://www.youtube.com/channel/UCSXwxpWZQ7XZ1WL3wqevChA/
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Environment :: Console
+Classifier: Environment :: Web Environment
+Classifier: Intended Audience :: Developers
+Classifier: Intended Audience :: System Administrators
+Classifier: Framework :: Apache Airflow
+Classifier: Framework :: Apache Airflow :: Provider
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Topic :: System :: Monitoring
+Requires-Python: ~=3.7
+Description-Content-Type: text/x-rst
+Provides-Extra: amazon
+Provides-Extra: apache.beam
+Provides-Extra: apache.cassandra
+Provides-Extra: cncf.kubernetes
+Provides-Extra: common.sql
+Provides-Extra: facebook
+Provides-Extra: microsoft.azure
+Provides-Extra: microsoft.mssql
+Provides-Extra: mysql
+Provides-Extra: oracle
+Provides-Extra: postgres
+Provides-Extra: presto
+Provides-Extra: salesforce
+Provides-Extra: sftp
+Provides-Extra: ssh
+Provides-Extra: trino
+Provides-Extra: leveldb
+License-File: LICENSE
+License-File: NOTICE
+
 
 .. Licensed to the Apache Software Foundation (ASF) under one
    or more contributor license agreements.  See the NOTICE file
    distributed with this work for additional information
    regarding copyright ownership.  The ASF licenses this file
    to you under the Apache License, Version 2.0 (the
    "License"); you may not use this file except in compliance
@@ -15,15 +65,15 @@
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.
 
 
 Package ``apache-airflow-providers-google``
 
-Release: ``8.9.0rc1``
+Release: ``9.0.0rc1``
 
 
 Google services including:
 
   - `Google Ads <https://ads.google.com/>`__
   - `Google Cloud (GCP) <https://cloud.google.com/>`__
   - `Google Firebase <https://firebase.google.com/>`__
@@ -35,58 +85,64 @@
 Provider package
 ----------------
 
 This is a provider package for ``google`` provider. All classes for this provider package
 are in ``airflow.providers.google`` python package.
 
 You can find package information and changelog for the provider
-in the `documentation <https://airflow.apache.org/docs/apache-airflow-providers-google/8.9.0/>`_.
+in the `documentation <https://airflow.apache.org/docs/apache-airflow-providers-google/9.0.0/>`_.
 
 
 Installation
 ------------
 
 You can install this package on top of an existing Airflow 2 installation (see ``Requirements`` below
 for the minimum Airflow version supported) via
 ``pip install apache-airflow-providers-google``
 
 The package supports the following python versions: 3.7,3.8,3.9,3.10
 
 Requirements
 ------------
 
-=======================================  ===================
+=======================================  ======================================
 PIP package                              Version required
-=======================================  ===================
+=======================================  ======================================
 ``apache-airflow``                       ``>=2.3.0``
 ``apache-airflow-providers-common-sql``  ``>=1.3.1``
 ``PyOpenSSL``
 ``asgiref``                              ``>=3.5.2``
 ``gcloud-aio-auth``                      ``>=4.0.0,<5.0.0``
 ``gcloud-aio-bigquery``                  ``>=6.1.2``
 ``gcloud-aio-storage``
-``google-ads``                           ``>=15.1.1``
-``google-api-core``                      ``>=2.7.0,<3.0.0``
+``googleapis-common-protos``             ``<2.0.0,>=1.5.8``
+``google-api-core``                      ``==2.8.2``
+``google-auth-oauthlib``                 ``<1.0.0,>=0.3.0``
+``grpcio``                               ``<2.0.0,>=1.38.1``
+``grpcio-status``                        ``<2.0.0,>=1.38.1``
+``PyYAML``                               ``<7.0,>=5.1``
+``proto-plus``                           ``==1.19.6``
+``protobuf!``                            ``=3.18.*,!=3.19.*,<=3.20.0,>=3.12.0``
 ``google-api-python-client``             ``>=1.6.0,<2.0.0``
 ``google-auth``                          ``>=1.0.0``
 ``google-auth-httplib2``                 ``>=0.0.1``
 ``google-cloud-aiplatform``              ``>=1.7.1,<2.0.0``
 ``google-cloud-automl``                  ``>=2.1.0``
 ``google-cloud-bigquery-datatransfer``   ``>=3.0.0``
-``google-cloud-bigtable``                ``>=1.0.0,<2.0.0``
+``google-cloud-bigtable``                ``>=2.0.0,<3.0.0``
 ``google-cloud-build``                   ``>=3.0.0``
 ``google-cloud-compute``                 ``>=0.1.0,<2.0.0``
 ``google-cloud-container``               ``>=2.2.0,<3.0.0``
-``google-cloud-dataflow-client``         ``>=0.5.2,<0.5.5``
+``google-cloud-dataflow-client``         ``>=0.5.2``
 ``google-cloud-dataform``                ``>=0.2.0``
 ``google-cloud-datacatalog``             ``>=3.0.0``
 ``google-cloud-dataplex``                ``>=0.1.0``
 ``google-cloud-dataproc``                ``>=3.1.0``
 ``google-cloud-dataproc-metastore``      ``>=1.2.0,<2.0.0``
-``google-cloud-dlp``                     ``>=0.11.0,<2.0.0``
+``google-cloud-dlp``                     ``>=3.0.0``
 ``google-cloud-kms``                     ``>=2.0.0``
 ``google-cloud-language``                ``>=1.1.1,<2.0.0``
 ``google-cloud-logging``                 ``>=2.1.1``
 ``google-cloud-memcache``                ``>=0.2.0``
 ``google-cloud-monitoring``              ``>=2.0.0``
 ``google-cloud-os-login``                ``>=2.0.0``
 ``google-cloud-orchestration-airflow``   ``>=1.0.0,<2.0.0``
@@ -105,17 +161,15 @@
 ``grpcio-gcp``                           ``>=0.2.2``
 ``httpx``
 ``json-merge-patch``                     ``>=0.2``
 ``looker-sdk``                           ``>=22.2.0``
 ``pandas-gbq``
 ``pandas``                               ``>=0.17.1``
 ``sqlalchemy-bigquery``                  ``>=1.2.1``
-``proto-plus``                           ``>=1.19.6``
-``protobuf``                             ``<=3.20.0``
-=======================================  ===================
+=======================================  ======================================
 
 Cross provider package dependencies
 -----------------------------------
 
 Those are dependencies that might be needed in order to use all the features of the package.
 You need to install the specified provider packages in order to use them.
 
@@ -168,14 +222,146 @@
    Please, only add notes to the Changelog just below the "Changelog" header when there are some breaking changes
    and you want to add an explanation to the users on how they are supposed to deal with them.
    The changelog is updated and maintained semi-automatically by release manager.
 
 Changelog
 ---------
 
+9.0.0
+.....
+
+Breaking changes
+~~~~~~~~~~~~~~~~
+
+Google  announced sunset of Bid manager API v1 and v1.1 by April 27, 2023 for more information
+please check: `docs <https://developers.google.com/bid-manager/v1.1>`_  As a result default value of api_version
+in GoogleDisplayVideo360Hook and related operators updated to v2
+
+This version of provider contains a temporary workaround to issue with ``v11`` version of
+google-ads API being discontinued, while the google provider dependencies preventing installing
+any google-ads client supporting ``v12`` API. This version contains vendored-in version of google-ads
+library ``20.0.0`` v12 support only. The workaround (and vendored-in library) will be removed
+as soon as dependencies of the provider will allow to use google-ads supporting newer
+API versions of google-ads.
+
+.. note::
+
+  ONLY v12 version of google ads is supported. You should set v12 when your create an operator or client.
+
+* ``Update DV360 operators to use API v2 (#30326)``
+* ``Fix dynamic imports in google ads vendored in library (#30544)``
+
+Features
+~~~~~~~~
+
+* ``Add deferrable mode to GKEStartPodOperator (#29266)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``BigQueryHook list_rows/get_datasets_list can return iterator (#30543)``
+* ``Fix cloud build async credentials (#30441)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``Add mechanism to suspend providers (#30422)``
+   * ``Small quotation fix (#30448)``
+
+8.12.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add missing 'poll_interval' in Bigquery operator (#30132)``
+* ``Add poll_interval param in BigQueryInsertJobOperator (#30091)``
+* ``Add 'job_id' to 'BigQueryToGCSOperator' templated_fields (#30006)``
+* ``Support deleting the local log files when using remote logging (#29772)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``fix setting project_id for gs to bq and bq to gs (#30053)``
+* ``Fix location on cloud build operators (#29937)``
+* ``'GoogleDriveHook': Fixing log message + adding more verbose documentation (#29694)``
+* ``Add "BOOLEAN" to type_map of MSSQLToGCSOperator, fix incorrect bit->int type conversion by specifying BIT fields explicitly (#29902)``
+* ``Google Cloud Providers - Fix _MethodDefault deepcopy failure (#29518)``
+* ``Handling project location param on async BigQuery dts trigger (#29786)``
+* ``Support CloudDataTransferServiceJobStatusSensor without specifying a project_id (#30035)``
+* ``Wait insert_job result in normal mode (#29925)``
+
+Misc
+~~~~
+
+* ``merge BigQueryTableExistenceAsyncSensor into BigQueryTableExistenceSensor (#30235)``
+* ``Remove  unnecessary upper constraints from google provider (#29915)``
+* ``Merge BigQueryTableExistencePartitionAsyncSensor into BigQueryTableExistencePartitionSensor (#30231)``
+* ``Merge GCSObjectExistenceAsyncSensor logic to GCSObjectExistenceSensor (#30014)``
+* ``Align cncf provider file names with AIP-21 (#29905)``
+* ``Switch to using vendored-in google ads. (#30410)``
+* ``Merging of the google ads vendored-in code. (#30399)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``adding trigger info to provider yaml (#29950)``
+
+8.11.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add deferrable mode to BigQueryTablePartitionExistenceSensor. (#29735)``
+* ``Add a new param for BigQuery operators to support additional actions when resource exists (#29394)``
+* ``Add deferrable mode to DataprocInstantiateWorkflowTemplateOperator (#28618)``
+* ``Dataproc batches (#29136)``
+* ``Add 'CloudSQLCloneInstanceOperator' (#29726)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``Fix 'NoneType' object is not subscriptable. (#29820)``
+* ``Fix and augment 'check-for-inclusive-language' CI check (#29549)``
+* ``Don't push secret in XCOM in BigQueryCreateDataTransferOperator (#29348)``
+
+Misc
+~~~~
+
+* ``Google Cloud Providers - Introduce GoogleCloudBaseOperator (#29680)``
+* ``Update google cloud dlp package and adjust hook and operators (#29234)``
+* ``Refactor Dataproc Trigger (#29364)``
+* ``Remove <2.0.0 limit on google-cloud-bigtable (#29644)``
+* ``Move help message to the google auth code (#29888)``
+
+8.10.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add defer mode to GKECreateClusterOperator and GKEDeleteClusterOperator (#28406)``
+
+Bug Fixes
+~~~~~~~~~
+* ``Move cloud_sql_binary_path from connection to Hook (#29499)``
+* ``Check that cloud sql provider version is valid (#29497)``
+* ``'GoogleDriveHook': Add folder_id param to upload_file (#29477)``
+
+Misc
+~~~~
+* ``Add documentation for BigQuery transfer operators (#29466)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``Upgrade Mypy to 1.0 (#29468)``
+   * ``Restore trigger logging (#29482)``
+   * ``Revert "Enable individual trigger logging (#27758)" (#29472)``
+   * ``Revert "Upgrade mypy to 0.991 (#28926)" (#29470)``
+   * ``Upgrade mypy to 0.991 (#28926)``
+
 8.9.0
 .....
 
 Features
 ~~~~~~~~
 
 * ``Add deferrable capability to existing ''DataprocDeleteClusterOperator'' (#29349)``
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/hooks/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/hooks/ads.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/hooks/ads.py`

 * *Files 6% similar despite different names*

```diff
@@ -17,26 +17,34 @@
 # under the License.
 """This module contains Google Ad hook."""
 from __future__ import annotations
 
 from tempfile import NamedTemporaryFile
 from typing import IO, Any
 
-from google.ads.googleads.client import GoogleAdsClient
-from google.ads.googleads.errors import GoogleAdsException
-from google.ads.googleads.v10.services.services.customer_service import CustomerServiceClient
-from google.ads.googleads.v10.services.services.google_ads_service import GoogleAdsServiceClient
-from google.ads.googleads.v10.services.types.google_ads_service import GoogleAdsRow, SearchGoogleAdsRequest
-from google.api_core.page_iterator import GRPCIterator
 from google.auth.exceptions import GoogleAuthError
 
 from airflow import AirflowException
 from airflow.compat.functools import cached_property
 from airflow.hooks.base import BaseHook
 from airflow.providers.google.common.hooks.base_google import get_field
+from airflow.providers.google_vendor.googleads.client import GoogleAdsClient
+from airflow.providers.google_vendor.googleads.errors import GoogleAdsException
+from airflow.providers.google_vendor.googleads.v12.services.services.customer_service import (
+    CustomerServiceClient,
+)
+from airflow.providers.google_vendor.googleads.v12.services.services.google_ads_service import (
+    GoogleAdsServiceClient,
+)
+from airflow.providers.google_vendor.googleads.v12.services.services.google_ads_service.pagers import (
+    SearchPager,
+)
+from airflow.providers.google_vendor.googleads.v12.services.types.google_ads_service import (
+    GoogleAdsRow,
+)
 
 
 class GoogleAdsHook(BaseHook):
     """
     Hook for the Google Ads API.
 
     This hook requires two connections:
@@ -69,15 +77,15 @@
     :param gcp_conn_id: The connection ID with the service account details.
     :param google_ads_conn_id: The connection ID with the details of Google Ads config.yaml file.
     :param api_version: The Google Ads API version to use.
 
     :return: list of Google Ads Row object(s)
     """
 
-    default_api_version = "v10"
+    default_api_version = "v12"
 
     def __init__(
         self,
         api_version: str | None,
         gcp_conn_id: str = "google_cloud_default",
         google_ads_conn_id: str = "google_ads_default",
     ) -> None:
@@ -219,27 +227,22 @@
 
         :return: Google Ads API response, converted to Google Ads Row objects
         """
         service = self._get_service
 
         iterators = []
         for client_id in client_ids:
-            request: SearchGoogleAdsRequest = self._get_client.get_type("SearchGoogleAdsRequest")
-            request.customer_id = client_id
-            request.query = query
-            request.page_size = page_size
-
-            iterator = service.search(request=request)
+            iterator = service.search(request=dict(customer_id=client_id, query=query, page_size=page_size))
             iterators.append(iterator)
 
         self.log.info("Fetched Google Ads Iterators")
 
         return self._extract_rows(iterators)
 
-    def _extract_rows(self, iterators: list[GRPCIterator]) -> list[GoogleAdsRow]:
+    def _extract_rows(self, iterators: list[SearchPager]) -> list[GoogleAdsRow]:
         """
         Convert Google Page Iterator (GRPCIterator) objects to Google Ads Rows
 
         :param iterators: List of Google Page Iterator (GRPCIterator) objects
 
         :return: API response for all clients in the form of Google Ads Row object(s)
         """
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/operators/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/operators/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/operators/ads.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/operators/ads.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/transfers/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/transfers/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/ads/transfers/ads_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/ads/transfers/ads_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/_internal_client/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/_internal_client/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/_internal_client/secret_manager_client.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/_internal_client/secret_manager_client.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_nl_text_classification.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_nl_text_classification.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_nl_text_sentiment.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_nl_text_sentiment.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_translation.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_translation.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_video_intelligence_classification.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_video_intelligence_classification.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_video_intelligence_tracking.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_video_intelligence_tracking.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_automl_vision_object_detection.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_automl_vision_object_detection.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py`

 * *Files 2% similar despite different names*

```diff
@@ -201,16 +201,15 @@
 os.environ["AIRFLOW_CONN_PROXY_MYSQL_SOCKET"] = (
     "gcpcloudsql://{user}:{password}@{public_ip}:{public_port}/{database}?"
     "database_type=mysql&"
     "project_id={project_id}&"
     "location={location}&"
     "instance={instance}&"
     "use_proxy=True&"
-    "sql_proxy_binary_path={sql_proxy_binary_path}&"
-    "sql_proxy_use_tcp=False".format(sql_proxy_binary_path=quote_plus(sql_proxy_binary_path), **mysql_kwargs)
+    "sql_proxy_use_tcp=False".format(**mysql_kwargs)
 )
 
 # MySQL: connect directly via TCP (non-SSL)
 os.environ["AIRFLOW_CONN_PUBLIC_MYSQL_TCP"] = (
     "gcpcloudsql://{user}:{password}@{public_ip}:{public_port}/{database}?"
     "database_type=mysql&"
     "project_id={project_id}&"
@@ -275,15 +274,18 @@
     catchup=False,
     tags=["example"],
 ) as dag:
     prev_task = None
 
     for connection_name in connection_names:
         task = CloudSQLExecuteQueryOperator(
-            gcp_cloudsql_conn_id=connection_name, task_id="example_gcp_sql_task_" + connection_name, sql=SQL
+            gcp_cloudsql_conn_id=connection_name,
+            task_id="example_gcp_sql_task_" + connection_name,
+            sql=SQL,
+            sql_proxy_binary_path=sql_proxy_binary_path,
         )
         tasks.append(task)
         if prev_task:
             prev_task >> task
         prev_task = task
 
 # [END howto_operator_cloudsql_query_operators]
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_storage_transfer_service_aws.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_storage_transfer_service_aws.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_task.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_cloud_task.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_compute.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_compute.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_compute_ssh.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_compute_ssh.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow_flex_template.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow_flex_template.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow_sql.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_dataflow_sql.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_facebook_ads_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_facebook_ads_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_looker.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_looker.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_postgres_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_postgres_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_presto_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_presto_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_salesforce_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_salesforce_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/example_dags/example_vertex_ai.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/example_dags/example_vertex_ai.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/automl.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/automl.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/bigquery.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/bigquery.py`

 * *Files 1% similar despite different names*

```diff
@@ -30,27 +30,28 @@
 import warnings
 from copy import deepcopy
 from datetime import datetime, timedelta
 from typing import Any, Iterable, Mapping, NoReturn, Sequence, Union, cast
 
 from aiohttp import ClientSession as ClientSession
 from gcloud.aio.bigquery import Job, Table as Table_async
+from google.api_core.page_iterator import HTTPIterator
 from google.api_core.retry import Retry
 from google.cloud.bigquery import (
     DEFAULT_RETRY,
     Client,
     CopyJob,
     ExternalConfig,
     ExtractJob,
     LoadJob,
     QueryJob,
     SchemaField,
 )
 from google.cloud.bigquery.dataset import AccessEntry, Dataset, DatasetListItem, DatasetReference
-from google.cloud.bigquery.table import EncryptionConfiguration, Row, Table, TableReference
+from google.cloud.bigquery.table import EncryptionConfiguration, Row, RowIterator, Table, TableReference
 from google.cloud.exceptions import NotFound
 from googleapiclient.discovery import Resource, build
 from pandas import DataFrame
 from pandas_gbq import read_gbq
 from pandas_gbq.gbq import GbqConnector  # noqa
 from requests import Session
 from sqlalchemy import create_engine
@@ -236,16 +237,16 @@
         **kwargs,
     ) -> DataFrame:
         """
         Returns a Pandas DataFrame for the results produced by a BigQuery
         query. The DbApiHook method must be overridden because Pandas
         doesn't support PEP 249 connections, except for SQLite. See:
 
-        https://github.com/pydata/pandas/blob/master/pandas/io/sql.py#L447
-        https://github.com/pydata/pandas/issues/6900
+        https://github.com/pandas-dev/pandas/blob/055d008615272a1ceca9720dc365a2abd316f353/pandas/io/sql.py#L415
+        https://github.com/pandas-dev/pandas/issues/6900
 
         :param sql: The BigQuery SQL to execute.
         :param parameters: The parameters to render the SQL query with (not
             used, leave to override superclass method)
         :param dialect: Dialect of BigQuery SQL – legacy SQL or standard SQL
             defaults to use `self.use_legacy_sql` if not specified
         :param kwargs: (optional) passed into pandas_gbq.read_gbq method
@@ -1002,15 +1003,16 @@
         self,
         project_id: str | None = None,
         include_all: bool = False,
         filter_: str | None = None,
         max_results: int | None = None,
         page_token: str | None = None,
         retry: Retry = DEFAULT_RETRY,
-    ) -> list[DatasetListItem]:
+        return_iterator: bool = False,
+    ) -> list[DatasetListItem] | HTTPIterator:
         """
         Method returns full list of BigQuery datasets in the current project
 
         For more information, see:
         https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/list
 
         :param project_id: Google Cloud Project for which you try to get all datasets
@@ -1022,25 +1024,32 @@
         :param max_results: int
         :param page_token: Token representing a cursor into the datasets. If not passed,
             the API will return the first page of datasets. The token marks the beginning of the
             iterator to be returned and the value of the ``page_token`` can be accessed at
             ``next_page_token`` of the :class:`~google.api_core.page_iterator.HTTPIterator`.
         :param page_token: str
         :param retry: How to retry the RPC.
+        :param return_iterator: Instead of returning a list[Row], returns a HTTPIterator
+            which can be used to obtain the next_page_token property.
         """
-        datasets = self.get_client(project_id=project_id).list_datasets(
+        iterator = self.get_client(project_id=project_id).list_datasets(
             project=project_id,
             include_all=include_all,
             filter=filter_,
             max_results=max_results,
             page_token=page_token,
             retry=retry,
         )
-        datasets_list = list(datasets)
 
+        # If iterator is requested, we cannot perform a list() on it to log the number
+        # of datasets because we will have started iteration
+        if return_iterator:
+            return iterator
+
+        datasets_list = list(iterator)
         self.log.info("Datasets List: %s", len(datasets_list))
         return datasets_list
 
     @GoogleBaseHook.fallback_to_default_project_id
     def get_dataset(self, dataset_id: str, project_id: str | None = None) -> Dataset:
         """
         Fetch the dataset referenced by dataset_id.
@@ -1228,29 +1237,34 @@
         table_id: str,
         max_results: int | None = None,
         selected_fields: list[str] | str | None = None,
         page_token: str | None = None,
         start_index: int | None = None,
         project_id: str | None = None,
         location: str | None = None,
-    ) -> list[Row]:
+        retry: Retry = DEFAULT_RETRY,
+        return_iterator: bool = False,
+    ) -> list[Row] | RowIterator:
         """
         List the rows of the table.
         See https://cloud.google.com/bigquery/docs/reference/rest/v2/tabledata/list
 
         :param dataset_id: the dataset ID of the requested table.
         :param table_id: the table ID of the requested table.
         :param max_results: the maximum results to return.
         :param selected_fields: List of fields to return (comma-separated). If
             unspecified, all fields are returned.
         :param page_token: page token, returned from a previous call,
             identifying the result set.
         :param start_index: zero based index of the starting row to read.
         :param project_id: Project ID for the project which the client acts on behalf of.
         :param location: Default location for job.
+        :param retry: How to retry the RPC.
+        :param return_iterator: Instead of returning a list[Row], returns a RowIterator
+            which can be used to obtain the next_page_token property.
         :return: list of rows
         """
         location = location or self.location
         if isinstance(selected_fields, str):
             selected_fields = selected_fields.split(",")
 
         if selected_fields:
@@ -1261,22 +1275,25 @@
         table = self._resolve_table_reference(
             table_resource={},
             project_id=project_id,
             dataset_id=dataset_id,
             table_id=table_id,
         )
 
-        result = self.get_client(project_id=project_id, location=location).list_rows(
+        iterator = self.get_client(project_id=project_id, location=location).list_rows(
             table=Table.from_api_repr(table),
             selected_fields=selected_fields,
             max_results=max_results,
             page_token=page_token,
             start_index=start_index,
+            retry=retry,
         )
-        return list(result)
+        if return_iterator:
+            return iterator
+        return list(iterator)
 
     @GoogleBaseHook.fallback_to_default_project_id
     def get_schema(self, dataset_id: str, table_id: str, project_id: str | None = None) -> dict:
         """
         Get the schema for a given dataset and table.
         see https://cloud.google.com/bigquery/docs/reference/v2/tables#resource
 
@@ -2451,15 +2468,15 @@
             "This method is deprecated. "
             "Please use `airflow.providers.google.cloud.hooks.bigquery.BigQueryHook.get_dataset_tables_list`",
             DeprecationWarning,
             stacklevel=3,
         )
         return self.hook.get_dataset_tables_list(*args, **kwargs)
 
-    def get_datasets_list(self, *args, **kwargs) -> list:
+    def get_datasets_list(self, *args, **kwargs) -> list | HTTPIterator:
         """
         This method is deprecated.
         Please use `airflow.providers.google.cloud.hooks.bigquery.BigQueryHook.get_datasets_list`
         """
         warnings.warn(
             "This method is deprecated. "
             "Please use `airflow.providers.google.cloud.hooks.bigquery.BigQueryHook.get_datasets_list`",
@@ -3044,14 +3061,32 @@
         """Get the big query job output for the given job id asynchronously using gcloud-aio."""
         async with ClientSession() as session:
             self.log.info("Executing get_job_output..")
             job_client = await self.get_job_instance(project_id, job_id, session)
             job_query_response = await job_client.get_query_results(cast(Session, session))
             return job_query_response
 
+    async def create_job_for_partition_get(
+        self,
+        dataset_id: str | None,
+        project_id: str | None = None,
+    ):
+        """Create a new job and get the job_id using gcloud-aio."""
+        async with ClientSession() as session:
+            self.log.info("Executing create_job..")
+            job_client = await self.get_job_instance(project_id, "", session)
+
+            query_request = {
+                "query": "SELECT partition_id "
+                f"FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.PARTITIONS`",
+                "useLegacySql": False,
+            }
+            job_query_resp = await job_client.query(query_request, cast(Session, session))
+            return job_query_resp["jobReference"]["jobId"]
+
     def get_records(self, query_results: dict[str, Any]) -> list[Any]:
         """
         Given the output query response from gcloud-aio bigquery, convert the response to records.
 
         :param query_results: the results from a SQL query
         """
         buffer = []
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/bigquery_dts.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/bigquery_dts.py`

 * *Files 6% similar despite different names*

```diff
@@ -300,42 +300,53 @@
             self._conn = DataTransferServiceAsyncClient(credentials=credentials, client_info=CLIENT_INFO)
         return self._conn
 
     async def _get_project_id(self) -> str:
         sync_hook = await self.get_sync_hook()
         return sync_hook.project_id
 
+    async def _get_project_location(self) -> str:
+        sync_hook = await self.get_sync_hook()
+        return sync_hook.location
+
     async def get_transfer_run(
         self,
         config_id: str,
         run_id: str,
         project_id: str | None,
+        location: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
     ):
         """
         Returns information about the particular transfer run.
 
         :param run_id: ID of the transfer run.
         :param config_id: ID of transfer config to be used.
         :param project_id: The BigQuery project id where the transfer configuration should be
             created. If set to None or missing, the default project_id from the Google Cloud connection
             is used.
+        :param location: BigQuery Transfer Service location for regional transfers.
         :param retry: A retry object used to retry requests. If `None` is
             specified, requests will not be retried.
         :param timeout: The amount of time, in seconds, to wait for the request to
             complete. Note that if retry is specified, the timeout applies to each individual
             attempt.
         :param metadata: Additional metadata that is provided to the method.
         :return: An ``google.cloud.bigquery_datatransfer_v1.types.TransferRun`` instance.
         """
         project_id = project_id or (await self._get_project_id())
+        location = location or (await self._get_project_location())
+        name = f"projects/{project_id}"
+        if location:
+            name += f"/locations/{location}"
+        name += f"/transferConfigs/{config_id}/runs/{run_id}"
+
         client = await self._get_conn()
-        name = f"projects/{project_id}/transferConfigs/{config_id}/runs/{run_id}"
         transfer_run = await client.get_transfer_run(
             name=name,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
         return transfer_run
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/bigtable.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/bigtable.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,20 +18,19 @@
 """This module contains a Google Cloud Bigtable Hook."""
 from __future__ import annotations
 
 import enum
 import warnings
 from typing import Sequence
 
-from google.cloud.bigtable import Client
+from google.cloud.bigtable import Client, enums
 from google.cloud.bigtable.cluster import Cluster
 from google.cloud.bigtable.column_family import ColumnFamily, GarbageCollectionRule
 from google.cloud.bigtable.instance import Instance
 from google.cloud.bigtable.table import ClusterState, Table
-from google.cloud.bigtable_admin_v2 import enums
 
 from airflow.providers.google.common.consts import CLIENT_INFO
 from airflow.providers.google.common.hooks.base_google import GoogleBaseHook
 
 
 class BigtableHook(GoogleBaseHook):
     """
@@ -52,28 +51,28 @@
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         super().__init__(
             gcp_conn_id=gcp_conn_id,
             delegate_to=delegate_to,
             impersonation_chain=impersonation_chain,
         )
-        self._client = None
+        self._client: Client | None = None
 
-    def _get_client(self, project_id: str):
+    def _get_client(self, project_id: str) -> Client:
         if not self._client:
             self._client = Client(
                 project=project_id,
                 credentials=self.get_credentials(),
                 client_info=CLIENT_INFO,
                 admin=True,
             )
         return self._client
 
     @GoogleBaseHook.fallback_to_default_project_id
-    def get_instance(self, instance_id: str, project_id: str) -> Instance:
+    def get_instance(self, instance_id: str, project_id: str) -> Instance | None:
         """
         Retrieves and returns the specified Cloud Bigtable instance if it exists.
         Otherwise, returns None.
 
         :param instance_id: The ID of the Cloud Bigtable instance.
         :param project_id: Optional, Google Cloud  project ID where the
             BigTable exists. If set to None or missing,
@@ -109,18 +108,18 @@
         self,
         instance_id: str,
         main_cluster_id: str,
         main_cluster_zone: str,
         project_id: str,
         replica_clusters: list[dict[str, str]] | None = None,
         instance_display_name: str | None = None,
-        instance_type: enums.Instance.Type = enums.Instance.Type.TYPE_UNSPECIFIED,
+        instance_type: enums.Instance.Type = enums.Instance.Type.UNSPECIFIED,  # type: ignore[assignment]
         instance_labels: dict | None = None,
         cluster_nodes: int | None = None,
-        cluster_storage_type: enums.StorageType = enums.StorageType.STORAGE_TYPE_UNSPECIFIED,
+        cluster_storage_type: enums.StorageType = enums.StorageType.UNSPECIFIED,  # type: ignore[assignment]
         timeout: float | None = None,
     ) -> Instance:
         """
         Creates new instance.
 
         :param instance_id: The ID for the new instance.
         :param main_cluster_id: The ID for main cluster for the new instance.
@@ -138,17 +137,14 @@
         :param instance_labels: (optional) Dictionary of labels to associate with the
             instance.
         :param cluster_nodes: (optional) Number of nodes for cluster.
         :param cluster_storage_type: (optional) The type of storage.
         :param timeout: (optional) timeout (in seconds) for instance creation.
                         If None is not specified, Operator will wait indefinitely.
         """
-        cluster_storage_type = enums.StorageType(cluster_storage_type)
-        instance_type = enums.Instance.Type(instance_type)
-
         instance = Instance(
             instance_id,
             self._get_client(project_id=project_id),
             instance_display_name,
             instance_type,
             instance_labels,
         )
@@ -196,16 +192,14 @@
         :param instance_display_name: (optional) Human-readable name of the instance.
         :param instance_type: (optional) The type of the instance.
         :param instance_labels: (optional) Dictionary of labels to associate with the
             instance.
         :param timeout: (optional) timeout (in seconds) for instance update.
             If None is not specified, Operator will wait indefinitely.
         """
-        instance_type = enums.Instance.Type(instance_type)
-
         instance = Instance(
             instance_id=instance_id,
             client=self._get_client(project_id=project_id),
             display_name=instance_display_name,
             instance_type=instance_type,
             labels=instance_labels,
         )
@@ -249,15 +243,18 @@
 
         :param instance_id: The ID of the Cloud Bigtable instance.
         :param table_id: The ID of the table in Cloud Bigtable.
         :param project_id: Optional, Google Cloud project ID where the
             BigTable exists. If set to None or missing,
             the default project_id from the Google Cloud connection is used.
         """
-        table = self.get_instance(instance_id=instance_id, project_id=project_id).table(table_id=table_id)
+        instance = self.get_instance(instance_id=instance_id, project_id=project_id)
+        if instance is None:
+            raise RuntimeError("Instance %s did not exist; unable to delete table %s" % instance_id, table_id)
+        table = instance.table(table_id=table_id)
         table.delete()
 
     @staticmethod
     def update_cluster(instance: Instance, cluster_id: str, nodes: int) -> None:
         """
         Updates number of nodes in the specified Cloud Bigtable cluster.
         Raises google.api_core.exceptions.NotFound if the cluster does not exist.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_build.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_build.py`

 * *Files 5% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 # under the License.
 """Hook for Google Cloud Build service."""
 from __future__ import annotations
 
 import warnings
 from typing import Sequence
 
+from google.api_core.client_options import ClientOptions
 from google.api_core.exceptions import AlreadyExists
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.operation import Operation
 from google.api_core.retry import Retry
 from google.cloud.devtools.cloudbuild_v1 import CloudBuildAsyncClient, CloudBuildClient, GetBuildRequest
 from google.cloud.devtools.cloudbuild_v1.types import Build, BuildTrigger, RepoSource
 
@@ -63,15 +64,15 @@
         if delegate_to:
             warnings.warn(
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         super().__init__(
             gcp_conn_id=gcp_conn_id, delegate_to=delegate_to, impersonation_chain=impersonation_chain
         )
-        self._client: CloudBuildClient | None = None
+        self._client: dict[str, CloudBuildClient] = {}
 
     def _get_build_id_from_operation(self, operation: Operation) -> str:
         """
         Retrieve Cloud Build ID from Operation Object.
 
         :param operation: The proto to append resource_label airflow
             version to
@@ -87,47 +88,57 @@
         """Waits for long-lasting operation to complete."""
         try:
             return operation.result(timeout=timeout)
         except Exception:
             error = operation.exception(timeout=timeout)
             raise AirflowException(error)
 
-    def get_conn(self) -> CloudBuildClient:
+    def get_conn(self, location: str = "global") -> CloudBuildClient:
         """
         Retrieves the connection to Google Cloud Build.
 
+        :param location: The location of the project.
+
         :return: Google Cloud Build client object.
         """
-        if not self._client:
-            self._client = CloudBuildClient(credentials=self.get_credentials(), client_info=CLIENT_INFO)
-        return self._client
+        if location not in self._client:
+            client_options = None
+            if location != "global":
+                client_options = ClientOptions(api_endpoint=f"{location}-cloudbuild.googleapis.com:443")
+            self._client[location] = CloudBuildClient(
+                credentials=self.get_credentials(),
+                client_info=CLIENT_INFO,
+                client_options=client_options,
+            )
+        return self._client[location]
 
     @GoogleBaseHook.fallback_to_default_project_id
     def cancel_build(
         self,
         id_: str,
         project_id: str = PROVIDE_PROJECT_ID,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> Build:
         """
         Cancels a build in progress.
 
         :param id_: The ID of the build.
         :param project_id: Optional, Google Cloud Project project_id where the function belongs.
             If set to None or missing, the default project_id from the GCP connection is used.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
-
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         self.log.info("Start cancelling build: %s.", id_)
 
         build = client.cancel_build(
             request={"project_id": project_id, "id": id_},
             retry=retry,
             timeout=timeout,
@@ -141,34 +152,38 @@
     def create_build_without_waiting_for_result(
         self,
         build: dict | Build,
         project_id: str = PROVIDE_PROJECT_ID,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> tuple[Operation, str]:
         """
         Starts a build with the specified configuration without waiting for it to finish.
 
         :param build: The build resource to create. If a dict is provided, it must be of the same form
             as the protobuf message `google.cloud.devtools.cloudbuild_v1.types.Build`
         :param project_id: Optional, Google Cloud Project project_id where the function belongs.
             If set to None or missing, the default project_id from the GCP connection is used.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
+
+        parent = f"projects/{project_id}/locations/{location}"
 
         self.log.info("Start creating build...")
 
         operation = client.create_build(
-            request={"project_id": project_id, "build": build},
+            request={"parent": parent, "project_id": project_id, "build": build},
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
         id_ = self._get_build_id_from_operation(operation)
         return operation, id_
 
@@ -223,30 +238,31 @@
     def create_build_trigger(
         self,
         trigger: dict | BuildTrigger,
         project_id: str = PROVIDE_PROJECT_ID,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> BuildTrigger:
         """
         Creates a new BuildTrigger.
 
         :param trigger: The BuildTrigger to create. If a dict is provided, it must be of the same form
             as the protobuf message `google.cloud.devtools.cloudbuild_v1.types.BuildTrigger`
         :param project_id: Optional, Google Cloud Project project_id where the function belongs.
             If set to None or missing, the default project_id from the GCP connection is used.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
-
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         self.log.info("Start creating build trigger...")
 
         try:
             trigger = client.create_build_trigger(
                 request={"project_id": project_id, "trigger": trigger},
                 retry=retry,
@@ -264,28 +280,30 @@
     def delete_build_trigger(
         self,
         trigger_id: str,
         project_id: str = PROVIDE_PROJECT_ID,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> None:
         """
         Deletes a BuildTrigger by its project ID and trigger ID.
 
         :param trigger_id: The ID of the BuildTrigger to delete.
         :param project_id: Optional, Google Cloud Project project_id where the function belongs.
             If set to None or missing, the default project_id from the GCP connection is used.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         self.log.info("Start deleting build trigger: %s.", trigger_id)
 
         client.delete_build_trigger(
             request={"project_id": project_id, "trigger_id": trigger_id},
             retry=retry,
             timeout=timeout,
@@ -298,29 +316,30 @@
     def get_build(
         self,
         id_: str,
         project_id: str = PROVIDE_PROJECT_ID,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> Build:
         """
         Returns information about a previously requested build.
 
         :param id_: The ID of the build.
         :param project_id: Optional, Google Cloud Project project_id where the function belongs.
             If set to None or missing, the default project_id from the GCP connection is used.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
-
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         self.log.info("Start retrieving build: %s.", id_)
 
         build = client.get_build(
             request={"project_id": project_id, "id": id_},
             retry=retry,
             timeout=timeout,
@@ -335,29 +354,30 @@
     def get_build_trigger(
         self,
         trigger_id: str,
         project_id: str = PROVIDE_PROJECT_ID,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> BuildTrigger:
         """
         Returns information about a BuildTrigger.
 
         :param trigger_id: The ID of the BuildTrigger to get.
         :param project_id: Optional, Google Cloud Project project_id where the function belongs.
             If set to None or missing, the default project_id from the GCP connection is used.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
-
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         self.log.info("Start retrieving build trigger: %s.", trigger_id)
 
         trigger = client.get_build_trigger(
             request={"project_id": project_id, "trigger_id": trigger_id},
             retry=retry,
             timeout=timeout,
@@ -367,15 +387,15 @@
         self.log.info("Build trigger has been retrieved: %s.", trigger_id)
 
         return trigger
 
     @GoogleBaseHook.fallback_to_default_project_id
     def list_build_triggers(
         self,
-        location: str,
+        location: str = "global",
         project_id: str = PROVIDE_PROJECT_ID,
         page_size: int | None = None,
         page_token: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
     ) -> list[BuildTrigger]:
@@ -390,15 +410,15 @@
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
 
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         parent = f"projects/{project_id}/locations/{location}"
 
         self.log.info("Start retrieving build triggers.")
 
         response = client.list_build_triggers(
             request={
@@ -415,15 +435,15 @@
         self.log.info("Build triggers have been retrieved.")
 
         return list(response.triggers)
 
     @GoogleBaseHook.fallback_to_default_project_id
     def list_builds(
         self,
-        location: str,
+        location: str = "global",
         project_id: str = PROVIDE_PROJECT_ID,
         page_size: int | None = None,
         page_token: int | None = None,
         filter_: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
@@ -440,15 +460,15 @@
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
 
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         parent = f"projects/{project_id}/locations/{location}"
 
         self.log.info("Start retrieving builds.")
 
         response = client.list_builds(
             request={
@@ -472,62 +492,64 @@
         self,
         id_: str,
         project_id: str = PROVIDE_PROJECT_ID,
         wait: bool = True,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> Build:
         """
         Creates a new build based on the specified build. This method creates a new build
         using the original build request, which may or may not result in an identical build.
 
         :param id_: Build ID of the original build.
         :param project_id: Optional, Google Cloud Project project_id where the function belongs.
             If set to None or missing, the default project_id from the GCP connection is used.
         :param wait: Optional, wait for operation to finish.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
-
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         self.log.info("Start retrying build: %s.", id_)
 
         operation = client.retry_build(
             request={"project_id": project_id, "id": id_},
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         id_ = self._get_build_id_from_operation(operation)
 
         if not wait:
-            return self.get_build(id_=id_, project_id=project_id)
+            return self.get_build(id_=id_, project_id=project_id, location=location)
 
         operation.result()
 
         self.log.info("Build has been retried: %s.", id_)
 
-        return self.get_build(id_=id_, project_id=project_id)
+        return self.get_build(id_=id_, project_id=project_id, location=location)
 
     @GoogleBaseHook.fallback_to_default_project_id
     def run_build_trigger(
         self,
         trigger_id: str,
         source: dict | RepoSource,
         project_id: str = PROVIDE_PROJECT_ID,
         wait: bool = True,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> Build:
         """
         Runs a BuildTrigger at a particular source revision.
 
         :param trigger_id: The ID of the trigger.
         :param source: Source to build against this trigger. If a dict is provided, it must be of the
             same form as the protobuf message `google.cloud.devtools.cloudbuild_v1.types.RepoSource`
@@ -535,62 +557,63 @@
             If set to None or missing, the default project_id from the GCP connection is used.
         :param wait: Optional, wait for operation to finish.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
-
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         self.log.info("Start running build trigger: %s.", trigger_id)
         operation = client.run_build_trigger(
             request={"project_id": project_id, "trigger_id": trigger_id, "source": source},
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         id_ = self._get_build_id_from_operation(operation)
 
         if not wait:
-            return self.get_build(id_=id_, project_id=project_id)
+            return self.get_build(id_=id_, project_id=project_id, location=location)
         operation.result()
 
         self.log.info("Build trigger has been run: %s.", trigger_id)
 
-        return self.get_build(id_=id_, project_id=project_id)
+        return self.get_build(id_=id_, project_id=project_id, location=location)
 
     @GoogleBaseHook.fallback_to_default_project_id
     def update_build_trigger(
         self,
         trigger_id: str,
         trigger: dict | BuildTrigger,
         project_id: str,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> BuildTrigger:
         """
         Updates a BuildTrigger by its project ID and trigger ID.
 
         :param trigger_id: The ID of the trigger.
         :param trigger: The BuildTrigger to create. If a dict is provided, it must be of the same form
             as the protobuf message `google.cloud.devtools.cloudbuild_v1.types.BuildTrigger`
         :param project_id: Optional, Google Cloud Project project_id where the function belongs.
             If set to None or missing, the default project_id from the GCP connection is used.
         :param retry: Optional, a retry object used  to retry requests. If `None` is specified, requests
             will not be retried.
         :param timeout: Optional, the amount of time, in seconds, to wait for the request to complete.
             Note that if `retry` is specified, the timeout applies to each individual attempt.
         :param metadata: Optional, additional metadata that is provided to the method.
-
+        :param location: The location of the project.
         """
-        client = self.get_conn()
+        client = self.get_conn(location=location)
 
         self.log.info("Start updating build trigger: %s.", trigger_id)
 
         trigger = client.update_build_trigger(
             request={"project_id": project_id, "trigger_id": trigger_id, "trigger": trigger},
             retry=retry,
             timeout=timeout,
@@ -609,20 +632,26 @@
     async def get_cloud_build(
         self,
         id_: str,
         project_id: str = PROVIDE_PROJECT_ID,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
+        location: str = "global",
     ) -> Build:
         """Retrieves a Cloud Build with a specified id."""
         if not id_:
             raise AirflowException("Google Cloud Build id is required.")
 
-        client = CloudBuildAsyncClient()
+        client_options = None
+        if location != "global":
+            client_options = ClientOptions(api_endpoint=f"{location}-cloudbuild.googleapis.com:443")
+        client = CloudBuildAsyncClient(
+            credentials=self.get_credentials(), client_info=CLIENT_INFO, client_options=client_options
+        )
 
         request = GetBuildRequest(
             project_id=project_id,
             id=id_,
         )
         build_instance = await client.get_build(
             request=request,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_composer.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_composer.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_memorystore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_memorystore.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_sql.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_sql.py`

 * *Files 1% similar despite different names*

```diff
@@ -55,14 +55,16 @@
 from airflow.utils.log.logging_mixin import LoggingMixin
 
 UNIX_PATH_MAX = 108
 
 # Time to sleep between active checks of the operation results
 TIME_TO_SLEEP_IN_SECONDS = 20
 
+CLOUD_SQL_PROXY_VERSION_REGEX = re.compile(r"^v?(\d+\.\d+\.\d+)(-\w*.?\d?)?$")
+
 
 class CloudSqlOperationStatus:
     """Helper class with operation statuses."""
 
     PENDING = "PENDING"
     RUNNING = "RUNNING"
     DONE = "DONE"
@@ -341,14 +343,41 @@
                 .execute(num_retries=self.num_retries)
             )
             operation_name = response["name"]
             self._wait_for_operation_to_complete(project_id=project_id, operation_name=operation_name)
         except HttpError as ex:
             raise AirflowException(f"Importing instance {instance} failed: {ex.content}")
 
+    @GoogleBaseHook.fallback_to_default_project_id
+    def clone_instance(self, instance: str, body: dict, project_id: str) -> None:
+        """
+        Clones an instance to a target instance.
+
+        :param instance: Database instance ID to be cloned. This does not include the
+            project ID.
+        :param instance: Database instance ID to be used for the clone. This does not include the
+            project ID.
+        :param body: The request body, as described in
+            https://cloud.google.com/sql/docs/mysql/admin-api/rest/v1/instances/clone
+        :param project_id: Project ID of the project that contains the instance. If set
+            to None or missing, the default project_id from the Google Cloud connection is used.
+        :return: None
+        """
+        try:
+            response = (
+                self.get_conn()
+                .instances()
+                .clone(project=project_id, instance=instance, body=body)
+                .execute(num_retries=self.num_retries)
+            )
+            operation_name = response["name"]
+            self._wait_for_operation_to_complete(project_id=project_id, operation_name=operation_name)
+        except HttpError as ex:
+            raise AirflowException(f"Cloning of instance {instance} failed: {ex.content}")
+
     def _wait_for_operation_to_complete(self, project_id: str, operation_name: str) -> None:
         """
         Waits for the named operation to complete - checks status of the
         asynchronous call.
 
         :param project_id: Project ID of the project that contains the instance.
         :param operation_name: Name of the operation.
@@ -445,24 +474,15 @@
     def _is_os_64bit() -> bool:
         return platform.machine().endswith("64")
 
     def _download_sql_proxy_if_needed(self) -> None:
         if os.path.isfile(self.sql_proxy_path):
             self.log.info("cloud-sql-proxy is already present")
             return
-        system = platform.system().lower()
-        processor = os.uname().machine
-        if processor == "x86_64":
-            processor = "amd64"
-        if not self.sql_proxy_version:
-            download_url = CLOUD_SQL_PROXY_DOWNLOAD_URL.format(system, processor)
-        else:
-            download_url = CLOUD_SQL_PROXY_VERSION_DOWNLOAD_URL.format(
-                self.sql_proxy_version, system, processor
-            )
+        download_url = self._get_sql_proxy_download_url()
         proxy_path_tmp = self.sql_proxy_path + ".tmp"
         self.log.info("Downloading cloud_sql_proxy from %s to %s", download_url, proxy_path_tmp)
         # httpx has a breaking API change (follow_redirects vs allow_redirects)
         # and this should work with both versions (cf. issue #20088)
         if "follow_redirects" in signature(httpx.get).parameters.keys():
             response = httpx.get(download_url, follow_redirects=True)
         else:
@@ -478,14 +498,32 @@
             )
 
         self.log.info("Moving sql_proxy binary from %s to %s", proxy_path_tmp, self.sql_proxy_path)
         shutil.move(proxy_path_tmp, self.sql_proxy_path)
         os.chmod(self.sql_proxy_path, 0o744)  # Set executable bit
         self.sql_proxy_was_downloaded = True
 
+    def _get_sql_proxy_download_url(self):
+        system = platform.system().lower()
+        processor = os.uname().machine
+        if processor == "x86_64":
+            processor = "amd64"
+        if not self.sql_proxy_version:
+            download_url = CLOUD_SQL_PROXY_DOWNLOAD_URL.format(system, processor)
+        else:
+            if not CLOUD_SQL_PROXY_VERSION_REGEX.match(self.sql_proxy_version):
+                raise ValueError(
+                    "The sql_proxy_version should match the regular expression "
+                    f"{CLOUD_SQL_PROXY_VERSION_REGEX.pattern}"
+                )
+            download_url = CLOUD_SQL_PROXY_VERSION_DOWNLOAD_URL.format(
+                self.sql_proxy_version, system, processor
+            )
+        return download_url
+
     def _get_credential_parameters(self) -> list[str]:
         extras = GoogleBaseHook.get_connection(conn_id=self.gcp_conn_id).extra_dejson
         key_path = get_field(extras, "key_path")
         keyfile_dict = get_field(extras, "keyfile_dict")
         if key_path:
             credential_params = ["-credential_file", key_path]
         elif keyfile_dict:
@@ -653,30 +691,30 @@
     Main parameters of the hook are retrieved from the standard URI components:
 
     * **user** - User name to authenticate to the database (from login of the URI).
     * **password** - Password to authenticate to the database (from password of the URI).
     * **public_ip** - IP to connect to for public connection (from host of the URI).
     * **public_port** - Port to connect to for public connection (from port of the URI).
     * **database** - Database to connect to (from schema of the URI).
+    * **sql_proxy_binary_path** - Optional path to Cloud SQL Proxy binary. If the binary
+      is not specified or the binary is not present, it is automatically downloaded.
 
     Remaining parameters are retrieved from the extras (URI query parameters):
 
     * **project_id** - Optional, Google Cloud project where the Cloud SQL
        instance exists. If missing, default project id passed is used.
     * **instance** -  Name of the instance of the Cloud SQL database instance.
     * **location** - The location of the Cloud SQL instance (for example europe-west1).
     * **database_type** - The type of the database instance (MySQL or Postgres).
     * **use_proxy** - (default False) Whether SQL proxy should be used to connect to Cloud
       SQL DB.
     * **use_ssl** - (default False) Whether SSL should be used to connect to Cloud SQL DB.
       You cannot use proxy and SSL together.
     * **sql_proxy_use_tcp** - (default False) If set to true, TCP is used to connect via
       proxy, otherwise UNIX sockets are used.
-    * **sql_proxy_binary_path** - Optional path to Cloud SQL Proxy binary. If the binary
-      is not specified or the binary is not present, it is automatically downloaded.
     * **sql_proxy_version** -  Specific version of the proxy to download (for example
       v1.13). If not specified, the latest version is downloaded.
     * **sslcert** - Path to client certificate to authenticate when SSL is used.
     * **sslkey** - Path to client private key to authenticate when SSL is used.
     * **sslrootcert** - Path to server's certificate to authenticate when SSL is used.
 
     :param gcp_cloudsql_conn_id: URL of the connection
@@ -687,21 +725,20 @@
     """
 
     conn_name_attr = "gcp_cloudsql_conn_id"
     default_conn_name = "google_cloud_sqldb_default"
     conn_type = "gcpcloudsqldb"
     hook_name = "Google Cloud SQL Database"
 
-    _conn = None
-
     def __init__(
         self,
         gcp_cloudsql_conn_id: str = "google_cloud_sql_default",
         gcp_conn_id: str = "google_cloud_default",
         default_gcp_project_id: str | None = None,
+        sql_proxy_binary_path: str | None = None,
     ) -> None:
         super().__init__()
         self.gcp_conn_id = gcp_conn_id
         self.gcp_cloudsql_conn_id = gcp_cloudsql_conn_id
         self.cloudsql_connection = self.get_connection(self.gcp_cloudsql_conn_id)
         self.extras = self.cloudsql_connection.extra_dejson
         self.project_id = self.extras.get("project_id", default_gcp_project_id)
@@ -709,15 +746,15 @@
         self.database = self.cloudsql_connection.schema
         self.location = self.extras.get("location")
         self.database_type = self.extras.get("database_type")
         self.use_proxy = self._get_bool(self.extras.get("use_proxy", "False"))
         self.use_ssl = self._get_bool(self.extras.get("use_ssl", "False"))
         self.sql_proxy_use_tcp = self._get_bool(self.extras.get("sql_proxy_use_tcp", "False"))
         self.sql_proxy_version = self.extras.get("sql_proxy_version")
-        self.sql_proxy_binary_path = self.extras.get("sql_proxy_binary_path")
+        self.sql_proxy_binary_path = sql_proxy_binary_path
         self.user = self.cloudsql_connection.login
         self.password = self.cloudsql_connection.password
         self.public_ip = self.cloudsql_connection.host
         self.public_port = self.cloudsql_connection.port
         self.sslcert = self.extras.get("sslcert")
         self.sslkey = self.extras.get("sslkey")
         self.sslrootcert = self.extras.get("sslrootcert")
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/cloud_storage_transfer_service.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/cloud_storage_transfer_service.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/compute.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/compute.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/compute_ssh.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/compute_ssh.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/datacatalog.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/datacatalog.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataflow.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataflow.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataform.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataform.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/datafusion.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/datafusion.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataplex.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataplex.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataprep.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataprep.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataproc.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataproc.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,14 +24,15 @@
 from typing import Any, Sequence
 
 from google.api_core.client_options import ClientOptions
 from google.api_core.exceptions import ServerError
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.operation import Operation
 from google.api_core.operation_async import AsyncOperation
+from google.api_core.operations_v1.operations_client import OperationsClient
 from google.api_core.retry import Retry
 from google.cloud.dataproc_v1 import (
     Batch,
     BatchControllerAsyncClient,
     BatchControllerClient,
     Cluster,
     ClusterControllerAsyncClient,
@@ -981,14 +982,76 @@
             },
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
         return result
 
+    @GoogleBaseHook.fallback_to_default_project_id
+    def wait_for_batch(
+        self,
+        batch_id: str,
+        region: str,
+        project_id: str,
+        wait_check_interval: int = 10,
+        retry: Retry | _MethodDefault = DEFAULT,
+        timeout: float | None = None,
+        metadata: Sequence[tuple[str, str]] = (),
+    ) -> Batch:
+        """
+        Wait for a Batch job to complete.
+
+        After Batch job submission, the operator will wait for the job to complete, however, this is useful
+        in the case where Airflow is restarted or the task pid is killed for any reason. In this case, the
+        Batch create will happen again, AlreadyExists will be raised and caught, then should fall to this
+        function for waiting on completion.
+
+        :param batch_id: Required. The ID to use for the batch, which will become the final component
+            of the batch's resource name.
+            This value must be 4-63 characters. Valid characters are /[a-z][0-9]-/.
+        :param region: Required. The Cloud Dataproc region in which to handle the request.
+        :param project_id: Required. The ID of the Google Cloud project that the cluster belongs to.
+        :param wait_check_interval: The amount of time to pause between checks for job completion
+        :param retry: A retry object used to retry requests to get_batch.
+            If ``None`` is specified, requests will not be retried.
+        :param timeout: The amount of time, in seconds, to wait for the create_batch request to complete.
+            Note that if ``retry`` is specified, the timeout applies to each individual attempt.
+        :param metadata: Additional metadata that is provided to the method.
+        """
+        state = None
+        first_loop: bool = True
+        while state not in [
+            Batch.State.CANCELLED,
+            Batch.State.FAILED,
+            Batch.State.SUCCEEDED,
+            Batch.State.STATE_UNSPECIFIED,
+        ]:
+            try:
+                if not first_loop:
+                    time.sleep(wait_check_interval)
+                first_loop = False
+                self.log.debug("Waiting for batch %s", batch_id)
+                result = self.get_batch(
+                    batch_id=batch_id,
+                    region=region,
+                    project_id=project_id,
+                    retry=retry,
+                    timeout=timeout,
+                    metadata=metadata,
+                )
+                state = result.state
+            except ServerError as err:
+                self.log.info(
+                    "Retrying. Dataproc API returned server error when waiting for batch id %s: %s",
+                    batch_id,
+                    err,
+                )
+
+        return result
+
 
 class DataprocAsyncHook(GoogleBaseHook):
     """
     Asynchronous Hook for Google Cloud Dataproc APIs.
 
     All the methods in the hook where project_id is used must be called with
     keyword arguments rather than positional.
@@ -1043,14 +1106,18 @@
         if region and region != "global":
             client_options = ClientOptions(api_endpoint=f"{region}-dataproc.googleapis.com:443")
 
         return BatchControllerAsyncClient(
             credentials=self.get_credentials(), client_info=CLIENT_INFO, client_options=client_options
         )
 
+    def get_operations_client(self, region: str) -> OperationsClient:
+        """Returns OperationsClient"""
+        return self.get_template_client(region=region).transport.operations_client
+
     @GoogleBaseHook.fallback_to_default_project_id
     async def create_cluster(
         self,
         region: str,
         project_id: str,
         cluster_name: str,
         cluster_config: dict | Cluster | None = None,
@@ -1455,14 +1522,17 @@
             request={"parent": parent, "template": template, "request_id": request_id},
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
         return operation
 
+    async def get_operation(self, region, operation_name):
+        return await self.get_operations_client(region).get_operation(name=operation_name)
+
     @GoogleBaseHook.fallback_to_default_project_id
     async def get_job(
         self,
         job_id: str,
         project_id: str,
         region: str,
         retry: Retry | _MethodDefault = DEFAULT,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dataproc_metastore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dataproc_metastore.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/datastore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/datastore.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/dlp.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/dlp.py`

 * *Files 7% similar despite different names*

```diff
@@ -29,36 +29,36 @@
 import re
 import time
 import warnings
 from typing import Sequence
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
-from google.cloud.dlp_v2 import DlpServiceClient
+from google.cloud.dlp import DlpServiceClient
 from google.cloud.dlp_v2.types import (
     ByteContentItem,
     ContentItem,
     DeidentifyConfig,
     DeidentifyContentResponse,
     DeidentifyTemplate,
     DlpJob,
-    FieldMask,
     InspectConfig,
     InspectContentResponse,
     InspectJobConfig,
     InspectTemplate,
     JobTrigger,
     ListInfoTypesResponse,
     RedactImageRequest,
     RedactImageResponse,
     ReidentifyContentResponse,
     RiskAnalysisJobConfig,
     StoredInfoType,
     StoredInfoTypeConfig,
 )
+from google.protobuf.field_mask_pb2 import FieldMask
 
 from airflow.exceptions import AirflowException
 from airflow.providers.google.common.consts import CLIENT_INFO
 from airflow.providers.google.common.hooks.base_google import PROVIDE_PROJECT_ID, GoogleBaseHook
 
 DLP_JOB_PATH_PATTERN = "^projects/[^/]+/dlpJobs/(?P<job>.*?)$"
 
@@ -97,26 +97,35 @@
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         super().__init__(
             gcp_conn_id=gcp_conn_id,
             delegate_to=delegate_to,
             impersonation_chain=impersonation_chain,
         )
-        self._client = None
+        self._client: DlpServiceClient | None = None
 
     def get_conn(self) -> DlpServiceClient:
         """
         Provides a client for interacting with the Cloud DLP API.
 
         :return: Google Cloud DLP API Client
         """
         if not self._client:
             self._client = DlpServiceClient(credentials=self.get_credentials(), client_info=CLIENT_INFO)
         return self._client
 
+    def _project_deidentify_template_path(self, project_id, template_id):
+        return f"{DlpServiceClient.common_project_path(project_id)}/deidentifyTemplates/{template_id}"
+
+    def _project_stored_info_type_path(self, project_id, info_type_id):
+        return f"{DlpServiceClient.common_project_path(project_id)}/storedInfoTypes/{info_type_id}"
+
+    def _project_inspect_template_path(self, project_id, inspect_template_id):
+        return f"{DlpServiceClient.common_project_path(project_id)}/inspectTemplates/{inspect_template_id}"
+
     @GoogleBaseHook.fallback_to_default_project_id
     def cancel_dlp_job(
         self,
         dlp_job_id: str,
         project_id: str = PROVIDE_PROJECT_ID,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
@@ -138,15 +147,22 @@
         """
         client = self.get_conn()
 
         if not dlp_job_id:
             raise AirflowException("Please provide the ID of the DLP job resource to be cancelled.")
 
         name = DlpServiceClient.dlp_job_path(project_id, dlp_job_id)
-        client.cancel_dlp_job(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        client.cancel_dlp_job(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     def create_deidentify_template(
         self,
         organization_id: str | None = None,
         project_id: str | None = None,
         deidentify_template: dict | DeidentifyTemplate | None = None,
         template_id: str | None = None,
@@ -173,24 +189,26 @@
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            parent = DlpServiceClient.organization_path(organization_id)
+            parent = DlpServiceClient.common_organization_path(organization_id)
         elif project_id:
-            parent = DlpServiceClient.project_path(project_id)
+            parent = DlpServiceClient.common_project_path(project_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         return client.create_deidentify_template(
-            parent=parent,
-            deidentify_template=deidentify_template,
-            template_id=template_id,
+            request=dict(
+                parent=parent,
+                deidentify_template=deidentify_template,
+                template_id=template_id,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def create_dlp_job(
@@ -223,20 +241,22 @@
         :param wait_until_finished: (Optional) If true, it will keep polling the job state
             until it is set to DONE.
         :param time_to_sleep_in_seconds: (Optional) Time to sleep, in seconds, between active checks
             of the operation results. Defaults to 60.
         """
         client = self.get_conn()
 
-        parent = DlpServiceClient.project_path(project_id)
+        parent = DlpServiceClient.common_project_path(project_id)
         job = client.create_dlp_job(
-            parent=parent,
-            inspect_job=inspect_job,
-            risk_job=risk_job,
-            job_id=job_id,
+            request=dict(
+                parent=parent,
+                inspect_job=inspect_job,
+                risk_job=risk_job,
+                job_id=job_id,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         if wait_until_finished:
             pattern = re.compile(DLP_JOB_PATH_PATTERN, re.IGNORECASE)
@@ -245,15 +265,15 @@
                 job_name = match.groupdict()["job"]
             else:
                 raise AirflowException(f"Unable to retrieve DLP job's ID from {job.name}.")
 
         while wait_until_finished:
             job = self.get_dlp_job(dlp_job_id=job_name, project_id=project_id)
 
-            self.log.info("DLP job %s state: %s.", job.name, DlpJob.JobState.Name(job.state))
+            self.log.info("DLP job %s state: %s.", job.name, job.state)
 
             if job.state == DlpJob.JobState.DONE:
                 return job
             elif job.state in [
                 DlpJob.JobState.PENDING,
                 DlpJob.JobState.RUNNING,
                 DlpJob.JobState.JOB_STATE_UNSPECIFIED,
@@ -296,24 +316,26 @@
         """
         client = self.get_conn()
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            parent = DlpServiceClient.organization_path(organization_id)
+            parent = DlpServiceClient.common_organization_path(organization_id)
         elif project_id:
-            parent = DlpServiceClient.project_path(project_id)
+            parent = DlpServiceClient.common_project_path(project_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         return client.create_inspect_template(
-            parent=parent,
-            inspect_template=inspect_template,
-            template_id=template_id,
+            request=dict(
+                parent=parent,
+                inspect_template=inspect_template,
+                template_id=template_id,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def create_job_trigger(
@@ -339,19 +361,21 @@
         :param timeout: (Optional) The amount of time, in seconds, to wait for the request
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
-        parent = DlpServiceClient.project_path(project_id)
+        parent = DlpServiceClient.common_project_path(project_id)
         return client.create_job_trigger(
-            parent=parent,
-            job_trigger=job_trigger,
-            trigger_id=trigger_id,
+            request=dict(
+                parent=parent,
+                job_trigger=job_trigger,
+                trigger_id=trigger_id,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     def create_stored_info_type(
         self,
@@ -382,24 +406,26 @@
         """
         client = self.get_conn()
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            parent = DlpServiceClient.organization_path(organization_id)
+            parent = DlpServiceClient.common_organization_path(organization_id)
         elif project_id:
-            parent = DlpServiceClient.project_path(project_id)
+            parent = DlpServiceClient.common_project_path(project_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         return client.create_stored_info_type(
-            parent=parent,
-            config=config,
-            stored_info_type_id=stored_info_type_id,
+            request=dict(
+                parent=parent,
+                config=config,
+                stored_info_type_id=stored_info_type_id,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def deidentify_content(
@@ -437,22 +463,24 @@
         :param timeout: (Optional) The amount of time, in seconds, to wait for the request
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
-        parent = DlpServiceClient.project_path(project_id)
+        parent = DlpServiceClient.common_project_path(project_id)
         return client.deidentify_content(
-            parent=parent,
-            deidentify_config=deidentify_config,
-            inspect_config=inspect_config,
-            item=item,
-            inspect_template_name=inspect_template_name,
-            deidentify_template_name=deidentify_template_name,
+            request=dict(
+                parent=parent,
+                deidentify_config=deidentify_config,
+                inspect_config=inspect_config,
+                item=item,
+                inspect_template_name=inspect_template_name,
+                deidentify_template_name=deidentify_template_name,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     def delete_deidentify_template(
         self, template_id, organization_id=None, project_id=None, retry=DEFAULT, timeout=None, metadata=()
@@ -478,21 +506,28 @@
         if not template_id:
             raise AirflowException("Please provide the ID of deidentify template to be deleted.")
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_deidentify_template_path(organization_id, template_id)
+            name = DlpServiceClient.deidentify_template_path(organization_id, template_id)
         elif project_id:
-            name = DlpServiceClient.project_deidentify_template_path(project_id, template_id)
+            name = self._project_deidentify_template_path(project_id, template_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
-        client.delete_deidentify_template(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        client.delete_deidentify_template(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def delete_dlp_job(
         self,
         dlp_job_id: str,
         project_id: str,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -516,15 +551,22 @@
         """
         client = self.get_conn()
 
         if not dlp_job_id:
             raise AirflowException("Please provide the ID of the DLP job resource to be cancelled.")
 
         name = DlpServiceClient.dlp_job_path(project_id, dlp_job_id)
-        client.delete_dlp_job(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        client.delete_dlp_job(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     def delete_inspect_template(
         self,
         template_id: str,
         organization_id: str | None = None,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -552,21 +594,28 @@
         if not template_id:
             raise AirflowException("Please provide the ID of the inspect template to be deleted.")
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_inspect_template_path(organization_id, template_id)
+            name = DlpServiceClient.inspect_template_path(organization_id, template_id)
         elif project_id:
-            name = DlpServiceClient.project_inspect_template_path(project_id, template_id)
+            name = self._project_inspect_template_path(project_id, template_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
-        client.delete_inspect_template(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        client.delete_inspect_template(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def delete_job_trigger(
         self,
         job_trigger_id: str,
         project_id: str,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -588,16 +637,23 @@
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
         if not job_trigger_id:
             raise AirflowException("Please provide the ID of the DLP job trigger to be deleted.")
 
-        name = DlpServiceClient.project_job_trigger_path(project_id, job_trigger_id)
-        client.delete_job_trigger(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        name = DlpServiceClient.job_trigger_path(project_id, job_trigger_id)
+        client.delete_job_trigger(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     def delete_stored_info_type(
         self,
         stored_info_type_id: str,
         organization_id: str | None = None,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -625,21 +681,28 @@
         if not stored_info_type_id:
             raise AirflowException("Please provide the ID of the stored info type to be deleted.")
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_stored_info_type_path(organization_id, stored_info_type_id)
+            name = DlpServiceClient.stored_info_type_path(organization_id, stored_info_type_id)
         elif project_id:
-            name = DlpServiceClient.project_stored_info_type_path(project_id, stored_info_type_id)
+            name = self._project_stored_info_type_path(project_id, stored_info_type_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
-        client.delete_stored_info_type(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        client.delete_stored_info_type(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     def get_deidentify_template(
         self,
         template_id: str,
         organization_id: str | None = None,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -667,21 +730,28 @@
         if not template_id:
             raise AirflowException("Please provide the ID of the deidentify template to be read.")
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_deidentify_template_path(organization_id, template_id)
+            name = DlpServiceClient.deidentify_template_path(organization_id, template_id)
         elif project_id:
-            name = DlpServiceClient.project_deidentify_template_path(project_id, template_id)
+            name = self._project_deidentify_template_path(project_id, template_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
-        return client.get_deidentify_template(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        return client.get_deidentify_template(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def get_dlp_job(
         self,
         dlp_job_id: str,
         project_id: str,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -704,15 +774,22 @@
         """
         client = self.get_conn()
 
         if not dlp_job_id:
             raise AirflowException("Please provide the ID of the DLP job resource to be read.")
 
         name = DlpServiceClient.dlp_job_path(project_id, dlp_job_id)
-        return client.get_dlp_job(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        return client.get_dlp_job(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     def get_inspect_template(
         self,
         template_id: str,
         organization_id: str | None = None,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -740,21 +817,28 @@
         if not template_id:
             raise AirflowException("Please provide the ID of the inspect template to be read.")
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_inspect_template_path(organization_id, template_id)
+            name = DlpServiceClient.inspect_template_path(organization_id, template_id)
         elif project_id:
-            name = DlpServiceClient.project_inspect_template_path(project_id, template_id)
+            name = self._project_inspect_template_path(project_id, template_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
-        return client.get_inspect_template(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        return client.get_inspect_template(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def get_job_trigger(
         self,
         job_trigger_id: str,
         project_id: str,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -776,16 +860,23 @@
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
         if not job_trigger_id:
             raise AirflowException("Please provide the ID of the DLP job trigger to be read.")
 
-        name = DlpServiceClient.project_job_trigger_path(project_id, job_trigger_id)
-        return client.get_job_trigger(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        name = DlpServiceClient.job_trigger_path(project_id, job_trigger_id)
+        return client.get_job_trigger(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     def get_stored_info_type(
         self,
         stored_info_type_id: str,
         organization_id: str | None = None,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
@@ -813,21 +904,28 @@
         if not stored_info_type_id:
             raise AirflowException("Please provide the ID of the stored info type to be read.")
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_stored_info_type_path(organization_id, stored_info_type_id)
+            name = DlpServiceClient.stored_info_type_path(organization_id, stored_info_type_id)
         elif project_id:
-            name = DlpServiceClient.project_stored_info_type_path(project_id, stored_info_type_id)
+            name = self._project_stored_info_type_path(project_id, stored_info_type_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
-        return client.get_stored_info_type(name=name, retry=retry, timeout=timeout, metadata=metadata)
+        return client.get_stored_info_type(
+            request=dict(
+                name=name,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def inspect_content(
         self,
         project_id: str,
         inspect_config: dict | InspectConfig | None = None,
         item: dict | ContentItem | None = None,
@@ -853,20 +951,22 @@
         :param timeout: (Optional) The amount of time, in seconds, to wait for the request
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
-        parent = DlpServiceClient.project_path(project_id)
+        parent = DlpServiceClient.common_project_path(project_id)
         return client.inspect_content(
-            parent=parent,
-            inspect_config=inspect_config,
-            item=item,
-            inspect_template_name=inspect_template_name,
+            request=dict(
+                parent=parent,
+                inspect_config=inspect_config,
+                item=item,
+                inspect_template_name=inspect_template_name,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     def list_deidentify_templates(
         self,
@@ -899,24 +999,26 @@
         """
         client = self.get_conn()
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            parent = DlpServiceClient.organization_path(organization_id)
+            parent = DlpServiceClient.common_organization_path(organization_id)
         elif project_id:
-            parent = DlpServiceClient.project_path(project_id)
+            parent = DlpServiceClient.common_project_path(project_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         results = client.list_deidentify_templates(
-            parent=parent,
-            page_size=page_size,
-            order_by=order_by,
+            request=dict(
+                parent=parent,
+                page_size=page_size,
+                order_by=order_by,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         return list(results)
 
@@ -949,21 +1051,23 @@
         :param timeout: (Optional) The amount of time, in seconds, to wait for the request
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
-        parent = DlpServiceClient.project_path(project_id)
+        parent = DlpServiceClient.common_project_path(project_id)
         results = client.list_dlp_jobs(
-            parent=parent,
-            filter_=results_filter,
-            page_size=page_size,
-            type_=job_type,
-            order_by=order_by,
+            request=dict(
+                parent=parent,
+                filter=results_filter,
+                page_size=page_size,
+                type_=job_type,
+                order_by=order_by,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
         return list(results)
 
     def list_info_types(
@@ -987,16 +1091,18 @@
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
         return client.list_info_types(
-            language_code=language_code,
-            filter_=results_filter,
+            request=dict(
+                language_code=language_code,
+                filter=results_filter,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     def list_inspect_templates(
         self,
@@ -1029,24 +1135,26 @@
         """
         client = self.get_conn()
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            parent = DlpServiceClient.organization_path(organization_id)
+            parent = DlpServiceClient.common_organization_path(organization_id)
         elif project_id:
-            parent = DlpServiceClient.project_path(project_id)
+            parent = DlpServiceClient.common_project_path(project_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         results = client.list_inspect_templates(
-            parent=parent,
-            page_size=page_size,
-            order_by=order_by,
+            request=dict(
+                parent=parent,
+                page_size=page_size,
+                order_by=order_by,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
         return list(results)
 
     @GoogleBaseHook.fallback_to_default_project_id
@@ -1076,20 +1184,22 @@
         :param timeout: (Optional) The amount of time, in seconds, to wait for the request
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
-        parent = DlpServiceClient.project_path(project_id)
+        parent = DlpServiceClient.common_project_path(project_id)
         results = client.list_job_triggers(
-            parent=parent,
-            page_size=page_size,
-            order_by=order_by,
-            filter_=results_filter,
+            request=dict(
+                parent=parent,
+                page_size=page_size,
+                order_by=order_by,
+                filter=results_filter,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
         return list(results)
 
     def list_stored_info_types(
@@ -1123,24 +1233,26 @@
         """
         client = self.get_conn()
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            parent = DlpServiceClient.organization_path(organization_id)
+            parent = DlpServiceClient.common_organization_path(organization_id)
         elif project_id:
-            parent = DlpServiceClient.project_path(project_id)
+            parent = DlpServiceClient.common_project_path(project_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         results = client.list_stored_info_types(
-            parent=parent,
-            page_size=page_size,
-            order_by=order_by,
+            request=dict(
+                parent=parent,
+                page_size=page_size,
+                order_by=order_by,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
         return list(results)
 
     @GoogleBaseHook.fallback_to_default_project_id
@@ -1175,21 +1287,23 @@
         :param timeout: (Optional) The amount of time, in seconds, to wait for the request
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
-        parent = DlpServiceClient.project_path(project_id)
+        parent = DlpServiceClient.common_project_path(project_id)
         return client.redact_image(
-            parent=parent,
-            inspect_config=inspect_config,
-            image_redaction_configs=image_redaction_configs,
-            include_findings=include_findings,
-            byte_item=byte_item,
+            request=dict(
+                parent=parent,
+                inspect_config=inspect_config,
+                image_redaction_configs=image_redaction_configs,
+                include_findings=include_findings,
+                byte_item=byte_item,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def reidentify_content(
@@ -1224,22 +1338,24 @@
         :param timeout: (Optional) The amount of time, in seconds, to wait for the request
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
-        parent = DlpServiceClient.project_path(project_id)
+        parent = DlpServiceClient.common_project_path(project_id)
         return client.reidentify_content(
-            parent=parent,
-            reidentify_config=reidentify_config,
-            inspect_config=inspect_config,
-            item=item,
-            inspect_template_name=inspect_template_name,
-            reidentify_template_name=reidentify_template_name,
+            request=dict(
+                parent=parent,
+                reidentify_config=reidentify_config,
+                inspect_config=inspect_config,
+                item=item,
+                inspect_template_name=inspect_template_name,
+                reidentify_template_name=reidentify_template_name,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     def update_deidentify_template(
         self,
@@ -1275,24 +1391,26 @@
         if not template_id:
             raise AirflowException("Please provide the ID of deidentify template to be updated.")
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_deidentify_template_path(organization_id, template_id)
+            name = DlpServiceClient.deidentify_template_path(organization_id, template_id)
         elif project_id:
-            name = DlpServiceClient.project_deidentify_template_path(project_id, template_id)
+            name = self._project_deidentify_template_path(project_id, template_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         return client.update_deidentify_template(
-            name=name,
-            deidentify_template=deidentify_template,
-            update_mask=update_mask,
+            request=dict(
+                name=name,
+                deidentify_template=deidentify_template,
+                update_mask=update_mask,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     def update_inspect_template(
         self,
@@ -1327,24 +1445,26 @@
 
         if not template_id:
             raise AirflowException("Please provide the ID of the inspect template to be updated.")
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_inspect_template_path(organization_id, template_id)
+            name = DlpServiceClient.inspect_template_path(organization_id, template_id)
         elif project_id:
-            name = DlpServiceClient.project_inspect_template_path(project_id, template_id)
+            name = self._project_inspect_template_path(project_id, template_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         return client.update_inspect_template(
-            name=name,
-            inspect_template=inspect_template,
-            update_mask=update_mask,
+            request=dict(
+                name=name,
+                inspect_template=inspect_template,
+                update_mask=update_mask,
+            ),
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
     @GoogleBaseHook.fallback_to_default_project_id
     def update_job_trigger(
@@ -1371,18 +1491,24 @@
         :param timeout: (Optional) The amount of time, in seconds, to wait for the request
             to complete. Note that if retry is specified, the timeout applies to each
             individual attempt.
         :param metadata: (Optional) Additional metadata that is provided to the method.
         """
         client = self.get_conn()
 
+        if isinstance(job_trigger, dict):
+            job_trigger = JobTrigger(**job_trigger)
+
+        if isinstance(update_mask, dict):
+            update_mask = FieldMask(**update_mask)
+
         if not job_trigger_id:
             raise AirflowException("Please provide the ID of the DLP job trigger to be updated.")
 
-        name = DlpServiceClient.project_job_trigger_path(project_id, job_trigger_id)
+        name = DlpServiceClient.job_trigger_path(project_id, job_trigger_id)
         return client.update_job_trigger(
             name=name,
             job_trigger=job_trigger,
             update_mask=update_mask,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
@@ -1423,16 +1549,23 @@
         if not stored_info_type_id:
             raise AirflowException("Please provide the ID of the stored info type to be updated.")
 
         # Handle project_id from connection configuration
         project_id = project_id or self.project_id
 
         if organization_id:
-            name = DlpServiceClient.organization_stored_info_type_path(organization_id, stored_info_type_id)
+            name = DlpServiceClient.stored_info_type_path(organization_id, stored_info_type_id)
         elif project_id:
-            name = DlpServiceClient.project_stored_info_type_path(project_id, stored_info_type_id)
+            name = self._project_stored_info_type_path(project_id, stored_info_type_id)
         else:
             raise AirflowException("Please provide either organization_id or project_id.")
 
         return client.update_stored_info_type(
-            name=name, config=config, update_mask=update_mask, retry=retry, timeout=timeout, metadata=metadata
+            request=dict(
+                name=name,
+                config=config,
+                update_mask=update_mask,
+            ),
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
         )
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/functions.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/functions.py`

 * *Files 1% similar despite different names*

```diff
@@ -36,15 +36,15 @@
     """
     Hook for the Google Cloud Functions APIs.
 
     All the methods in the hook where project_id is used must be called with
     keyword arguments rather than positional.
     """
 
-    _conn = None
+    _conn: build | None = None
 
     def __init__(
         self,
         api_version: str,
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/gcs.py`

 * *Files 2% similar despite different names*

```diff
@@ -47,16 +47,26 @@
 from airflow.exceptions import AirflowException
 from airflow.providers.google.cloud.utils.helpers import normalize_directory_path
 from airflow.providers.google.common.consts import CLIENT_INFO
 from airflow.providers.google.common.hooks.base_google import GoogleBaseAsyncHook, GoogleBaseHook
 from airflow.utils import timezone
 from airflow.version import version
 
+try:
+    # Airflow 2.3 doesn't have this yet
+    from airflow.typing_compat import ParamSpec
+except ImportError:
+    try:
+        from typing import ParamSpec  # type: ignore[no-redef, attr-defined]
+    except ImportError:
+        from typing_extensions import ParamSpec
+
 RT = TypeVar("RT")
 T = TypeVar("T", bound=Callable)
+FParams = ParamSpec("FParams")
 
 # GCSHook has a method named 'list' (to junior devs: please don't do this), so
 # we need to create an alias to prevent Mypy being confused.
 List = list
 
 # Use default timeout from google-cloud-storage
 DEFAULT_TIMEOUT = 60
@@ -72,17 +82,17 @@
 
     :param object_url_keyword_arg_name: Name of the object URL parameter
     :param bucket_name_keyword_arg_name: Name of the bucket name parameter
     :param object_name_keyword_arg_name: Name of the object name parameter
     :return: Decorator
     """
 
-    def _wrapper(func: T):
+    def _wrapper(func: Callable[FParams, RT]) -> Callable[FParams, RT]:
         @functools.wraps(func)
-        def _inner_wrapper(self: GCSHook, *args, **kwargs) -> RT:
+        def _inner_wrapper(self, *args, **kwargs) -> RT:
             if args:
                 raise AirflowException(
                     "You must use keyword arguments in this methods rather than positional"
                 )
 
             object_url = kwargs.get(object_url_keyword_arg_name)
             bucket_name = kwargs.get(bucket_name_keyword_arg_name)
@@ -115,17 +125,17 @@
                 raise TypeError(
                     f"{func.__name__}() missing 1 required positional argument: "
                     f"'{bucket_name_keyword_arg_name}'"
                 )
 
             return func(self, *args, **kwargs)
 
-        return cast(T, _inner_wrapper)
+        return cast(Callable[FParams, RT], _inner_wrapper)
 
-    return _wrapper
+    return cast(Callable[[T], T], _wrapper)
 
 
 # A fake bucket to use in functions decorated by _fallback_object_url_to_object_name_and_bucket_name.
 # This allows the 'bucket' argument to be of type str instead of str | None,
 # making it easier to type hint the function body without dealing with the None
 # case that can never happen at runtime.
 PROVIDE_BUCKET: str = cast(str, None)
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/gdm.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/gdm.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/kms.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/kms.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/life_sciences.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/life_sciences.py`

 * *Files 0% similar despite different names*

```diff
@@ -50,15 +50,15 @@
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account.
     """
 
-    _conn = None
+    _conn: build | None = None
 
     def __init__(
         self,
         api_version: str = "v2beta",
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/looker.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/looker.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/mlengine.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/mlengine.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/natural_language.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/natural_language.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/os_login.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/os_login.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/pubsub.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/pubsub.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/secret_manager.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/secret_manager.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/spanner.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/spanner.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/speech_to_text.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/speech_to_text.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/stackdriver.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/stackdriver.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/tasks.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/tasks.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/text_to_speech.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/text_to_speech.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/translate.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/translate.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/auto_ml.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/auto_ml.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/batch_prediction_job.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/batch_prediction_job.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/custom_job.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/custom_job.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/dataset.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/dataset.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/endpoint_service.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/endpoint_service.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/hyperparameter_tuning_job.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/hyperparameter_tuning_job.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/model_service.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vertex_ai/model_service.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/video_intelligence.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/video_intelligence.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/vision.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/vision.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/hooks/workflows.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/hooks/workflows.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/automl.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/automl.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/base.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/base.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/bigquery.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/bigquery.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/bigquery_dts.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/bigquery_dts.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/bigtable.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/bigtable.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_build.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_build.py`

 * *Files 15% similar despite different names*

```diff
@@ -21,21 +21,23 @@
 from airflow.providers.google.cloud.links.base import BaseGoogleLink
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 BUILD_BASE_LINK = "/cloud-build"
 
-BUILD_LINK = BUILD_BASE_LINK + "/builds/{build_id}?project={project_id}"
+BUILD_LINK = BUILD_BASE_LINK + "/builds;region={region}/{build_id}?project={project_id}"
 
-BUILD_LIST_LINK = BUILD_BASE_LINK + "/builds?project={project_id}"
+BUILD_LIST_LINK = BUILD_BASE_LINK + "/builds;region={region}?project={project_id}"
 
-BUILD_TRIGGERS_LIST_LINK = BUILD_BASE_LINK + "/triggers?project={project_id}"
+BUILD_TRIGGERS_LIST_LINK = BUILD_BASE_LINK + "/triggers;region={region}?project={project_id}"
 
-BUILD_TRIGGER_DETAILS_LINK = BUILD_BASE_LINK + "/triggers/edit/{trigger_id}?project={project_id}"
+BUILD_TRIGGER_DETAILS_LINK = (
+    BUILD_BASE_LINK + "/triggers;region={region}/edit/{trigger_id}?project={project_id}"
+)
 
 
 class CloudBuildLink(BaseGoogleLink):
     """Helper class for constructing Cloud Build link"""
 
     name = "Cloud Build Details"
     key = "cloud_build_key"
@@ -43,20 +45,22 @@
 
     @staticmethod
     def persist(
         context: Context,
         task_instance,
         build_id: str,
         project_id: str,
+        region: str,
     ):
         task_instance.xcom_push(
             context=context,
             key=CloudBuildLink.key,
             value={
                 "project_id": project_id,
+                "region": region,
                 "build_id": build_id,
             },
         )
 
 
 class CloudBuildListLink(BaseGoogleLink):
     """Helper class for constructing Cloud Build List link"""
@@ -66,20 +70,22 @@
     format_str = BUILD_LIST_LINK
 
     @staticmethod
     def persist(
         context: Context,
         task_instance,
         project_id: str,
+        region: str,
     ):
         task_instance.xcom_push(
             context=context,
             key=CloudBuildListLink.key,
             value={
                 "project_id": project_id,
+                "region": region,
             },
         )
 
 
 class CloudBuildTriggersListLink(BaseGoogleLink):
     """Helper class for constructing Cloud Build Triggers List link"""
 
@@ -88,20 +94,22 @@
     format_str = BUILD_TRIGGERS_LIST_LINK
 
     @staticmethod
     def persist(
         context: Context,
         task_instance,
         project_id: str,
+        region: str,
     ):
         task_instance.xcom_push(
             context=context,
             key=CloudBuildTriggersListLink.key,
             value={
                 "project_id": project_id,
+                "region": region,
             },
         )
 
 
 class CloudBuildTriggerDetailsLink(BaseGoogleLink):
     """Helper class for constructing Cloud Build Trigger Details link"""
 
@@ -110,17 +118,19 @@
     format_str = BUILD_TRIGGER_DETAILS_LINK
 
     @staticmethod
     def persist(
         context: Context,
         task_instance,
         project_id: str,
+        region: str,
         trigger_id: str,
     ):
         task_instance.xcom_push(
             context=context,
             key=CloudBuildTriggerDetailsLink.key,
             value={
                 "project_id": project_id,
+                "region": region,
                 "trigger_id": trigger_id,
             },
         )
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_functions.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_functions.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_memorystore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_memorystore.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_sql.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_sql.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_storage_transfer.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_storage_transfer.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/cloud_tasks.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/cloud_tasks.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/compute.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/compute.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/data_loss_prevention.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/data_loss_prevention.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/datacatalog.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/datacatalog.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataflow.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataflow.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataform.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataform.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/datafusion.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/datafusion.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataplex.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataplex.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataprep.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataprep.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/dataproc.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/dataproc.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/datastore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/datastore.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/kubernetes_engine.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/kubernetes_engine.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/life_sciences.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/life_sciences.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/mlengine.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/mlengine.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/pubsub.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/pubsub.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/spanner.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/spanner.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/stackdriver.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/stackdriver.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/vertex_ai.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/vertex_ai.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/links/workflows.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/links/workflows.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/log/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/log/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/log/gcs_task_handler.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/log/gcs_task_handler.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,19 +15,21 @@
 # KIND, either express or implied.  See the License for the
 # specific language governing permissions and limitations
 # under the License.
 from __future__ import annotations
 
 import logging
 import os
+import shutil
 from pathlib import Path
 from typing import Collection
 
 # not sure why but mypy complains on missing `storage` but it is clearly there and is importable
 from google.cloud import storage  # type: ignore[attr-defined]
+from packaging.version import Version
 
 from airflow.compat.functools import cached_property
 from airflow.configuration import conf
 from airflow.exceptions import AirflowNotFoundException
 from airflow.providers.google.cloud.hooks.gcs import GCSHook, _parse_gcs_url
 from airflow.providers.google.cloud.utils.credentials_provider import get_credentials_and_project_id
 from airflow.providers.google.common.consts import CLIENT_INFO
@@ -39,14 +41,25 @@
         "https://www.googleapis.com/auth/devstorage.read_write",
     ]
 )
 
 logger = logging.getLogger(__name__)
 
 
+def get_default_delete_local_copy():
+    """Load delete_local_logs conf if Airflow version > 2.6 and return False if not
+    TODO: delete this function when min airflow version >= 2.6
+    """
+    from airflow.version import version
+
+    if Version(version) < Version("2.6"):
+        return False
+    return conf.getboolean("logging", "delete_local_logs")
+
+
 class GCSTaskHandler(FileTaskHandler, LoggingMixin):
     """
     GCSTaskHandler is a python log handler that handles and reads
     task instance logs. It extends airflow FileTaskHandler and
     uploads to and reads from GCS remote storage. Upon log reading
     failure, it reads from host machine's local disk.
 
@@ -59,38 +72,44 @@
         If omitted, authorization based on `the Application Default Credentials
         <https://cloud.google.com/docs/authentication/production#finding_credentials_automatically>`__ will
         be used.
     :param gcp_keyfile_dict: Dictionary of keyfile parameters. Mutually exclusive with gcp_key_path.
     :param gcp_scopes: Comma-separated string containing OAuth2 scopes
     :param project_id: Project ID to read the secrets from. If not passed, the project ID from credentials
         will be used.
+    :param delete_local_copy: Whether local log files should be deleted after they are downloaded when using
+        remote logging
     """
 
     trigger_should_wrap = True
 
     def __init__(
         self,
         *,
         base_log_folder: str,
         gcs_log_folder: str,
         filename_template: str | None = None,
         gcp_key_path: str | None = None,
         gcp_keyfile_dict: dict | None = None,
         gcp_scopes: Collection[str] | None = _DEFAULT_SCOPESS,
         project_id: str | None = None,
+        **kwargs,
     ):
         super().__init__(base_log_folder, filename_template)
         self.remote_base = gcs_log_folder
         self.log_relative_path = ""
         self.closed = False
         self.upload_on_close = True
         self.gcp_key_path = gcp_key_path
         self.gcp_keyfile_dict = gcp_keyfile_dict
         self.scopes = gcp_scopes
         self.project_id = project_id
+        self.delete_local_copy = (
+            kwargs["delete_local_copy"] if "delete_local_copy" in kwargs else get_default_delete_local_copy()
+        )
 
     @cached_property
     def hook(self) -> GCSHook | None:
         """Returns GCSHook if remote_log_conn_id configured."""
         conn_id = conf.get("logging", "remote_log_conn_id", fallback=None)
         if conn_id:
             try:
@@ -143,15 +162,17 @@
 
         local_loc = os.path.join(self.local_base, self.log_relative_path)
         remote_loc = os.path.join(self.remote_base, self.log_relative_path)
         if os.path.exists(local_loc):
             # read log and remove old logs to get just the latest additions
             with open(local_loc) as logfile:
                 log = logfile.read()
-            self.gcs_write(log, remote_loc)
+            gcs_write = self.gcs_write(log, remote_loc)
+            if gcs_write and self.delete_local_copy:
+                shutil.rmtree(os.path.dirname(local_loc))
 
         # Mark closed so we don't double write if close is called twice
         self.closed = True
 
     def _add_message(self, msg):
         filename, lineno, func, stackinfo = logger.findCaller()
         record = logging.LogRecord("", logging.INFO, filename, lineno, msg + "\n", None, None, func=func)
@@ -203,21 +224,22 @@
 
         messages, logs = self._read_remote_logs(ti, try_number, metadata)
         if not logs:
             return super()._read(ti, try_number, metadata)
 
         return "".join([f"*** {x}\n" for x in messages]) + "\n".join(logs), {"end_of_log": True}
 
-    def gcs_write(self, log, remote_log_location):
+    def gcs_write(self, log, remote_log_location) -> bool:
         """
-        Writes the log to the remote_log_location. Fails silently if no log
-        was created.
+        Writes the log to the remote_log_location and return `True` when done. Fails silently
+         and return `False` if no log was created.
 
         :param log: the log to write to the remote_log_location
         :param remote_log_location: the log's location in remote storage
+        :return: whether the log is successfully written to remote location or not.
         """
         try:
             blob = storage.Blob.from_string(remote_log_location, self.client)
             old_log = blob.download_as_bytes().decode()
             log = "\n".join([old_log, log]) if old_log else log
         except Exception as e:
             if self.no_log_found(e):
@@ -228,14 +250,16 @@
                 )
                 self.log.warning("Error checking for previous log: %s", e)
         try:
             blob = storage.Blob.from_string(remote_log_location, self.client)
             blob.upload_from_string(log, content_type="text/plain")
         except Exception as e:
             self.log.error("Could not write logs to %s: %s", remote_log_location, e)
+            return False
+        return True
 
     @staticmethod
     def no_log_found(exc):
         """
         Given exception, determine whether it is result of log not found.
 
         :meta private:
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/log/stackdriver_task_handler.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/log/stackdriver_task_handler.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/automl.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/automl.py`

 * *Files 1% similar despite different names*

```diff
@@ -28,31 +28,31 @@
     ColumnSpec,
     Dataset,
     Model,
     PredictResponse,
     TableSpec,
 )
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.automl import CloudAutoMLHook
 from airflow.providers.google.cloud.links.automl import (
     AutoMLDatasetLink,
     AutoMLDatasetListLink,
     AutoMLModelLink,
     AutoMLModelPredictLink,
     AutoMLModelTrainLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 MetaData = Sequence[Tuple[str, str]]
 
 
-class AutoMLTrainModelOperator(BaseOperator):
+class AutoMLTrainModelOperator(GoogleCloudBaseOperator):
     """
     Creates Google Cloud AutoML model.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLTrainModelOperator`
 
@@ -140,15 +140,15 @@
                 dataset_id=self.model["dataset_id"] or "-",
                 model_id=model_id,
                 project_id=project_id,
             )
         return result
 
 
-class AutoMLPredictOperator(BaseOperator):
+class AutoMLPredictOperator(GoogleCloudBaseOperator):
     """
     Runs prediction operation on Google Cloud AutoML.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLPredictOperator`
 
@@ -232,15 +232,15 @@
                 task_instance=self,
                 model_id=self.model_id,
                 project_id=project_id,
             )
         return PredictResponse.to_dict(result)
 
 
-class AutoMLBatchPredictOperator(BaseOperator):
+class AutoMLBatchPredictOperator(GoogleCloudBaseOperator):
     """
     Perform a batch prediction on Google Cloud AutoML.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLBatchPredictOperator`
 
@@ -341,15 +341,15 @@
                 task_instance=self,
                 model_id=self.model_id,
                 project_id=project_id,
             )
         return result
 
 
-class AutoMLCreateDatasetOperator(BaseOperator):
+class AutoMLCreateDatasetOperator(GoogleCloudBaseOperator):
     """
     Creates a Google Cloud AutoML dataset.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLCreateDatasetOperator`
 
@@ -433,15 +433,15 @@
                 task_instance=self,
                 dataset_id=dataset_id,
                 project_id=project_id,
             )
         return result
 
 
-class AutoMLImportDataOperator(BaseOperator):
+class AutoMLImportDataOperator(GoogleCloudBaseOperator):
     """
     Imports data to a Google Cloud AutoML dataset.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLImportDataOperator`
 
@@ -526,15 +526,15 @@
                 context=context,
                 task_instance=self,
                 dataset_id=self.dataset_id,
                 project_id=project_id,
             )
 
 
-class AutoMLTablesListColumnSpecsOperator(BaseOperator):
+class AutoMLTablesListColumnSpecsOperator(GoogleCloudBaseOperator):
     """
     Lists column specs in a table.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLTablesListColumnSpecsOperator`
 
@@ -636,15 +636,15 @@
                 task_instance=self,
                 dataset_id=self.dataset_id,
                 project_id=project_id,
             )
         return result
 
 
-class AutoMLTablesUpdateDatasetOperator(BaseOperator):
+class AutoMLTablesUpdateDatasetOperator(GoogleCloudBaseOperator):
     """
     Updates a dataset.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLTablesUpdateDatasetOperator`
 
@@ -723,15 +723,15 @@
                 task_instance=self,
                 dataset_id=hook.extract_object_id(self.dataset),
                 project_id=project_id,
             )
         return Dataset.to_dict(result)
 
 
-class AutoMLGetModelOperator(BaseOperator):
+class AutoMLGetModelOperator(GoogleCloudBaseOperator):
     """
     Get Google Cloud AutoML model.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLGetModelOperator`
 
@@ -810,15 +810,15 @@
                 dataset_id=model["dataset_id"],
                 model_id=self.model_id,
                 project_id=project_id,
             )
         return model
 
 
-class AutoMLDeleteModelOperator(BaseOperator):
+class AutoMLDeleteModelOperator(GoogleCloudBaseOperator):
     """
     Delete Google Cloud AutoML model.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLDeleteModelOperator`
 
@@ -886,15 +886,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         operation.result()
 
 
-class AutoMLDeployModelOperator(BaseOperator):
+class AutoMLDeployModelOperator(GoogleCloudBaseOperator):
     """
     Deploys a model. If a model is already deployed, deploying it with the same parameters
     has no effect. Deploying with different parameters (as e.g. changing node_number) will
     reset the deployment state without pausing the model_id's availability.
 
     Only applicable for Text Classification, Image Object Detection and Tables; all other
     domains manage deployment automatically.
@@ -976,15 +976,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         operation.result()
         self.log.info("Model deployed.")
 
 
-class AutoMLTablesListTableSpecsOperator(BaseOperator):
+class AutoMLTablesListTableSpecsOperator(GoogleCloudBaseOperator):
     """
     Lists table specs in a dataset.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLTablesListTableSpecsOperator`
 
@@ -1076,15 +1076,15 @@
                 task_instance=self,
                 dataset_id=self.dataset_id,
                 project_id=project_id,
             )
         return result
 
 
-class AutoMLListDatasetOperator(BaseOperator):
+class AutoMLListDatasetOperator(GoogleCloudBaseOperator):
     """
     Lists AutoML Datasets in project.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLListDatasetOperator`
 
@@ -1158,15 +1158,15 @@
         )
         project_id = self.project_id or hook.project_id
         if project_id:
             AutoMLDatasetListLink.persist(context=context, task_instance=self, project_id=project_id)
         return result
 
 
-class AutoMLDeleteDatasetOperator(BaseOperator):
+class AutoMLDeleteDatasetOperator(GoogleCloudBaseOperator):
     """
     Deletes a dataset and all of its contents.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:AutoMLDeleteDatasetOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/bigquery.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/bigquery.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,28 +24,29 @@
 from typing import TYPE_CHECKING, Any, Iterable, Sequence, SupportsAbs
 
 import attr
 from google.api_core.exceptions import Conflict
 from google.api_core.retry import Retry
 from google.cloud.bigquery import DEFAULT_RETRY, CopyJob, ExtractJob, LoadJob, QueryJob
 
-from airflow.exceptions import AirflowException
+from airflow.exceptions import AirflowException, AirflowSkipException
 from airflow.models import BaseOperator, BaseOperatorLink
 from airflow.models.xcom import XCom
 from airflow.providers.common.sql.operators.sql import (
     SQLCheckOperator,
     SQLColumnCheckOperator,
     SQLIntervalCheckOperator,
     SQLTableCheckOperator,
     SQLValueCheckOperator,
     _parse_boolean,
 )
 from airflow.providers.google.cloud.hooks.bigquery import BigQueryHook, BigQueryJob
 from airflow.providers.google.cloud.hooks.gcs import GCSHook, _parse_gcs_url
 from airflow.providers.google.cloud.links.bigquery import BigQueryDatasetLink, BigQueryTableLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.triggers.bigquery import (
     BigQueryCheckTrigger,
     BigQueryGetDataTrigger,
     BigQueryInsertJobTrigger,
     BigQueryIntervalCheckTrigger,
     BigQueryValueCheckTrigger,
 )
@@ -63,14 +64,23 @@
 
     CHECK = "#C0D7FF"
     QUERY = "#A1BBFF"
     TABLE = "#81A0FF"
     DATASET = "#5F86FF"
 
 
+class IfExistAction(enum.Enum):
+    """Action to take if the resource exist"""
+
+    IGNORE = "ignore"
+    LOG = "log"
+    FAIL = "fail"
+    SKIP = "skip"
+
+
 class BigQueryConsoleLink(BaseOperatorLink):
     """Helper class for constructing BigQuery link."""
 
     name = "BigQuery Console"
 
     def get_link(
         self,
@@ -163,14 +173,16 @@
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     :param labels: a dictionary containing labels for the table, passed to BigQuery
     :param deferrable: Run operator in the deferrable mode
+    :param poll_interval: (Deferrable mode only) polling period in seconds to check for the status of job.
+        Defaults to 4 seconds.
     """
 
     template_fields: Sequence[str] = (
         "sql",
         "gcp_conn_id",
         "impersonation_chain",
         "labels",
@@ -184,24 +196,26 @@
         sql: str,
         gcp_conn_id: str = "google_cloud_default",
         use_legacy_sql: bool = True,
         location: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         labels: dict | None = None,
         deferrable: bool = False,
+        poll_interval: float = 4.0,
         **kwargs,
     ) -> None:
         super().__init__(sql=sql, **kwargs)
         self.gcp_conn_id = gcp_conn_id
         self.sql = sql
         self.use_legacy_sql = use_legacy_sql
         self.location = location
         self.impersonation_chain = impersonation_chain
         self.labels = labels
         self.deferrable = deferrable
+        self.poll_interval = poll_interval
 
     def _submit_job(
         self,
         hook: BigQueryHook,
         job_id: str,
     ) -> BigQueryJob:
         """Submit a new job and get the job id for polling the status using Trigger."""
@@ -226,14 +240,15 @@
             context["ti"].xcom_push(key="job_id", value=job.job_id)
             self.defer(
                 timeout=self.execution_timeout,
                 trigger=BigQueryCheckTrigger(
                     conn_id=self.gcp_conn_id,
                     job_id=job.job_id,
                     project_id=hook.project_id,
+                    poll_interval=self.poll_interval,
                 ),
                 method_name="execute_complete",
             )
 
     def execute_complete(self, context: Context, event: dict[str, Any]) -> None:
         """
         Callback for when the trigger fires - returns immediately.
@@ -243,15 +258,17 @@
         if event["status"] == "error":
             raise AirflowException(event["message"])
 
         records = event["records"]
         if not records:
             raise AirflowException("The query returned empty results")
         elif not all(bool(r) for r in records):
-            self._raise_exception(f"Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}")
+            self._raise_exception(  # type: ignore[attr-defined]
+                f"Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}"
+            )
         self.log.info("Record: %s", event["records"])
         self.log.info("Success.")
 
 
 class BigQueryValueCheckOperator(_BigQueryDbHookMixin, SQLValueCheckOperator):
     """
     Performs a simple value check using sql code.
@@ -272,14 +289,16 @@
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     :param labels: a dictionary containing labels for the table, passed to BigQuery
     :param deferrable: Run operator in the deferrable mode
+    :param poll_interval: (Deferrable mode only) polling period in seconds to check for the status of job.
+        Defaults to 4 seconds.
     """
 
     template_fields: Sequence[str] = (
         "sql",
         "gcp_conn_id",
         "pass_value",
         "impersonation_chain",
@@ -296,23 +315,25 @@
         tolerance: Any = None,
         gcp_conn_id: str = "google_cloud_default",
         use_legacy_sql: bool = True,
         location: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         labels: dict | None = None,
         deferrable: bool = False,
+        poll_interval: float = 4.0,
         **kwargs,
     ) -> None:
         super().__init__(sql=sql, pass_value=pass_value, tolerance=tolerance, **kwargs)
         self.location = location
         self.gcp_conn_id = gcp_conn_id
         self.use_legacy_sql = use_legacy_sql
         self.impersonation_chain = impersonation_chain
         self.labels = labels
         self.deferrable = deferrable
+        self.poll_interval = poll_interval
 
     def _submit_job(
         self,
         hook: BigQueryHook,
         job_id: str,
     ) -> BigQueryJob:
         """Submit a new job and get the job id for polling the status using Triggerer."""
@@ -344,14 +365,15 @@
                 trigger=BigQueryValueCheckTrigger(
                     conn_id=self.gcp_conn_id,
                     job_id=job.job_id,
                     project_id=hook.project_id,
                     sql=self.sql,
                     pass_value=self.pass_value,
                     tolerance=self.tol,
+                    poll_interval=self.poll_interval,
                 ),
                 method_name="execute_complete",
             )
 
     def execute_complete(self, context: Context, event: dict[str, Any]) -> None:
         """
         Callback for when the trigger fires - returns immediately.
@@ -398,14 +420,16 @@
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     :param labels: a dictionary containing labels for the table, passed to BigQuery
     :param deferrable: Run operator in the deferrable mode
+    :param poll_interval: (Deferrable mode only) polling period in seconds to check for the status of job.
+        Defaults to 4 seconds.
     """
 
     template_fields: Sequence[str] = (
         "table",
         "gcp_conn_id",
         "sql1",
         "sql2",
@@ -423,14 +447,15 @@
         days_back: SupportsAbs[int] = -7,
         gcp_conn_id: str = "google_cloud_default",
         use_legacy_sql: bool = True,
         location: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         labels: dict | None = None,
         deferrable: bool = False,
+        poll_interval: float = 4.0,
         **kwargs,
     ) -> None:
         super().__init__(
             table=table,
             metrics_thresholds=metrics_thresholds,
             date_filter_column=date_filter_column,
             days_back=days_back,
@@ -439,14 +464,15 @@
 
         self.gcp_conn_id = gcp_conn_id
         self.use_legacy_sql = use_legacy_sql
         self.location = location
         self.impersonation_chain = impersonation_chain
         self.labels = labels
         self.deferrable = deferrable
+        self.poll_interval = poll_interval
 
     def _submit_job(
         self,
         hook: BigQueryHook,
         sql: str,
         job_id: str,
     ) -> BigQueryJob:
@@ -482,14 +508,15 @@
                     project_id=hook.project_id,
                     table=self.table,
                     metrics_thresholds=self.metrics_thresholds,
                     date_filter_column=self.date_filter_column,
                     days_back=self.days_back,
                     ratio_formula=self.ratio_formula,
                     ignore_zero=self.ignore_zero,
+                    poll_interval=self.poll_interval,
                 ),
                 method_name="execute_complete",
             )
 
     def execute_complete(self, context: Context, event: dict[str, Any]) -> None:
         """
         Callback for when the trigger fires - returns immediately.
@@ -726,15 +753,15 @@
                 f"The following tests have failed:\n{', '.join(failed_tests)}"
             )
             self._raise_exception(exception_string)
 
         self.log.info("All tests have passed")
 
 
-class BigQueryGetDataOperator(BaseOperator):
+class BigQueryGetDataOperator(GoogleCloudBaseOperator):
     """
     Fetches the data from a BigQuery table (alternatively fetch data for selected columns)
     and returns data in a python list. The number of elements in the returned list will
     be equal to the number of rows fetched. Each element in the list will again be a list
     where element would represent the columns values for that row.
 
     **Example Result**: ``[['Tony', '10'], ['Mike', '20'], ['Steve', '15']]``
@@ -768,27 +795,29 @@
     :param project_id: (Optional) The name of the project where the data
         will be returned from. (templated)
     :param max_results: The maximum number of records (rows) to be fetched
         from the table. (templated)
     :param selected_fields: List of fields to return (comma-separated). If
         unspecified, all fields are returned.
     :param gcp_conn_id: (Optional) The connection ID used to connect to Google Cloud.
-    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
-        if any. For this to work, the service account making the request must have
-        domain-wide delegation enabled. Deprecated.
     :param location: The location used for the operation.
     :param impersonation_chain: Optional service account to impersonate using short-term
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     :param deferrable: Run operator in the deferrable mode
+    :param poll_interval: (Deferrable mode only) polling period in seconds to check for the status of job.
+        Defaults to 4 seconds.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled. Deprecated.
     """
 
     template_fields: Sequence[str] = (
         "dataset_id",
         "table_id",
         "project_id",
         "max_results",
@@ -802,18 +831,19 @@
         *,
         dataset_id: str,
         table_id: str,
         project_id: str | None = None,
         max_results: int = 100,
         selected_fields: str | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         location: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         deferrable: bool = False,
+        delegate_to: str | None = None,
+        poll_interval: float = 4.0,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
 
         self.dataset_id = dataset_id
         self.table_id = table_id
         self.max_results = int(max_results)
@@ -824,14 +854,15 @@
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         self.delegate_to = delegate_to
         self.location = location
         self.impersonation_chain = impersonation_chain
         self.project_id = project_id
         self.deferrable = deferrable
+        self.poll_interval = poll_interval
 
     def _submit_job(
         self,
         hook: BigQueryHook,
         job_id: str,
     ) -> BigQueryJob:
         get_query = self.generate_query()
@@ -899,14 +930,15 @@
             timeout=self.execution_timeout,
             trigger=BigQueryGetDataTrigger(
                 conn_id=self.gcp_conn_id,
                 job_id=self.job_id,
                 dataset_id=self.dataset_id,
                 table_id=self.table_id,
                 project_id=hook.project_id,
+                poll_interval=self.poll_interval,
             ),
             method_name="execute_complete",
         )
 
     def execute_complete(self, context: Context, event: dict[str, Any]) -> Any:
         """
         Callback for when the trigger fires - returns immediately.
@@ -916,15 +948,15 @@
         if event["status"] == "error":
             raise AirflowException(event["message"])
 
         self.log.info("Total extracted rows: %s", len(event["records"]))
         return event["records"]
 
 
-class BigQueryExecuteQueryOperator(BaseOperator):
+class BigQueryExecuteQueryOperator(GoogleCloudBaseOperator):
     """
     Executes BigQuery SQL queries in a specific BigQuery database.
     This operator does not assert idempotency.
 
     This operator is deprecated.
     Please use :class:`airflow.providers.google.cloud.operators.bigquery.BigQueryInsertJobOperator`
 
@@ -1136,15 +1168,15 @@
     def on_kill(self) -> None:
         super().on_kill()
         if self.hook is not None:
             self.log.info("Cancelling running query")
             self.hook.cancel_job(self.hook.running_job_id)
 
 
-class BigQueryCreateEmptyTableOperator(BaseOperator):
+class BigQueryCreateEmptyTableOperator(GoogleCloudBaseOperator):
     """
     Creates a new, empty table in the specified BigQuery dataset,
     optionally with schema.
 
     The schema to be used for the BigQuery table may be specified in one of
     two ways. You may either directly pass the schema fields in, or you may
     point the operator to a Google Cloud Storage object name. The object in
@@ -1248,15 +1280,18 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-    :param exists_ok: If ``True``, ignore "already exists" errors when creating the table.
+    :param if_exists: What should Airflow do if the table exists. If set to `log`, the TI will be passed to
+        success and an error message will be logged. Set to `ignore` to ignore the error, set to `fail` to
+        fail the TI, and set to `skip` to skip it.
+    :param exists_ok: Deprecated - use `if_exists="ignore"` instead.
     """
 
     template_fields: Sequence[str] = (
         "dataset_id",
         "table_id",
         "table_resource",
         "project_id",
@@ -1277,25 +1312,26 @@
         table_id: str,
         table_resource: dict[str, Any] | None = None,
         project_id: str | None = None,
         schema_fields: list | None = None,
         gcs_schema_object: str | None = None,
         time_partitioning: dict | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        bigquery_conn_id: str | None = None,
         google_cloud_storage_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         labels: dict | None = None,
         view: dict | None = None,
         materialized_view: dict | None = None,
         encryption_configuration: dict | None = None,
         location: str | None = None,
         cluster_fields: list[str] | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
-        exists_ok: bool = False,
+        if_exists: str = "log",
+        delegate_to: str | None = None,
+        bigquery_conn_id: str | None = None,
+        exists_ok: bool | None = None,
         **kwargs,
     ) -> None:
         if bigquery_conn_id:
             warnings.warn(
                 "The bigquery_conn_id parameter has been deprecated. Use the gcp_conn_id parameter instead.",
                 DeprecationWarning,
                 stacklevel=2,
@@ -1321,15 +1357,19 @@
         self.view = view
         self.materialized_view = materialized_view
         self.encryption_configuration = encryption_configuration
         self.location = location
         self.cluster_fields = cluster_fields
         self.table_resource = table_resource
         self.impersonation_chain = impersonation_chain
-        self.exists_ok = exists_ok
+        if exists_ok is not None:
+            warnings.warn("`exists_ok` parameter is deprecated, please use `if_exists`", DeprecationWarning)
+            self.if_exists = IfExistAction.IGNORE if exists_ok else IfExistAction.LOG
+        else:
+            self.if_exists = IfExistAction(if_exists)
 
     def execute(self, context: Context) -> None:
         bq_hook = BigQueryHook(
             gcp_conn_id=self.gcp_conn_id,
             delegate_to=self.delegate_to,
             location=self.location,
             impersonation_chain=self.impersonation_chain,
@@ -1357,31 +1397,37 @@
                 time_partitioning=self.time_partitioning,
                 cluster_fields=self.cluster_fields,
                 labels=self.labels,
                 view=self.view,
                 materialized_view=self.materialized_view,
                 encryption_configuration=self.encryption_configuration,
                 table_resource=self.table_resource,
-                exists_ok=self.exists_ok,
+                exists_ok=self.if_exists == IfExistAction.IGNORE,
             )
             BigQueryTableLink.persist(
                 context=context,
                 task_instance=self,
                 dataset_id=table.to_api_repr()["tableReference"]["datasetId"],
                 project_id=table.to_api_repr()["tableReference"]["projectId"],
                 table_id=table.to_api_repr()["tableReference"]["tableId"],
             )
             self.log.info(
                 "Table %s.%s.%s created successfully", table.project, table.dataset_id, table.table_id
             )
         except Conflict:
-            self.log.info("Table %s.%s already exists.", self.dataset_id, self.table_id)
+            error_msg = f"Table {self.dataset_id}.{self.table_id} already exists."
+            if self.if_exists == IfExistAction.LOG:
+                self.log.info(error_msg)
+            elif self.if_exists == IfExistAction.FAIL:
+                raise AirflowException(error_msg)
+            else:
+                raise AirflowSkipException(error_msg)
 
 
-class BigQueryCreateExternalTableOperator(BaseOperator):
+class BigQueryCreateExternalTableOperator(GoogleCloudBaseOperator):
     """
     Creates a new external table in the dataset with the data from Google Cloud
     Storage.
 
     The schema to be used for the BigQuery table may be specified in one of
     two ways. You may either directly pass the schema fields in, or you may
     point the operator to a Google Cloud Storage object name. The object in
@@ -1485,22 +1531,22 @@
         skip_leading_rows: int | None = None,
         field_delimiter: str | None = None,
         max_bad_records: int = 0,
         quote_character: str | None = None,
         allow_quoted_newlines: bool = False,
         allow_jagged_rows: bool = False,
         gcp_conn_id: str = "google_cloud_default",
-        bigquery_conn_id: str | None = None,
         google_cloud_storage_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         src_fmt_configs: dict | None = None,
         labels: dict | None = None,
         encryption_configuration: dict | None = None,
         location: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
+        bigquery_conn_id: str | None = None,
         **kwargs,
     ) -> None:
         if bigquery_conn_id:
             warnings.warn(
                 "The bigquery_conn_id parameter has been deprecated. Use the gcp_conn_id parameter instead.",
                 DeprecationWarning,
                 stacklevel=2,
@@ -1663,15 +1709,15 @@
             task_instance=self,
             dataset_id=table.to_api_repr()["tableReference"]["datasetId"],
             project_id=table.to_api_repr()["tableReference"]["projectId"],
             table_id=table.to_api_repr()["tableReference"]["tableId"],
         )
 
 
-class BigQueryDeleteDatasetOperator(BaseOperator):
+class BigQueryDeleteDatasetOperator(GoogleCloudBaseOperator):
     """
     This operator deletes an existing dataset from your Project in Big query.
     https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/delete
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:BigQueryDeleteDatasetOperator`
@@ -1716,16 +1762,16 @@
     def __init__(
         self,
         *,
         dataset_id: str,
         project_id: str | None = None,
         delete_contents: bool = False,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         self.dataset_id = dataset_id
         self.project_id = project_id
         self.delete_contents = delete_contents
         self.gcp_conn_id = gcp_conn_id
         if delegate_to:
@@ -1747,15 +1793,15 @@
         )
 
         bq_hook.delete_dataset(
             project_id=self.project_id, dataset_id=self.dataset_id, delete_contents=self.delete_contents
         )
 
 
-class BigQueryCreateEmptyDatasetOperator(BaseOperator):
+class BigQueryCreateEmptyDatasetOperator(GoogleCloudBaseOperator):
     """
     This operator is used to create new dataset for your Project in BigQuery.
     https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#resource
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:BigQueryCreateEmptyDatasetOperator`
@@ -1774,24 +1820,27 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-    :param exists_ok: If ``True``, ignore "already exists" errors when creating the dataset.
+    :param if_exists: What should Airflow do if the dataset exists. If set to `log`, the TI will be passed to
+        success and an error message will be logged. Set to `ignore` to ignore the error, set to `fail` to
+        fail the TI, and set to `skip` to skip it.
         **Example**: ::
 
             create_new_dataset = BigQueryCreateEmptyDatasetOperator(
                 dataset_id='new-dataset',
                 project_id='my-project',
                 dataset_reference={"friendlyName": "New Dataset"}
                 gcp_conn_id='_my_gcp_conn_',
                 task_id='newDatasetCreator',
                 dag=dag)
+    :param exists_ok: Deprecated - use `if_exists="ignore"` instead.
     """
 
     template_fields: Sequence[str] = (
         "dataset_id",
         "project_id",
         "dataset_reference",
         "impersonation_chain",
@@ -1804,32 +1853,37 @@
         self,
         *,
         dataset_id: str | None = None,
         project_id: str | None = None,
         dataset_reference: dict | None = None,
         location: str | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
-        exists_ok: bool = False,
+        if_exists: str = "log",
+        delegate_to: str | None = None,
+        exists_ok: bool | None = None,
         **kwargs,
     ) -> None:
 
         self.dataset_id = dataset_id
         self.project_id = project_id
         self.location = location
         self.gcp_conn_id = gcp_conn_id
         self.dataset_reference = dataset_reference if dataset_reference else {}
         if delegate_to:
             warnings.warn(
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         self.delegate_to = delegate_to
         self.impersonation_chain = impersonation_chain
-        self.exists_ok = exists_ok
+        if exists_ok is not None:
+            warnings.warn("`exists_ok` parameter is deprecated, please use `if_exists`", DeprecationWarning)
+            self.if_exists = IfExistAction.IGNORE if exists_ok else IfExistAction.LOG
+        else:
+            self.if_exists = IfExistAction(if_exists)
 
         super().__init__(**kwargs)
 
     def execute(self, context: Context) -> None:
         bq_hook = BigQueryHook(
             gcp_conn_id=self.gcp_conn_id,
             delegate_to=self.delegate_to,
@@ -1839,28 +1893,34 @@
 
         try:
             dataset = bq_hook.create_empty_dataset(
                 project_id=self.project_id,
                 dataset_id=self.dataset_id,
                 dataset_reference=self.dataset_reference,
                 location=self.location,
-                exists_ok=self.exists_ok,
+                exists_ok=self.if_exists == IfExistAction.IGNORE,
             )
             BigQueryDatasetLink.persist(
                 context=context,
                 task_instance=self,
                 dataset_id=dataset["datasetReference"]["datasetId"],
                 project_id=dataset["datasetReference"]["projectId"],
             )
         except Conflict:
             dataset_id = self.dataset_reference.get("datasetReference", {}).get("datasetId", self.dataset_id)
-            self.log.info("Dataset %s already exists.", dataset_id)
+            error_msg = f"Dataset {dataset_id} already exists."
+            if self.if_exists == IfExistAction.LOG:
+                self.log.info(error_msg)
+            elif self.if_exists == IfExistAction.FAIL:
+                raise AirflowException(error_msg)
+            else:
+                raise AirflowSkipException(error_msg)
 
 
-class BigQueryGetDatasetOperator(BaseOperator):
+class BigQueryGetDatasetOperator(GoogleCloudBaseOperator):
     """
     This operator is used to return the dataset specified by dataset_id.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:BigQueryGetDatasetOperator`
 
@@ -1892,16 +1952,16 @@
 
     def __init__(
         self,
         *,
         dataset_id: str,
         project_id: str | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         self.dataset_id = dataset_id
         self.project_id = project_id
         self.gcp_conn_id = gcp_conn_id
         if delegate_to:
             warnings.warn(
@@ -1927,15 +1987,15 @@
             task_instance=self,
             dataset_id=dataset["datasetReference"]["datasetId"],
             project_id=dataset["datasetReference"]["projectId"],
         )
         return dataset
 
 
-class BigQueryGetDatasetTablesOperator(BaseOperator):
+class BigQueryGetDatasetTablesOperator(GoogleCloudBaseOperator):
     """
     This operator retrieves the list of tables in the specified dataset.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:BigQueryGetDatasetTablesOperator`
 
@@ -1967,16 +2027,16 @@
     def __init__(
         self,
         *,
         dataset_id: str,
         project_id: str | None = None,
         max_results: int | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         self.dataset_id = dataset_id
         self.project_id = project_id
         self.max_results = max_results
         self.gcp_conn_id = gcp_conn_id
         if delegate_to:
@@ -1997,15 +2057,15 @@
         return bq_hook.get_dataset_tables(
             dataset_id=self.dataset_id,
             project_id=self.project_id,
             max_results=self.max_results,
         )
 
 
-class BigQueryPatchDatasetOperator(BaseOperator):
+class BigQueryPatchDatasetOperator(GoogleCloudBaseOperator):
     """
     This operator is used to patch dataset for your Project in BigQuery.
     It only replaces fields that are provided in the submitted dataset resource.
 
     This operator is deprecated.
     Please use :class:`airflow.providers.google.cloud.operators.bigquery.BigQueryUpdateTableOperator`
 
@@ -2040,16 +2100,16 @@
     def __init__(
         self,
         *,
         dataset_id: str,
         dataset_resource: dict,
         project_id: str | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         warnings.warn(
             "This operator is deprecated. Please use BigQueryUpdateDatasetOperator.",
             DeprecationWarning,
             stacklevel=2,
         )
@@ -2075,15 +2135,15 @@
         return bq_hook.patch_dataset(
             dataset_id=self.dataset_id,
             dataset_resource=self.dataset_resource,
             project_id=self.project_id,
         )
 
 
-class BigQueryUpdateTableOperator(BaseOperator):
+class BigQueryUpdateTableOperator(GoogleCloudBaseOperator):
     """
     This operator is used to update table for your Project in BigQuery.
     Use ``fields`` to specify which fields of table to update. If a field
     is listed in ``fields`` and is ``None`` in table, it will be deleted.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -2128,16 +2188,16 @@
         *,
         table_resource: dict[str, Any],
         fields: list[str] | None = None,
         dataset_id: str | None = None,
         table_id: str | None = None,
         project_id: str | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         self.dataset_id = dataset_id
         self.table_id = table_id
         self.project_id = project_id
         self.fields = fields
         self.gcp_conn_id = gcp_conn_id
@@ -2172,15 +2232,15 @@
             project_id=table["tableReference"]["projectId"],
             table_id=table["tableReference"]["tableId"],
         )
 
         return table
 
 
-class BigQueryUpdateDatasetOperator(BaseOperator):
+class BigQueryUpdateDatasetOperator(GoogleCloudBaseOperator):
     """
     This operator is used to update dataset for your Project in BigQuery.
     Use ``fields`` to specify which fields of dataset to update. If a field
     is listed in ``fields`` and is ``None`` in dataset, it will be deleted.
     If no ``fields`` are provided then all fields of provided ``dataset_resource``
     will be used.
 
@@ -2222,16 +2282,16 @@
         self,
         *,
         dataset_resource: dict[str, Any],
         fields: list[str] | None = None,
         dataset_id: str | None = None,
         project_id: str | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         self.dataset_id = dataset_id
         self.project_id = project_id
         self.fields = fields
         self.gcp_conn_id = gcp_conn_id
         self.dataset_resource = dataset_resource
@@ -2264,15 +2324,15 @@
             task_instance=self,
             dataset_id=dataset["datasetReference"]["datasetId"],
             project_id=dataset["datasetReference"]["projectId"],
         )
         return dataset
 
 
-class BigQueryDeleteTableOperator(BaseOperator):
+class BigQueryDeleteTableOperator(GoogleCloudBaseOperator):
     """
     Deletes BigQuery tables
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:BigQueryDeleteTableOperator`
 
@@ -2303,18 +2363,18 @@
     ui_color = BigQueryUIColors.TABLE.value
 
     def __init__(
         self,
         *,
         deletion_dataset_table: str,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         ignore_if_missing: bool = False,
         location: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
 
         self.deletion_dataset_table = deletion_dataset_table
         self.gcp_conn_id = gcp_conn_id
         if delegate_to:
@@ -2333,15 +2393,15 @@
             delegate_to=self.delegate_to,
             location=self.location,
             impersonation_chain=self.impersonation_chain,
         )
         hook.delete_table(table_id=self.deletion_dataset_table, not_found_ok=self.ignore_if_missing)
 
 
-class BigQueryUpsertTableOperator(BaseOperator):
+class BigQueryUpsertTableOperator(GoogleCloudBaseOperator):
     """
     Upsert BigQuery table
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:BigQueryUpsertTableOperator`
 
@@ -2380,17 +2440,17 @@
     def __init__(
         self,
         *,
         dataset_id: str,
         table_resource: dict,
         project_id: str | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         location: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
 
         self.dataset_id = dataset_id
         self.table_resource = table_resource
         self.project_id = project_id
@@ -2421,15 +2481,15 @@
             task_instance=self,
             dataset_id=table["tableReference"]["datasetId"],
             project_id=table["tableReference"]["projectId"],
             table_id=table["tableReference"]["tableId"],
         )
 
 
-class BigQueryUpdateTableSchemaOperator(BaseOperator):
+class BigQueryUpdateTableSchemaOperator(GoogleCloudBaseOperator):
     """
     Update BigQuery Table Schema
     Updates fields on a table schema based on contents of the supplied schema_fields_updates
     parameter. The supplied schema does not need to be complete, if the field
     already exists in the schema you only need to supply keys & values for the
     items you want to patch, just ensure the "name" key is set.
 
@@ -2491,16 +2551,16 @@
         *,
         schema_fields_updates: list[dict[str, Any]],
         dataset_id: str,
         table_id: str,
         include_policy_tags: bool = False,
         project_id: str | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         self.schema_fields_updates = schema_fields_updates
         self.include_policy_tags = include_policy_tags
         self.table_id = table_id
         self.dataset_id = dataset_id
         self.project_id = project_id
@@ -2534,15 +2594,15 @@
             dataset_id=table["tableReference"]["datasetId"],
             project_id=table["tableReference"]["projectId"],
             table_id=table["tableReference"]["tableId"],
         )
         return table
 
 
-class BigQueryInsertJobOperator(BaseOperator):
+class BigQueryInsertJobOperator(GoogleCloudBaseOperator):
     """
     Executes a BigQuery job. Waits for the job to complete and returns job id.
     This operator work in the following way:
 
     - it calculates a unique hash of the job using job's configuration or uuid if ``force_rerun`` is True
     - creates ``job_id`` in form of
         ``[provided_job_id | airflow_{dag_id}_{task_id}_{exec_date}]_{uniqueness_suffix}``
@@ -2586,14 +2646,16 @@
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     :param cancel_on_kill: Flag which indicates whether cancel the hook's job or not, when on_kill is called
     :param result_retry: How to retry the `result` call that retrieves rows
     :param result_timeout: The number of seconds to wait for `result` method before using `result_retry`
     :param deferrable: Run operator in the deferrable mode
+    :param poll_interval: (Deferrable mode only) polling period in seconds to check for the status of job.
+        Defaults to 4 seconds.
     """
 
     template_fields: Sequence[str] = (
         "configuration",
         "job_id",
         "impersonation_chain",
         "project_id",
@@ -2611,20 +2673,21 @@
         configuration: dict[str, Any],
         project_id: str | None = None,
         location: str | None = None,
         job_id: str | None = None,
         force_rerun: bool = True,
         reattach_states: set[str] | None = None,
         gcp_conn_id: str = "google_cloud_default",
-        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         cancel_on_kill: bool = True,
         result_retry: Retry = DEFAULT_RETRY,
         result_timeout: float | None = None,
         deferrable: bool = False,
+        poll_interval: float = 4.0,
+        delegate_to: str | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.configuration = configuration
         self.location = location
         self.job_id = job_id
         self.project_id = project_id
@@ -2638,14 +2701,15 @@
         self.reattach_states: set[str] = reattach_states or set()
         self.impersonation_chain = impersonation_chain
         self.cancel_on_kill = cancel_on_kill
         self.result_retry = result_retry
         self.result_timeout = result_timeout
         self.hook: BigQueryHook | None = None
         self.deferrable = deferrable
+        self.poll_interval = poll_interval
 
     def prepare_template(self) -> None:
         # If .json is passed then we have to read the file
         if isinstance(self.configuration, str) and self.configuration.endswith(".json"):
             with open(self.configuration) as file:
                 self.configuration = json.loads(file.read())
 
@@ -2745,14 +2809,15 @@
             return self.job_id
         self.defer(
             timeout=self.execution_timeout,
             trigger=BigQueryInsertJobTrigger(
                 conn_id=self.gcp_conn_id,
                 job_id=self.job_id,
                 project_id=self.project_id,
+                poll_interval=self.poll_interval,
             ),
             method_name="execute_complete",
         )
 
     def execute_complete(self, context: Context, event: dict[str, Any]):
         """
         Callback for when the trigger fires - returns immediately.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/bigquery_dts.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/bigquery_dts.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,29 +28,29 @@
     TransferConfig,
     TransferRun,
     TransferState,
 )
 
 from airflow import AirflowException
 from airflow.compat.functools import cached_property
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.bigquery_dts import BiqQueryDataTransferServiceHook, get_object_id
 from airflow.providers.google.cloud.links.bigquery_dts import BigQueryDataTransferConfigLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.triggers.bigquery_dts import BigQueryDataTransferRunTrigger
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 def _get_transfer_config_details(config_transfer_name: str):
     config_details = config_transfer_name.split("/")
     return {"project_id": config_details[1], "region": config_details[3], "config_id": config_details[5]}
 
 
-class BigQueryCreateDataTransferOperator(BaseOperator):
+class BigQueryCreateDataTransferOperator(GoogleCloudBaseOperator):
     """
     Creates a new data transfer configuration.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:BigQueryCreateDataTransferOperator`
 
@@ -134,18 +134,21 @@
             config_id=transfer_config["config_id"],
             project_id=transfer_config["project_id"],
         )
 
         result = TransferConfig.to_dict(response)
         self.log.info("Created DTS transfer config %s", get_object_id(result))
         self.xcom_push(context, key="transfer_config_id", value=get_object_id(result))
+        # don't push AWS secret in XCOM
+        result.get("params", {}).pop("secret_access_key", None)
+        result.get("params", {}).pop("access_key_id", None)
         return result
 
 
-class BigQueryDeleteDataTransferConfigOperator(BaseOperator):
+class BigQueryDeleteDataTransferConfigOperator(GoogleCloudBaseOperator):
     """
     Deletes transfer configuration.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:BigQueryDeleteDataTransferConfigOperator`
 
@@ -209,15 +212,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class BigQueryDataTransferServiceStartTransferRunsOperator(BaseOperator):
+class BigQueryDataTransferServiceStartTransferRunsOperator(GoogleCloudBaseOperator):
     """
     Start manual transfer runs to be executed now with schedule_time equal
     to current time. The transfer runs can be created for a time range where
     the run_time is between start_time (inclusive) and end_time
     (exclusive), or for a specific run_time.
 
     .. seealso::
@@ -299,14 +302,18 @@
             impersonation_chain=self.impersonation_chain,
             location=self.location,
         )
         return hook
 
     def execute(self, context: Context):
         self.log.info("Submitting manual transfer for %s", self.transfer_config_id)
+
+        if self.requested_run_time and isinstance(self.requested_run_time.get("seconds"), str):
+            self.requested_run_time["seconds"] = int(self.requested_run_time["seconds"])
+
         response = self.hook.start_manual_transfer_runs(
             transfer_config_id=self.transfer_config_id,
             requested_time_range=self.requested_time_range,
             requested_run_time=self.requested_run_time,
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/bigtable.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/bigtable.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,25 +18,25 @@
 """This module contains Google Cloud Bigtable operators."""
 from __future__ import annotations
 
 import enum
 from typing import TYPE_CHECKING, Iterable, Sequence
 
 import google.api_core.exceptions
+from google.cloud.bigtable import enums
 from google.cloud.bigtable.column_family import GarbageCollectionRule
-from google.cloud.bigtable_admin_v2 import enums
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.bigtable import BigtableHook
 from airflow.providers.google.cloud.links.bigtable import (
     BigtableClusterLink,
     BigtableInstanceLink,
     BigtableTablesLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 class BigtableValidationMixin:
     """Common class for Cloud Bigtable operators for validating required fields."""
@@ -45,15 +45,15 @@
 
     def _validate_inputs(self):
         for attr_name in self.REQUIRED_ATTRIBUTES:
             if not getattr(self, attr_name):
                 raise AirflowException(f"Empty parameter: {attr_name}")
 
 
-class BigtableCreateInstanceOperator(BaseOperator, BigtableValidationMixin):
+class BigtableCreateInstanceOperator(GoogleCloudBaseOperator, BigtableValidationMixin):
     """
     Creates a new Cloud Bigtable instance.
     If the Cloud Bigtable instance with the given ID exists, the operator does not
     compare its configuration
     and immediately succeeds. No changes are made to the existing instance.
 
     For more details about instance creation have a look at the reference:
@@ -167,15 +167,15 @@
             )
             BigtableInstanceLink.persist(context=context, task_instance=self)
         except google.api_core.exceptions.GoogleAPICallError as e:
             self.log.error("An error occurred. Exiting.")
             raise e
 
 
-class BigtableUpdateInstanceOperator(BaseOperator, BigtableValidationMixin):
+class BigtableUpdateInstanceOperator(GoogleCloudBaseOperator, BigtableValidationMixin):
     """
     Updates an existing Cloud Bigtable instance.
 
     For more details about instance creation have a look at the reference:
     https://googleapis.dev/python/bigtable/latest/instance.html#google.cloud.bigtable.instance.Instance.update
 
     .. seealso::
@@ -254,15 +254,15 @@
             )
             BigtableInstanceLink.persist(context=context, task_instance=self)
         except google.api_core.exceptions.GoogleAPICallError as e:
             self.log.error("An error occurred. Exiting.")
             raise e
 
 
-class BigtableDeleteInstanceOperator(BaseOperator, BigtableValidationMixin):
+class BigtableDeleteInstanceOperator(GoogleCloudBaseOperator, BigtableValidationMixin):
     """
     Deletes the Cloud Bigtable instance, including its clusters and all related tables.
 
     For more details about deleting instance have a look at the reference:
     https://googleapis.github.io/google-cloud-python/latest/bigtable/instance.html#google.cloud.bigtable.instance.Instance.delete
 
     .. seealso::
@@ -320,15 +320,15 @@
                 self.project_id,
             )
         except google.api_core.exceptions.GoogleAPICallError as e:
             self.log.error("An error occurred. Exiting.")
             raise e
 
 
-class BigtableCreateTableOperator(BaseOperator, BigtableValidationMixin):
+class BigtableCreateTableOperator(GoogleCloudBaseOperator, BigtableValidationMixin):
     """
     Creates the table in the Cloud Bigtable instance.
 
     For more details about creating table have a look at the reference:
     https://googleapis.github.io/google-cloud-python/latest/bigtable/table.html#google.cloud.bigtable.table.Table.create
 
     .. seealso::
@@ -430,15 +430,15 @@
             if not self._compare_column_families(hook, instance):
                 raise AirflowException(
                     f"Table '{self.table_id}' already exists with different Column Families."
                 )
             self.log.info("The table '%s' already exists. Consider it as created", self.table_id)
 
 
-class BigtableDeleteTableOperator(BaseOperator, BigtableValidationMixin):
+class BigtableDeleteTableOperator(GoogleCloudBaseOperator, BigtableValidationMixin):
     """
     Deletes the Cloud Bigtable table.
 
     For more details about deleting table have a look at the reference:
     https://googleapis.github.io/google-cloud-python/latest/bigtable/table.html#google.cloud.bigtable.table.Table.delete
 
     .. seealso::
@@ -508,15 +508,15 @@
             # It's OK if table doesn't exists.
             self.log.info("The table '%s' no longer exists. Consider it as deleted", self.table_id)
         except google.api_core.exceptions.GoogleAPICallError as e:
             self.log.error("An error occurred. Exiting.")
             raise e
 
 
-class BigtableUpdateClusterOperator(BaseOperator, BigtableValidationMixin):
+class BigtableUpdateClusterOperator(GoogleCloudBaseOperator, BigtableValidationMixin):
     """
     Updates a Cloud Bigtable cluster.
 
     For more details about updating a Cloud Bigtable cluster,
     have a look at the reference:
     https://googleapis.github.io/google-cloud-python/latest/bigtable/cluster.html#google.cloud.bigtable.cluster.Cluster.update
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_build.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_build.py`

 * *Files 8% similar despite different names*

```diff
@@ -26,35 +26,35 @@
 from urllib.parse import unquote, urlsplit
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.devtools.cloudbuild_v1.types import Build, BuildTrigger, RepoSource
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.cloud_build import CloudBuildHook
 from airflow.providers.google.cloud.links.cloud_build import (
     CloudBuildLink,
     CloudBuildListLink,
     CloudBuildTriggerDetailsLink,
     CloudBuildTriggersListLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.triggers.cloud_build import CloudBuildCreateBuildTrigger
 from airflow.providers.google.common.consts import GOOGLE_DEFAULT_DEFERRABLE_METHOD_NAME
 from airflow.utils import yaml
 from airflow.utils.helpers import exactly_one
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 REGEX_REPO_PATH = re.compile(r"^/(?P<project_id>[^/]+)/(?P<repo_name>[^/]+)[\+/]*(?P<branch_name>[^:]+)?")
 
 
-class CloudBuildCancelBuildOperator(BaseOperator):
+class CloudBuildCancelBuildOperator(GoogleCloudBaseOperator):
     """
     Cancels a build in progress.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildCancelBuildOperator`
 
@@ -71,64 +71,68 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "id_", "gcp_conn_id")
+    template_fields: Sequence[str] = ("project_id", "id_", "gcp_conn_id", "location")
     operator_extra_links = (CloudBuildLink(),)
 
     def __init__(
         self,
         *,
         id_: str,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.id_ = id_
         self.project_id = project_id
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.location = location
 
     def execute(self, context: Context):
         hook = CloudBuildHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         result = hook.cancel_build(
             id_=self.id_,
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
 
         self.xcom_push(context, key="id", value=result.id)
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
                 build_id=result.id,
             )
         return Build.to_dict(result)
 
 
-class CloudBuildCreateBuildOperator(BaseOperator):
+class CloudBuildCreateBuildOperator(GoogleCloudBaseOperator):
     """
     Starts a build with the specified configuration.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildCreateBuildOperator`
 
@@ -154,17 +158,18 @@
     :param delegate_to: The account to impersonate using domain-wide delegation of authority,
         if any. For this to work, the service account making the request must have
         domain-wide delegation enabled.
     :param retry: Designation of what errors, if any, should be retried.
     :param timeout: The timeout for this request.
     :param metadata: Strings which should be sent along with the request as metadata.
     :param deferrable: Run operator in the deferrable mode
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "build", "gcp_conn_id", "impersonation_chain")
+    template_fields: Sequence[str] = ("project_id", "build", "gcp_conn_id", "impersonation_chain", "location")
     operator_extra_links = (CloudBuildLink(),)
 
     def __init__(
         self,
         *,
         build: dict | Build,
         project_id: str | None = None,
@@ -173,14 +178,15 @@
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
         delegate_to: str | None = None,
         poll_interval: float = 4.0,
         deferrable: bool = False,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.build = build
         # Not template fields to keep original value
         self.build_raw = build
         self.project_id = project_id
@@ -193,14 +199,15 @@
         if delegate_to:
             warnings.warn(
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         self.delegate_to = delegate_to
         self.poll_interval = poll_interval
         self.deferrable = deferrable
+        self.location = location
 
     def prepare_template(self) -> None:
         # if no file is specified, skip
         if not isinstance(self.build_raw, str):
             return
         with open(self.build_raw) as file:
             if any(self.build_raw.endswith(ext) for ext in [".yaml", ".yml"]):
@@ -218,41 +225,46 @@
 
         self.cloud_build_operation, self.id_ = hook.create_build_without_waiting_for_result(
             build=build,
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
         self.xcom_push(context, key="id", value=self.id_)
         if not self.wait:
-            return Build.to_dict(hook.get_build(id_=self.id_, project_id=self.project_id))
+            return Build.to_dict(
+                hook.get_build(id_=self.id_, project_id=self.project_id, location=self.location)
+            )
 
         if self.deferrable:
             self.defer(
                 trigger=CloudBuildCreateBuildTrigger(
                     id_=self.id_,
                     project_id=self.project_id,
                     gcp_conn_id=self.gcp_conn_id,
                     impersonation_chain=self.impersonation_chain,
                     delegate_to=self.delegate_to,
                     poll_interval=self.poll_interval,
+                    location=self.location,
                 ),
                 method_name=GOOGLE_DEFAULT_DEFERRABLE_METHOD_NAME,
             )
         else:
             cloud_build_instance_result = hook.wait_for_operation(
                 timeout=self.timeout, operation=self.cloud_build_operation
             )
             project_id = self.project_id or hook.project_id
             if project_id:
                 CloudBuildLink.persist(
                     context=context,
                     task_instance=self,
                     project_id=project_id,
+                    region=self.location,
                     build_id=cloud_build_instance_result.id,
                 )
             return Build.to_dict(cloud_build_instance_result)
 
     def execute_complete(self, context: Context, event: dict):
         if event["status"] == "success":
             hook = CloudBuildHook(
@@ -263,22 +275,23 @@
             self.log.info("Cloud Build completed with response %s ", event["message"])
             project_id = self.project_id or hook.project_id
             if project_id:
                 CloudBuildLink.persist(
                     context=context,
                     task_instance=self,
                     project_id=project_id,
+                    region=self.location,
                     build_id=event["id_"],
                 )
             return event["instance"]
         else:
             raise AirflowException(f"Unexpected error in the operation: {event['message']}")
 
 
-class CloudBuildCreateBuildTriggerOperator(BaseOperator):
+class CloudBuildCreateBuildTriggerOperator(GoogleCloudBaseOperator):
     """
     Creates a new BuildTrigger.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildCreateBuildTriggerOperator`
 
@@ -296,18 +309,18 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "trigger", "gcp_conn_id")
+    template_fields: Sequence[str] = ("project_id", "trigger", "gcp_conn_id", "location")
     operator_extra_links = (
         CloudBuildTriggersListLink(),
         CloudBuildTriggerDetailsLink(),
     )
 
     def __init__(
         self,
@@ -315,52 +328,57 @@
         trigger: dict | BuildTrigger,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.trigger = trigger
         self.project_id = project_id
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.location = location
 
     def execute(self, context: Context):
         hook = CloudBuildHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         result = hook.create_build_trigger(
             trigger=self.trigger,
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
         self.xcom_push(context, key="id", value=result.id)
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildTriggerDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
                 trigger_id=result.id,
             )
             CloudBuildTriggersListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
             )
         return BuildTrigger.to_dict(result)
 
 
-class CloudBuildDeleteBuildTriggerOperator(BaseOperator):
+class CloudBuildDeleteBuildTriggerOperator(GoogleCloudBaseOperator):
     """
     Deletes a BuildTrigger by its project ID and trigger ID.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildDeleteBuildTriggerOperator`
 
@@ -377,59 +395,64 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "trigger_id", "gcp_conn_id")
+    template_fields: Sequence[str] = ("project_id", "trigger_id", "gcp_conn_id", "location")
     operator_extra_links = (CloudBuildTriggersListLink(),)
 
     def __init__(
         self,
         *,
         trigger_id: str,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.trigger_id = trigger_id
         self.project_id = project_id
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.location = location
 
     def execute(self, context: Context):
         hook = CloudBuildHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         hook.delete_build_trigger(
             trigger_id=self.trigger_id,
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildTriggersListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
             )
 
 
-class CloudBuildGetBuildOperator(BaseOperator):
+class CloudBuildGetBuildOperator(GoogleCloudBaseOperator):
     """
     Returns information about a previously requested build.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildGetBuildOperator`
 
@@ -446,62 +469,66 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "id_", "gcp_conn_id")
+    template_fields: Sequence[str] = ("project_id", "id_", "gcp_conn_id", "location")
     operator_extra_links = (CloudBuildLink(),)
 
     def __init__(
         self,
         *,
         id_: str,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.id_ = id_
         self.project_id = project_id
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.location = location
 
     def execute(self, context: Context):
         hook = CloudBuildHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         result = hook.get_build(
             id_=self.id_,
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
                 build_id=result.id,
             )
         return Build.to_dict(result)
 
 
-class CloudBuildGetBuildTriggerOperator(BaseOperator):
+class CloudBuildGetBuildTriggerOperator(GoogleCloudBaseOperator):
     """
     Returns information about a BuildTrigger.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildGetBuildTriggerOperator`
 
@@ -518,62 +545,66 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "trigger_id", "gcp_conn_id")
+    template_fields: Sequence[str] = ("project_id", "trigger_id", "gcp_conn_id", "location")
     operator_extra_links = (CloudBuildTriggerDetailsLink(),)
 
     def __init__(
         self,
         *,
         trigger_id: str,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.trigger_id = trigger_id
         self.project_id = project_id
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.location = location
 
     def execute(self, context: Context):
         hook = CloudBuildHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         result = hook.get_build_trigger(
             trigger_id=self.trigger_id,
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildTriggerDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
                 trigger_id=result.id,
             )
         return BuildTrigger.to_dict(result)
 
 
-class CloudBuildListBuildTriggersOperator(BaseOperator):
+class CloudBuildListBuildTriggersOperator(GoogleCloudBaseOperator):
     """
     Lists existing BuildTriggers.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildListBuildTriggersOperator`
 
@@ -601,15 +632,15 @@
 
     template_fields: Sequence[str] = ("location", "project_id", "gcp_conn_id")
     operator_extra_links = (CloudBuildTriggersListLink(),)
 
     def __init__(
         self,
         *,
-        location: str,
+        location: str = "global",
         project_id: str | None = None,
         page_size: int | None = None,
         page_token: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
@@ -640,19 +671,20 @@
         )
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildTriggersListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
             )
         return [BuildTrigger.to_dict(result) for result in results]
 
 
-class CloudBuildListBuildsOperator(BaseOperator):
+class CloudBuildListBuildsOperator(GoogleCloudBaseOperator):
     """
     Lists previously requested builds.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildListBuildsOperator`
 
@@ -680,15 +712,15 @@
 
     template_fields: Sequence[str] = ("location", "project_id", "gcp_conn_id")
     operator_extra_links = (CloudBuildListLink(),)
 
     def __init__(
         self,
         *,
-        location: str,
+        location: str = "global",
         project_id: str | None = None,
         page_size: int | None = None,
         filter_: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
@@ -715,19 +747,21 @@
             filter_=self.filter_,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         project_id = self.project_id or hook.project_id
         if project_id:
-            CloudBuildListLink.persist(context=context, task_instance=self, project_id=project_id)
+            CloudBuildListLink.persist(
+                context=context, task_instance=self, project_id=project_id, region=self.location
+            )
         return [Build.to_dict(result) for result in results]
 
 
-class CloudBuildRetryBuildOperator(BaseOperator):
+class CloudBuildRetryBuildOperator(GoogleCloudBaseOperator):
     """
     Creates a new build based on the specified build. This method creates a new build
     using the original build request, which may or may not result in an identical build.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildRetryBuildOperator`
@@ -746,67 +780,71 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "id_", "gcp_conn_id")
+    template_fields: Sequence[str] = ("project_id", "id_", "gcp_conn_id", "location")
     operator_extra_links = (CloudBuildLink(),)
 
     def __init__(
         self,
         *,
         id_: str,
         project_id: str | None = None,
         wait: bool = True,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.id_ = id_
         self.project_id = project_id
         self.wait = wait
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.location = location
 
     def execute(self, context: Context):
         hook = CloudBuildHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         result = hook.retry_build(
             id_=self.id_,
             project_id=self.project_id,
             wait=self.wait,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
 
         self.xcom_push(context, key="id", value=result.id)
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
                 build_id=result.id,
             )
         return Build.to_dict(result)
 
 
-class CloudBuildRunBuildTriggerOperator(BaseOperator):
+class CloudBuildRunBuildTriggerOperator(GoogleCloudBaseOperator):
     """
     Runs a BuildTrigger at a particular source revision.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildRunBuildTriggerOperator`
 
@@ -826,69 +864,73 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "trigger_id", "source", "gcp_conn_id")
+    template_fields: Sequence[str] = ("project_id", "trigger_id", "source", "gcp_conn_id", "location")
     operator_extra_links = (CloudBuildLink(),)
 
     def __init__(
         self,
         *,
         trigger_id: str,
         source: dict | RepoSource,
         project_id: str | None = None,
         wait: bool = True,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.trigger_id = trigger_id
         self.source = source
         self.project_id = project_id
         self.wait = wait
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.location = location
 
     def execute(self, context: Context):
         hook = CloudBuildHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         result = hook.run_build_trigger(
             trigger_id=self.trigger_id,
             source=self.source,
             project_id=self.project_id,
             wait=self.wait,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
         self.xcom_push(context, key="id", value=result.id)
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
                 build_id=result.id,
             )
         return Build.to_dict(result)
 
 
-class CloudBuildUpdateBuildTriggerOperator(BaseOperator):
+class CloudBuildUpdateBuildTriggerOperator(GoogleCloudBaseOperator):
     """
     Updates a BuildTrigger by its project ID and trigger ID.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudBuildUpdateBuildTriggerOperator`
 
@@ -907,60 +949,64 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-
+    :param location: The location of the project.
     """
 
-    template_fields: Sequence[str] = ("project_id", "trigger_id", "trigger", "gcp_conn_id")
+    template_fields: Sequence[str] = ("project_id", "trigger_id", "trigger", "gcp_conn_id", "location")
     operator_extra_links = (CloudBuildTriggerDetailsLink(),)
 
     def __init__(
         self,
         *,
         trigger_id: str,
         trigger: dict | BuildTrigger,
         project_id: str | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        location: str = "global",
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.trigger_id = trigger_id
         self.trigger = trigger
         self.project_id = project_id
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.location = location
 
     def execute(self, context: Context):
         hook = CloudBuildHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         result = hook.update_build_trigger(
             trigger_id=self.trigger_id,
             trigger=self.trigger,
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
+            location=self.location,
         )
         self.xcom_push(context, key="id", value=result.id)
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudBuildTriggerDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
+                region=self.location,
                 trigger_id=result.id,
             )
         return BuildTrigger.to_dict(result)
 
 
 class BuildProcessor:
     """
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_composer.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_composer.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,17 +24,17 @@
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.orchestration.airflow.service_v1 import ImageVersion
 from google.cloud.orchestration.airflow.service_v1.types import Environment
 from google.protobuf.field_mask_pb2 import FieldMask
 
 from airflow import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.cloud_composer import CloudComposerHook
 from airflow.providers.google.cloud.links.base import BaseGoogleLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.triggers.cloud_composer import CloudComposerExecutionTrigger
 from airflow.providers.google.common.consts import GOOGLE_DEFAULT_DEFERRABLE_METHOD_NAME
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 CLOUD_COMPOSER_BASE_LINK = "https://console.cloud.google.com/composer/environments"
@@ -85,15 +85,15 @@
             key=CloudComposerEnvironmentsLink.key,
             value={
                 "project_id": operator_instance.project_id,
             },
         )
 
 
-class CloudComposerCreateEnvironmentOperator(BaseOperator):
+class CloudComposerCreateEnvironmentOperator(GoogleCloudBaseOperator):
     """
     Create a new environment.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param environment_id: Required. The ID of the Google Cloud environment that the service belongs to.
     :param environment:  The environment to create.
@@ -231,15 +231,15 @@
                 metadata=self.metadata,
             )
             return Environment.to_dict(env)
         else:
             raise AirflowException(f"Unexpected error in the operation: {event['operation_name']}")
 
 
-class CloudComposerDeleteEnvironmentOperator(BaseOperator):
+class CloudComposerDeleteEnvironmentOperator(GoogleCloudBaseOperator):
     """
     Delete an environment.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param environment_id: Required. The ID of the Google Cloud environment that the service belongs to.
     :param retry: Designation of what errors, if any, should be retried.
@@ -332,15 +332,15 @@
                 method_name=GOOGLE_DEFAULT_DEFERRABLE_METHOD_NAME,
             )
 
     def execute_complete(self, context: Context, event: dict):
         pass
 
 
-class CloudComposerGetEnvironmentOperator(BaseOperator):
+class CloudComposerGetEnvironmentOperator(GoogleCloudBaseOperator):
     """
     Get an existing environment.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param environment_id: Required. The ID of the Google Cloud environment that the service belongs to.
     :param retry: Designation of what errors, if any, should be retried.
@@ -414,15 +414,15 @@
             metadata=self.metadata,
         )
 
         CloudComposerEnvironmentLink.persist(operator_instance=self, context=context)
         return Environment.to_dict(result)
 
 
-class CloudComposerListEnvironmentsOperator(BaseOperator):
+class CloudComposerListEnvironmentsOperator(GoogleCloudBaseOperator):
     """
     List environments.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param page_size: The maximum number of environments to return.
     :param page_token: The next_page_token value returned from a previous List
@@ -498,15 +498,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         return [Environment.to_dict(env) for env in result]
 
 
-class CloudComposerUpdateEnvironmentOperator(BaseOperator):
+class CloudComposerUpdateEnvironmentOperator(GoogleCloudBaseOperator):
     r"""
     Update an environment.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param environment_id: Required. The ID of the Google Cloud environment that the service belongs to.
     :param environment:  A patch environment. Fields specified by the ``updateMask`` will be copied from the
@@ -633,15 +633,15 @@
                 metadata=self.metadata,
             )
             return Environment.to_dict(env)
         else:
             raise AirflowException(f"Unexpected error in the operation: {event['operation_name']}")
 
 
-class CloudComposerListImageVersionsOperator(BaseOperator):
+class CloudComposerListImageVersionsOperator(GoogleCloudBaseOperator):
     """
     List ImageVersions for provided location.
 
     :param request:  The request object. List ImageVersions in a project and location.
     :param retry: Designation of what errors, if any, should be retried.
     :param timeout: The timeout for this request.
     :param metadata: Strings which should be sent along with the request as metadata.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_memorystore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_memorystore.py`

 * *Files 1% similar despite different names*

```diff
@@ -29,31 +29,31 @@
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.memcache_v1beta2.types import cloud_memcache
 from google.cloud.redis_v1 import FailoverInstanceRequest, InputConfig, Instance, OutputConfig
 from google.protobuf.field_mask_pb2 import FieldMask
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.cloud_memorystore import (
     CloudMemorystoreHook,
     CloudMemorystoreMemcachedHook,
 )
 from airflow.providers.google.cloud.links.cloud_memorystore import (
     MemcachedInstanceDetailsLink,
     MemcachedInstanceListLink,
     RedisInstanceDetailsLink,
     RedisInstanceListLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudMemorystoreCreateInstanceOperator(BaseOperator):
+class CloudMemorystoreCreateInstanceOperator(GoogleCloudBaseOperator):
     """
     Creates a Redis instance based on the specified tier and memory size.
 
     By default, the instance is accessible from the project's `default network
     <https://cloud.google.com/compute/docs/networks-and-firewalls#networks>`__.
 
     .. seealso::
@@ -148,15 +148,15 @@
             instance_id=self.instance_id,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return Instance.to_dict(result)
 
 
-class CloudMemorystoreDeleteInstanceOperator(BaseOperator):
+class CloudMemorystoreDeleteInstanceOperator(GoogleCloudBaseOperator):
     """
     Deletes a specific Redis instance. Instance stops serving and data is deleted.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreDeleteInstanceOperator`
 
@@ -224,15 +224,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudMemorystoreExportInstanceOperator(BaseOperator):
+class CloudMemorystoreExportInstanceOperator(GoogleCloudBaseOperator):
     """
     Export Redis instance data into a Redis RDB format file in Cloud Storage.
 
     Redis will continue serving during this operation.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -319,15 +319,15 @@
             task_instance=self,
             instance_id=self.instance,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudMemorystoreFailoverInstanceOperator(BaseOperator):
+class CloudMemorystoreFailoverInstanceOperator(GoogleCloudBaseOperator):
     """
     Initiates a failover of the primary node to current replica node for a specific STANDARD tier Cloud
     Memorystore for Redis instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreFailoverInstanceOperator`
@@ -410,15 +410,15 @@
             task_instance=self,
             instance_id=self.instance,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudMemorystoreGetInstanceOperator(BaseOperator):
+class CloudMemorystoreGetInstanceOperator(GoogleCloudBaseOperator):
     """
     Gets the details of a specific Redis instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreGetInstanceOperator`
 
@@ -495,15 +495,15 @@
             instance_id=self.instance,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return Instance.to_dict(result)
 
 
-class CloudMemorystoreImportOperator(BaseOperator):
+class CloudMemorystoreImportOperator(GoogleCloudBaseOperator):
     """
     Import a Redis RDB snapshot file from Cloud Storage into a Redis instance.
 
     Redis may stop serving during this operation. Instance state will be IMPORTING for entire operation. When
     complete, the instance will contain only data from the imported file.
 
     .. seealso::
@@ -590,15 +590,15 @@
             task_instance=self,
             instance_id=self.instance,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudMemorystoreListInstancesOperator(BaseOperator):
+class CloudMemorystoreListInstancesOperator(GoogleCloudBaseOperator):
     """
     Lists all Redis instances owned by a project in either the specified location (region) or all locations.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreListInstancesOperator`
 
@@ -678,15 +678,15 @@
             task_instance=self,
             project_id=self.project_id or hook.project_id,
         )
         instances = [Instance.to_dict(a) for a in result]
         return instances
 
 
-class CloudMemorystoreUpdateInstanceOperator(BaseOperator):
+class CloudMemorystoreUpdateInstanceOperator(GoogleCloudBaseOperator):
     """
     Updates the metadata and configuration of a specific Redis instance.
 
     :param update_mask: Required. Mask of fields to update. At least one path must be supplied in this field.
         The elements of the repeated paths field may only include these fields from ``Instance``:
 
         -  ``displayName``
@@ -787,15 +787,15 @@
             task_instance=self,
             instance_id=self.instance_id or instance_id,
             location_id=self.location or location_id,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudMemorystoreScaleInstanceOperator(BaseOperator):
+class CloudMemorystoreScaleInstanceOperator(GoogleCloudBaseOperator):
     """
     Updates the metadata and configuration of a specific Redis instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreScaleInstanceOperator`
 
@@ -880,15 +880,15 @@
             task_instance=self,
             instance_id=self.instance_id or instance_id,
             location_id=self.location or location_id,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudMemorystoreCreateInstanceAndImportOperator(BaseOperator):
+class CloudMemorystoreCreateInstanceAndImportOperator(GoogleCloudBaseOperator):
     """
     Creates a Redis instance based on the specified tier and memory size and import a Redis RDB snapshot file
     from Cloud Storage into a this instance.
 
     By default, the instance is accessible from the project's `default network
     <https://cloud.google.com/compute/docs/networks-and-firewalls#networks>`__.
 
@@ -1001,15 +1001,15 @@
             task_instance=self,
             instance_id=self.instance_id,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudMemorystoreExportAndDeleteInstanceOperator(BaseOperator):
+class CloudMemorystoreExportAndDeleteInstanceOperator(GoogleCloudBaseOperator):
     """
     Export Redis instance data into a Redis RDB format file in Cloud Storage. In next step, deletes a this
     instance.
 
     Redis will continue serving during this operation.
 
     .. seealso::
@@ -1098,15 +1098,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudMemorystoreMemcachedApplyParametersOperator(BaseOperator):
+class CloudMemorystoreMemcachedApplyParametersOperator(GoogleCloudBaseOperator):
     """
     Will update current set of Parameters to the set of specified nodes of the Memcached Instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreMemcachedApplyParametersOperator`
 
@@ -1185,15 +1185,15 @@
             task_instance=self,
             instance_id=self.instance_id,
             location_id=self.location,
             project_id=self.project_id,
         )
 
 
-class CloudMemorystoreMemcachedCreateInstanceOperator(BaseOperator):
+class CloudMemorystoreMemcachedCreateInstanceOperator(GoogleCloudBaseOperator):
     """
     Creates a Memcached instance based on the specified tier and memory size.
 
     By default, the instance is accessible from the project's `default network
     <https://cloud.google.com/compute/docs/networks-and-firewalls#networks>`__.
 
     .. seealso::
@@ -1275,15 +1275,15 @@
             instance_id=self.instance_id,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return cloud_memcache.Instance.to_dict(result)
 
 
-class CloudMemorystoreMemcachedDeleteInstanceOperator(BaseOperator):
+class CloudMemorystoreMemcachedDeleteInstanceOperator(GoogleCloudBaseOperator):
     """
     Deletes a specific Memcached instance. Instance stops serving and data is deleted.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreMemcachedDeleteInstanceOperator`
 
@@ -1338,15 +1338,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudMemorystoreMemcachedGetInstanceOperator(BaseOperator):
+class CloudMemorystoreMemcachedGetInstanceOperator(GoogleCloudBaseOperator):
     """
     Gets the details of a specific Memcached instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreMemcachedGetInstanceOperator`
 
@@ -1423,15 +1423,15 @@
             instance_id=self.instance,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return cloud_memcache.Instance.to_dict(result)
 
 
-class CloudMemorystoreMemcachedListInstancesOperator(BaseOperator):
+class CloudMemorystoreMemcachedListInstancesOperator(GoogleCloudBaseOperator):
     """
     Lists all Memcached instances owned by a project in either the specified location (region) or all
         locations.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudMemorystoreMemcachedListInstancesOperator`
@@ -1505,15 +1505,15 @@
             task_instance=self,
             project_id=self.project_id or hook.project_id,
         )
         instances = [cloud_memcache.Instance.to_dict(a) for a in result]
         return instances
 
 
-class CloudMemorystoreMemcachedUpdateInstanceOperator(BaseOperator):
+class CloudMemorystoreMemcachedUpdateInstanceOperator(GoogleCloudBaseOperator):
     """
     Updates the metadata and configuration of a specific Memcached instance.
 
     :param update_mask: Required. Mask of fields to update. At least one path must be supplied in this field.
         The elements of the repeated paths field may only include these fields from ``Instance``:
 
         -  ``displayName``
@@ -1611,15 +1611,15 @@
             task_instance=self,
             instance_id=self.instance_id or instance_id,
             location_id=self.location or location_id,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudMemorystoreMemcachedUpdateParametersOperator(BaseOperator):
+class CloudMemorystoreMemcachedUpdateParametersOperator(GoogleCloudBaseOperator):
     """
     Updates the defined Memcached Parameters for an existing Instance. This method only stages the
         parameters, it must be followed by apply_parameters to apply the parameters to nodes of
         the Memcached Instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_sql.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_sql.py`

 * *Files 5% similar despite different names*

```diff
@@ -20,17 +20,18 @@
 
 from typing import TYPE_CHECKING, Iterable, Mapping, Sequence
 
 from googleapiclient.errors import HttpError
 
 from airflow.exceptions import AirflowException
 from airflow.hooks.base import BaseHook
-from airflow.models import BaseOperator, Connection
+from airflow.models import Connection
 from airflow.providers.google.cloud.hooks.cloud_sql import CloudSQLDatabaseHook, CloudSQLHook
 from airflow.providers.google.cloud.links.cloud_sql import CloudSQLInstanceDatabaseLink, CloudSQLInstanceLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.utils.field_validator import GcpBodyFieldValidator
 from airflow.providers.google.common.hooks.base_google import get_field
 from airflow.providers.google.common.links.storage import FileDetailsLink
 from airflow.providers.mysql.hooks.mysql import MySqlHook
 from airflow.providers.postgres.hooks.postgres import PostgresHook
 
 if TYPE_CHECKING:
@@ -209,15 +210,15 @@
     dict(name="project", optional=True),
     dict(name="etag", optional=True),
     dict(name="charset", optional=True),
     dict(name="collation", optional=True),
 ]
 
 
-class CloudSQLBaseOperator(BaseOperator):
+class CloudSQLBaseOperator(GoogleCloudBaseOperator):
     """
     Abstract base operator for Google Cloud SQL operators to inherit from.
 
     :param instance: Cloud SQL instance ID. This does not include the project ID.
     :param project_id: Optional, Google Cloud Project ID.  f set to None or missing,
             the default project_id from the Google Cloud connection is used.
     :param gcp_conn_id: The connection ID used to connect to Google Cloud.
@@ -519,14 +520,106 @@
         if not self._check_if_instance_exists(self.instance, hook):
             print(f"Cloud SQL instance with ID {self.instance} does not exist. Aborting delete.")
             return True
         else:
             return hook.delete_instance(project_id=self.project_id, instance=self.instance)
 
 
+class CloudSQLCloneInstanceOperator(CloudSQLBaseOperator):
+    """
+    Clones an instance to a target instance
+
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:CloudSQLCloneInstanceOperator`
+
+    :param instance: Database instance ID to be cloned. This does not include the
+            project ID.
+    :param destination_instance_name: Database instance ID to be created. This does not include the
+        project ID.
+    :param clone_context: additional clone_context parameters as described in
+        https://cloud.google.com/sql/docs/mysql/admin-api/rest/v1/instances/clone
+    :param project_id: Project ID of the project that contains the instance. If set
+        to None or missing, the default project_id from the Google Cloud connection is used.
+    :param gcp_conn_id: The connection ID used to connect to Google Cloud.
+    :param api_version: API version used (e.g. v1beta4).
+    :param impersonation_chain: Optional service account to impersonate using short-term
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
+    """
+
+    # [START gcp_sql_clone_template_fields]
+    template_fields: Sequence[str] = (
+        "project_id",
+        "instance",
+        "destination_instance_name",
+        "gcp_conn_id",
+        "api_version",
+    )
+    # [END gcp_sql_clone_template_fields]
+
+    def __init__(
+        self,
+        *,
+        instance: str,
+        destination_instance_name: str,
+        clone_context: dict | None = None,
+        project_id: str | None = None,
+        gcp_conn_id: str = "google_cloud_default",
+        api_version: str = "v1beta4",
+        impersonation_chain: str | Sequence[str] | None = None,
+        **kwargs,
+    ) -> None:
+        self.destination_instance_name = destination_instance_name
+        self.clone_context = clone_context or {}
+        super().__init__(
+            project_id=project_id,
+            instance=instance,
+            gcp_conn_id=gcp_conn_id,
+            api_version=api_version,
+            impersonation_chain=impersonation_chain,
+            **kwargs,
+        )
+
+    def _validate_inputs(self) -> None:
+        super()._validate_inputs()
+        if not self.destination_instance_name:
+            raise AirflowException("The required parameter 'destination_instance_name' is empty or None")
+
+    def execute(self, context: Context):
+        hook = CloudSQLHook(
+            gcp_conn_id=self.gcp_conn_id,
+            api_version=self.api_version,
+            impersonation_chain=self.impersonation_chain,
+        )
+        if not self._check_if_instance_exists(self.instance, hook):
+            raise AirflowException(
+                f"Cloud SQL instance with ID {self.instance} does not exist. "
+                "Please specify another instance to patch."
+            )
+        else:
+            body = {
+                "cloneContext": {
+                    "kind": "sql#cloneContext",
+                    "destinationInstanceName": self.destination_instance_name,
+                    **self.clone_context,
+                }
+            }
+            return hook.clone_instance(
+                project_id=self.project_id,
+                body=body,
+                instance=self.instance,
+            )
+
+
 class CloudSQLCreateInstanceDatabaseOperator(CloudSQLBaseOperator):
     """
     Creates a new database inside a Cloud SQL instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudSQLCreateInstanceDatabaseOperator`
@@ -1018,15 +1111,15 @@
             task_instance=self,
             uri=self.body["importContext"]["uri"][5:],
             project_id=self.project_id or hook.project_id,
         )
         return hook.import_instance(project_id=self.project_id, instance=self.instance, body=self.body)
 
 
-class CloudSQLExecuteQueryOperator(BaseOperator):
+class CloudSQLExecuteQueryOperator(GoogleCloudBaseOperator):
     """
     Performs DML or DDL query on an existing Cloud Sql instance. It optionally uses
     cloud-sql-proxy to establish secure connection with the database.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudSQLExecuteQueryOperator`
@@ -1041,14 +1134,16 @@
         (default value: False)
     :param gcp_conn_id: The connection ID used to connect to Google Cloud for
         cloud-sql-proxy authentication.
     :param gcp_cloudsql_conn_id: The connection ID used to connect to Google Cloud SQL
        its schema should be gcpcloudsql://.
        See :class:`~airflow.providers.google.cloud.hooks.cloud_sql.CloudSQLDatabaseHook` for
        details on how to define ``gcpcloudsql://`` connection.
+    :param sql_proxy_binary_path: (optional) Path to the cloud-sql-proxy binary.
+          is not specified or the binary is not present, it is automatically downloaded.
     """
 
     # [START gcp_sql_query_template_fields]
     template_fields: Sequence[str] = ("sql", "gcp_cloudsql_conn_id", "gcp_conn_id")
     template_ext: Sequence[str] = (".sql",)
     template_fields_renderers = {"sql": "sql"}
     # [END gcp_sql_query_template_fields]
@@ -1058,23 +1153,25 @@
         self,
         *,
         sql: str | Iterable[str],
         autocommit: bool = False,
         parameters: Iterable | Mapping | None = None,
         gcp_conn_id: str = "google_cloud_default",
         gcp_cloudsql_conn_id: str = "google_cloud_sql_default",
+        sql_proxy_binary_path: str | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.sql = sql
         self.gcp_conn_id = gcp_conn_id
         self.gcp_cloudsql_conn_id = gcp_cloudsql_conn_id
         self.autocommit = autocommit
         self.parameters = parameters
         self.gcp_connection: Connection | None = None
+        self.sql_proxy_binary_path = sql_proxy_binary_path
 
     def _execute_query(self, hook: CloudSQLDatabaseHook, database_hook: PostgresHook | MySqlHook) -> None:
         cloud_sql_proxy_runner = None
         try:
             if hook.use_proxy:
                 cloud_sql_proxy_runner = hook.get_sqlproxy_runner()
                 hook.free_reserved_port()
@@ -1090,14 +1187,15 @@
 
     def execute(self, context: Context):
         self.gcp_connection = BaseHook.get_connection(self.gcp_conn_id)
         hook = CloudSQLDatabaseHook(
             gcp_cloudsql_conn_id=self.gcp_cloudsql_conn_id,
             gcp_conn_id=self.gcp_conn_id,
             default_gcp_project_id=get_field(self.gcp_connection.extra_dejson, "project"),
+            sql_proxy_binary_path=self.sql_proxy_binary_path,
         )
         hook.validate_ssl_certs()
         connection = hook.create_connection()
         hook.validate_socket_path_length()
         database_hook = hook.get_database_hook(connection=connection)
         try:
             self._execute_query(hook, database_hook)
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/cloud_storage_transfer_service.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/cloud_storage_transfer_service.py`

 * *Files 0% similar despite different names*

```diff
@@ -20,15 +20,14 @@
 
 import warnings
 from copy import deepcopy
 from datetime import date, time
 from typing import TYPE_CHECKING, Sequence
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.amazon.aws.hooks.base_aws import AwsBaseHook
 from airflow.providers.google.cloud.hooks.cloud_storage_transfer_service import (
     ACCESS_KEY_ID,
     AWS_ACCESS_KEY,
     AWS_S3_DATA_SOURCE,
     BUCKET_NAME,
     DAY,
@@ -57,14 +56,15 @@
     GcpTransferJobsStatus,
 )
 from airflow.providers.google.cloud.links.cloud_storage_transfer import (
     CloudStorageTransferDetailsLink,
     CloudStorageTransferJobLink,
     CloudStorageTransferListLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.utils.helpers import normalize_directory_path
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 class TransferJobPreprocessor:
@@ -170,15 +170,15 @@
         :raises: AirflowException
         """
         if TRANSFER_SPEC in self.body:
             self._restrict_aws_credentials()
             self._verify_data_source()
 
 
-class CloudDataTransferServiceCreateJobOperator(BaseOperator):
+class CloudDataTransferServiceCreateJobOperator(GoogleCloudBaseOperator):
     """
     Creates a transfer job that runs periodically.
 
     .. warning::
 
         This operator is NOT idempotent in the following cases:
 
@@ -265,15 +265,15 @@
                 project_id=project_id,
                 job_name=result[NAME],
             )
 
         return result
 
 
-class CloudDataTransferServiceUpdateJobOperator(BaseOperator):
+class CloudDataTransferServiceUpdateJobOperator(GoogleCloudBaseOperator):
     """
     Updates a transfer job that runs periodically.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataTransferServiceUpdateJobOperator`
 
@@ -355,15 +355,15 @@
                 project_id=project_id,
                 job_name=self.job_name,
             )
 
         return hook.update_transfer_job(job_name=self.job_name, body=self.body)
 
 
-class CloudDataTransferServiceDeleteJobOperator(BaseOperator):
+class CloudDataTransferServiceDeleteJobOperator(GoogleCloudBaseOperator):
     """
     Delete a transfer job. This is a soft delete. After a transfer job is
     deleted, the job and all the transfer executions are subject to garbage
     collection. Transfer jobs become eligible for garbage collection
     30 days after soft delete.
 
     .. seealso::
@@ -424,15 +424,15 @@
             api_version=self.api_version,
             gcp_conn_id=self.gcp_conn_id,
             impersonation_chain=self.google_impersonation_chain,
         )
         hook.delete_transfer_job(job_name=self.job_name, project_id=self.project_id)
 
 
-class CloudDataTransferServiceGetOperationOperator(BaseOperator):
+class CloudDataTransferServiceGetOperationOperator(GoogleCloudBaseOperator):
     """
     Gets the latest state of a long-running operation in Google Storage Transfer
     Service.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataTransferServiceGetOperationOperator`
@@ -498,15 +498,15 @@
                 project_id=project_id,
                 operation_name=self.operation_name,
             )
 
         return operation
 
 
-class CloudDataTransferServiceListOperationsOperator(BaseOperator):
+class CloudDataTransferServiceListOperationsOperator(GoogleCloudBaseOperator):
     """
     Lists long-running operations in Google Storage Transfer
     Service that match the specified filter.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataTransferServiceListOperationsOperator`
@@ -581,15 +581,15 @@
                 task_instance=self,
                 project_id=project_id,
             )
 
         return operations_list
 
 
-class CloudDataTransferServicePauseOperationOperator(BaseOperator):
+class CloudDataTransferServicePauseOperationOperator(GoogleCloudBaseOperator):
     """
     Pauses a transfer operation in Google Storage Transfer Service.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataTransferServicePauseOperationOperator`
 
@@ -640,15 +640,15 @@
             api_version=self.api_version,
             gcp_conn_id=self.gcp_conn_id,
             impersonation_chain=self.google_impersonation_chain,
         )
         hook.pause_transfer_operation(operation_name=self.operation_name)
 
 
-class CloudDataTransferServiceResumeOperationOperator(BaseOperator):
+class CloudDataTransferServiceResumeOperationOperator(GoogleCloudBaseOperator):
     """
     Resumes a transfer operation in Google Storage Transfer Service.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataTransferServiceResumeOperationOperator`
 
@@ -699,15 +699,15 @@
             api_version=self.api_version,
             gcp_conn_id=self.gcp_conn_id,
             impersonation_chain=self.google_impersonation_chain,
         )
         hook.resume_transfer_operation(operation_name=self.operation_name)
 
 
-class CloudDataTransferServiceCancelOperationOperator(BaseOperator):
+class CloudDataTransferServiceCancelOperationOperator(GoogleCloudBaseOperator):
     """
     Cancels a transfer operation in Google Storage Transfer Service.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataTransferServiceCancelOperationOperator`
 
@@ -759,15 +759,15 @@
             api_version=self.api_version,
             gcp_conn_id=self.gcp_conn_id,
             impersonation_chain=self.google_impersonation_chain,
         )
         hook.cancel_transfer_operation(operation_name=self.operation_name)
 
 
-class CloudDataTransferServiceS3ToGCSOperator(BaseOperator):
+class CloudDataTransferServiceS3ToGCSOperator(GoogleCloudBaseOperator):
     """
     Synchronizes an S3 bucket with a Google Cloud Storage bucket using the
     Google Cloud Storage Transfer Service.
 
     .. warning::
 
         This operator is NOT idempotent. If you run it many times, many transfer
@@ -932,15 +932,15 @@
 
         if self.transfer_options is not None:
             body[TRANSFER_SPEC][TRANSFER_OPTIONS] = self.transfer_options  # type: ignore[index]
 
         return body
 
 
-class CloudDataTransferServiceGCSToGCSOperator(BaseOperator):
+class CloudDataTransferServiceGCSToGCSOperator(GoogleCloudBaseOperator):
     """
     Copies objects from a bucket to another using the Google Cloud Storage Transfer Service.
 
     .. warning::
 
         This operator is NOT idempotent. If you run it many times, many transfer
         jobs will be created in the Google Cloud.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/compute.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/compute.py`

 * *Files 0% similar despite different names*

```diff
@@ -23,29 +23,29 @@
 
 from google.api_core import exceptions
 from google.api_core.retry import Retry
 from google.cloud.compute_v1.types import Instance, InstanceGroupManager, InstanceTemplate
 from json_merge_patch import merge
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.compute import ComputeEngineHook
 from airflow.providers.google.cloud.links.compute import (
     ComputeInstanceDetailsLink,
     ComputeInstanceGroupManagerDetailsLink,
     ComputeInstanceTemplateDetailsLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.utils.field_sanitizer import GcpBodyFieldSanitizer
 from airflow.providers.google.cloud.utils.field_validator import GcpBodyFieldValidator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class ComputeEngineBaseOperator(BaseOperator):
+class ComputeEngineBaseOperator(GoogleCloudBaseOperator):
     """Abstract base operator for Google Compute Engine operators to inherit from."""
 
     def __init__(
         self,
         *,
         zone: str,
         resource_id: str,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/datacatalog.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/datacatalog.py`

 * *Files 2% similar despite different names*

```diff
@@ -29,27 +29,27 @@
     SearchCatalogResult,
     Tag,
     TagTemplate,
     TagTemplateField,
 )
 from google.protobuf.field_mask_pb2 import FieldMask
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.datacatalog import CloudDataCatalogHook
 from airflow.providers.google.cloud.links.datacatalog import (
     DataCatalogEntryGroupLink,
     DataCatalogEntryLink,
     DataCatalogTagTemplateLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudDataCatalogCreateEntryOperator(BaseOperator):
+class CloudDataCatalogCreateEntryOperator(GoogleCloudBaseOperator):
     """
     Creates an entry.
 
     Currently only entries of 'FILESET' type can be created.
 
     The newly created entry ID are saved under the ``entry_id`` key in XCOM.
 
@@ -159,15 +159,15 @@
             entry_group_id=self.entry_group,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return Entry.to_dict(result)
 
 
-class CloudDataCatalogCreateEntryGroupOperator(BaseOperator):
+class CloudDataCatalogCreateEntryGroupOperator(GoogleCloudBaseOperator):
     """
     Creates an EntryGroup.
 
     The newly created entry group ID are saved under the ``entry_group_id`` key in XCOM.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -272,15 +272,15 @@
             entry_group_id=self.entry_group_id,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return EntryGroup.to_dict(result)
 
 
-class CloudDataCatalogCreateTagOperator(BaseOperator):
+class CloudDataCatalogCreateTagOperator(GoogleCloudBaseOperator):
     """
     Creates a tag on an entry.
 
     The newly created tag ID are saved under the ``tag_id`` key in XCOM.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -408,15 +408,15 @@
             entry_group_id=self.entry_group,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return Tag.to_dict(tag)
 
 
-class CloudDataCatalogCreateTagTemplateOperator(BaseOperator):
+class CloudDataCatalogCreateTagTemplateOperator(GoogleCloudBaseOperator):
     """
     Creates a tag template.
 
     The newly created tag template are saved under the ``tag_template_id`` key in XCOM.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -518,15 +518,15 @@
             tag_template_id=self.tag_template_id,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return TagTemplate.to_dict(result)
 
 
-class CloudDataCatalogCreateTagTemplateFieldOperator(BaseOperator):
+class CloudDataCatalogCreateTagTemplateFieldOperator(GoogleCloudBaseOperator):
     r"""
     Creates a field in a tag template.
 
     The newly created tag template field are saved under the ``tag_template_field_id`` key in XCOM.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -637,15 +637,15 @@
             tag_template_id=self.tag_template,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return TagTemplateField.to_dict(result)
 
 
-class CloudDataCatalogDeleteEntryOperator(BaseOperator):
+class CloudDataCatalogDeleteEntryOperator(GoogleCloudBaseOperator):
     """
     Deletes an existing entry.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogDeleteEntryOperator`
 
@@ -722,15 +722,15 @@
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
         except NotFound:
             self.log.info("Entry doesn't exists. Skipping.")
 
 
-class CloudDataCatalogDeleteEntryGroupOperator(BaseOperator):
+class CloudDataCatalogDeleteEntryGroupOperator(GoogleCloudBaseOperator):
     """
     Deletes an EntryGroup.
 
     Only entry groups that do not contain entries can be deleted.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -804,15 +804,15 @@
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
         except NotFound:
             self.log.info("Entry doesn't exists. skipping")
 
 
-class CloudDataCatalogDeleteTagOperator(BaseOperator):
+class CloudDataCatalogDeleteTagOperator(GoogleCloudBaseOperator):
     """
     Deletes a tag.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogDeleteTagOperator`
 
@@ -894,15 +894,15 @@
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
         except NotFound:
             self.log.info("Entry doesn't exists. skipping")
 
 
-class CloudDataCatalogDeleteTagTemplateOperator(BaseOperator):
+class CloudDataCatalogDeleteTagTemplateOperator(GoogleCloudBaseOperator):
     """
     Deletes a tag template and all tags using the template.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogDeleteTagTemplateOperator`
 
@@ -981,15 +981,15 @@
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
         except NotFound:
             self.log.info("Tag Template doesn't exists. skipping")
 
 
-class CloudDataCatalogDeleteTagTemplateFieldOperator(BaseOperator):
+class CloudDataCatalogDeleteTagTemplateFieldOperator(GoogleCloudBaseOperator):
     """
     Deletes a field in a tag template and all uses of that field.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogDeleteTagTemplateFieldOperator`
 
@@ -1071,15 +1071,15 @@
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
         except NotFound:
             self.log.info("Tag Template field doesn't exists. skipping")
 
 
-class CloudDataCatalogGetEntryOperator(BaseOperator):
+class CloudDataCatalogGetEntryOperator(GoogleCloudBaseOperator):
     """
     Gets an entry.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogGetEntryOperator`
 
@@ -1163,15 +1163,15 @@
             entry_group_id=self.entry_group,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return Entry.to_dict(result)
 
 
-class CloudDataCatalogGetEntryGroupOperator(BaseOperator):
+class CloudDataCatalogGetEntryGroupOperator(GoogleCloudBaseOperator):
     """
     Gets an entry group.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogGetEntryGroupOperator`
 
@@ -1257,15 +1257,15 @@
             entry_group_id=self.entry_group,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return EntryGroup.to_dict(result)
 
 
-class CloudDataCatalogGetTagTemplateOperator(BaseOperator):
+class CloudDataCatalogGetTagTemplateOperator(GoogleCloudBaseOperator):
     """
     Gets a tag template.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogGetTagTemplateOperator`
 
@@ -1343,15 +1343,15 @@
             tag_template_id=self.tag_template,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return TagTemplate.to_dict(result)
 
 
-class CloudDataCatalogListTagsOperator(BaseOperator):
+class CloudDataCatalogListTagsOperator(GoogleCloudBaseOperator):
     """
     Lists the tags on an Entry.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogListTagsOperator`
 
@@ -1443,15 +1443,15 @@
             entry_group_id=self.entry_group,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
         return [Tag.to_dict(item) for item in result]
 
 
-class CloudDataCatalogLookupEntryOperator(BaseOperator):
+class CloudDataCatalogLookupEntryOperator(GoogleCloudBaseOperator):
     r"""
     Get an entry by target resource name.
 
     This method allows clients to use the resource name from the source Google Cloud service
     to get the Data Catalog Entry.
 
     .. seealso::
@@ -1534,15 +1534,15 @@
             entry_group_id=entry_group_id,
             location_id=location_id,
             project_id=project_id,
         )
         return Entry.to_dict(result)
 
 
-class CloudDataCatalogRenameTagTemplateFieldOperator(BaseOperator):
+class CloudDataCatalogRenameTagTemplateFieldOperator(GoogleCloudBaseOperator):
     """
     Renames a field in a tag template.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogRenameTagTemplateFieldOperator`
 
@@ -1631,15 +1631,15 @@
             task_instance=self,
             tag_template_id=self.tag_template,
             location_id=self.location,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudDataCatalogSearchCatalogOperator(BaseOperator):
+class CloudDataCatalogSearchCatalogOperator(GoogleCloudBaseOperator):
     r"""
     Searches Data Catalog for multiple resources like entries, tags that match a query.
 
     This does not return the complete resource, only the resource identifier and high level fields.
     Clients can subsequently call ``Get`` methods.
 
     Note that searches do not have full recall. There may be results that match your query but are not
@@ -1741,15 +1741,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         return [SearchCatalogResult.to_dict(item) for item in result]
 
 
-class CloudDataCatalogUpdateEntryOperator(BaseOperator):
+class CloudDataCatalogUpdateEntryOperator(GoogleCloudBaseOperator):
     """
     Updates an existing entry.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogUpdateEntryOperator`
 
@@ -1851,15 +1851,15 @@
             entry_id=self.entry_id or entry_id,
             entry_group_id=self.entry_group or entry_group_id,
             location_id=self.location or location_id,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudDataCatalogUpdateTagOperator(BaseOperator):
+class CloudDataCatalogUpdateTagOperator(GoogleCloudBaseOperator):
     """
     Updates an existing tag.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogUpdateTagOperator`
 
@@ -1965,15 +1965,15 @@
             entry_id=self.entry or entry_id,
             entry_group_id=self.entry_group or entry_group_id,
             location_id=self.location or location_id,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudDataCatalogUpdateTagTemplateOperator(BaseOperator):
+class CloudDataCatalogUpdateTagTemplateOperator(GoogleCloudBaseOperator):
     """
     Updates a tag template.
 
     This method cannot be used to update the fields of a template. The tag
     template fields are represented as separate resources and should be updated using their own
     create/update/delete methods.
 
@@ -2074,15 +2074,15 @@
             task_instance=self,
             tag_template_id=self.tag_template_id or tag_template_id,
             location_id=self.location or location_id,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class CloudDataCatalogUpdateTagTemplateFieldOperator(BaseOperator):
+class CloudDataCatalogUpdateTagTemplateFieldOperator(GoogleCloudBaseOperator):
     """
     Updates a field in a tag template. This method cannot be used to update the field type.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataCatalogUpdateTagTemplateFieldOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataflow.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataflow.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,23 +24,23 @@
 import warnings
 from contextlib import ExitStack
 from enum import Enum
 from typing import TYPE_CHECKING, Any, Sequence
 
 from airflow import AirflowException
 from airflow.compat.functools import cached_property
-from airflow.models import BaseOperator
 from airflow.providers.apache.beam.hooks.beam import BeamHook, BeamRunnerType
 from airflow.providers.google.cloud.hooks.dataflow import (
     DEFAULT_DATAFLOW_LOCATION,
     DataflowHook,
     process_line_and_extract_dataflow_job_id_callback,
 )
 from airflow.providers.google.cloud.hooks.gcs import GCSHook
 from airflow.providers.google.cloud.links.dataflow import DataflowJobLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.triggers.dataflow import TemplateJobStartTrigger
 from airflow.version import version
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
@@ -166,15 +166,15 @@
         self.cancel_timeout = cancel_timeout
         self.wait_until_finished = wait_until_finished
         self.multiple_jobs = multiple_jobs
         self.check_if_running = check_if_running
         self.service_account = service_account
 
 
-class DataflowCreateJavaJobOperator(BaseOperator):
+class DataflowCreateJavaJobOperator(GoogleCloudBaseOperator):
     """
     Start a Java Cloud Dataflow batch job. The parameters of the operation
     will be passed to the job.
 
     This class is deprecated.
     Please use `providers.apache.beam.operators.beam.BeamRunJavaPipelineOperator`.
 
@@ -460,15 +460,15 @@
         self.log.info("On kill.")
         if self.job_id:
             self.dataflow_hook.cancel_job(
                 job_id=self.job_id, project_id=self.project_id or self.dataflow_hook.project_id
             )
 
 
-class DataflowTemplatedJobStartOperator(BaseOperator):
+class DataflowTemplatedJobStartOperator(GoogleCloudBaseOperator):
     """
     Start a Templated Cloud Dataflow job. The parameters of the operation
     will be passed to the job.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:DataflowTemplatedJobStartOperator`
@@ -745,15 +745,15 @@
                 job_name=self.job_name,
                 job_id=self.job.get("id"),
                 project_id=self.job.get("projectId"),
                 location=self.job.get("location"),
             )
 
 
-class DataflowStartFlexTemplateOperator(BaseOperator):
+class DataflowStartFlexTemplateOperator(GoogleCloudBaseOperator):
     """
     Starts flex templates with the Dataflow pipeline.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:DataflowStartFlexTemplateOperator`
 
@@ -936,15 +936,15 @@
             self.hook.cancel_job(
                 job_id=self.job.get("id"),
                 project_id=self.job.get("projectId"),
                 location=self.job.get("location"),
             )
 
 
-class DataflowStartSqlJobOperator(BaseOperator):
+class DataflowStartSqlJobOperator(GoogleCloudBaseOperator):
     """
     Starts Dataflow SQL query.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:DataflowStartSqlJobOperator`
 
@@ -1051,15 +1051,15 @@
             self.hook.cancel_job(
                 job_id=self.job.get("id"),
                 project_id=self.job.get("projectId"),
                 location=self.job.get("location"),
             )
 
 
-class DataflowCreatePythonJobOperator(BaseOperator):
+class DataflowCreatePythonJobOperator(GoogleCloudBaseOperator):
     """
     Launching Cloud Dataflow jobs written in python. Note that both
     dataflow_default_options and options will be merged to specify pipeline
     execution parameter, and dataflow_default_options is expected to save
     high-level options, for instances, project and zone information, which
     apply to all dataflow operators in the DAG.
 
@@ -1277,15 +1277,15 @@
         self.log.info("On kill.")
         if self.job_id:
             self.dataflow_hook.cancel_job(
                 job_id=self.job_id, project_id=self.project_id or self.dataflow_hook.project_id
             )
 
 
-class DataflowStopJobOperator(BaseOperator):
+class DataflowStopJobOperator(GoogleCloudBaseOperator):
     """
     Stops the job with the specified name prefix or Job ID.
     All jobs with provided name prefix will be stopped.
     Streaming jobs are drained by default.
 
     Parameter ``job_name_prefix`` and ``job_id`` are mutually exclusive.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataform.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataform.py`

 * *Files 1% similar despite different names*

```diff
@@ -36,19 +36,19 @@
     MakeDirectoryResponse,
     Repository,
     WorkflowInvocation,
     Workspace,
     WriteFileResponse,
 )
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.dataform import DataformHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 
-class DataformCreateCompilationResultOperator(BaseOperator):
+class DataformCreateCompilationResultOperator(GoogleCloudBaseOperator):
     """
     Creates a new CompilationResult in a given project and location.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param repository_id: Required. The ID of the Dataform repository that the task belongs to.
     :param compilation_result:  Required. The compilation result to create.
@@ -113,15 +113,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         return CompilationResult.to_dict(result)
 
 
-class DataformGetCompilationResultOperator(BaseOperator):
+class DataformGetCompilationResultOperator(GoogleCloudBaseOperator):
     """
     Fetches a single CompilationResult.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param repository_id: Required. The ID of the Dataform repository that the task belongs to.
     :param compilation_result_id:  The Id of the Dataform Compilation Result
@@ -188,15 +188,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         return CompilationResult.to_dict(result)
 
 
-class DataformCreateWorkflowInvocationOperator(BaseOperator):
+class DataformCreateWorkflowInvocationOperator(GoogleCloudBaseOperator):
     """
     Creates a new WorkflowInvocation in a given Repository.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param repository_id: Required. The ID of the Dataform repository that the task belongs to.
     :param workflow_invocation:  Required. The workflow invocation resource to create.
@@ -290,15 +290,15 @@
                 region=self.region,
                 timeout=self.timeout,
                 wait_time=self.wait_time,
             )
         return WorkflowInvocation.to_dict(result)
 
 
-class DataformGetWorkflowInvocationOperator(BaseOperator):
+class DataformGetWorkflowInvocationOperator(GoogleCloudBaseOperator):
     """
     Fetches a single WorkflowInvocation.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param repository_id: Required. The ID of the Dataform repository that the task belongs to.
     :param workflow_invocation_id:  the workflow invocation resource's id.
@@ -366,15 +366,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         return WorkflowInvocation.to_dict(result)
 
 
-class DataformCancelWorkflowInvocationOperator(BaseOperator):
+class DataformCancelWorkflowInvocationOperator(GoogleCloudBaseOperator):
     """
     Requests cancellation of a running WorkflowInvocation.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param repository_id: Required. The ID of the Dataform repository that the task belongs to.
     :param workflow_invocation_id:  the workflow invocation resource's id.
@@ -441,15 +441,15 @@
             workflow_invocation_id=self.workflow_invocation_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class DataformCreateRepositoryOperator(BaseOperator):
+class DataformCreateRepositoryOperator(GoogleCloudBaseOperator):
     """
     Creates repository.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param repository_id: Required. The ID of the Dataform repository that the task belongs to.
     :param retry: Designation of what errors, if any, should be retried.
@@ -531,15 +531,15 @@
             region=self.region,
             repository_id=self.repository_id,
         )
 
         return Repository.to_dict(repository)
 
 
-class DataformDeleteRepositoryOperator(BaseOperator):
+class DataformDeleteRepositoryOperator(GoogleCloudBaseOperator):
     """
     Deletes repository.
 
     :param project_id: Required. The ID of the Google Cloud project where repository located.
     :param region: Required. The ID of the Google Cloud region where repository located.
     :param repository_id: Required. The ID of the Dataform repository that should be deleted.
     :param retry: Designation of what errors, if any, should be retried.
@@ -613,15 +613,15 @@
             force=self.force,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class DataformCreateWorkspaceOperator(BaseOperator):
+class DataformCreateWorkspaceOperator(GoogleCloudBaseOperator):
     """
     Creates workspace.
 
     :param project_id: Required. The ID of the Google Cloud project where workspace should be in.
     :param region: Required. Name of the Google Cloud region that where workspace should be in.
     :param repository_id: Required. The ID of the Dataform repository that the workspace belongs to.
     :param workspace_id: Required. The ID of the new workspace that will be created.
@@ -708,15 +708,15 @@
             repository_id=self.repository_id,
             workspace_id=self.workspace_id,
         )
 
         return Workspace.to_dict(workspace)
 
 
-class DataformDeleteWorkspaceOperator(BaseOperator):
+class DataformDeleteWorkspaceOperator(GoogleCloudBaseOperator):
     """
     Deletes workspace.
 
     :param project_id: Required. The ID of the Google Cloud project where workspace located.
     :param region: Required. The ID of the Google Cloud region where workspace located.
     :param repository_id: Required. The ID of the Dataform repository where workspace located.
     :param workspace_id: Required. The ID of the Dataform workspace that should be deleted.
@@ -792,15 +792,15 @@
             workspace_id=self.workspace_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class DataformWriteFileOperator(BaseOperator):
+class DataformWriteFileOperator(GoogleCloudBaseOperator):
     """
     Writes new file to specified workspace.
 
     :param project_id: Required. The ID of the Google Cloud project where workspace located.
     :param region: Required. The ID of the Google Cloud region where workspace located.
     :param repository_id: Required. The ID of the Dataform repository where workspace located.
     :param workspace_id: Required. The ID of the Dataform workspace where files should be created.
@@ -884,15 +884,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         return WriteFileResponse.to_dict(write_file_response)
 
 
-class DataformMakeDirectoryOperator(BaseOperator):
+class DataformMakeDirectoryOperator(GoogleCloudBaseOperator):
     """
     Makes new directory in specified workspace.
 
     :param project_id: Required. The ID of the Google Cloud project where workspace located.
     :param region: Required. The ID of the Google Cloud region where workspace located.
     :param repository_id: Required. The ID of the Dataform repository where workspace located.
     :param workspace_id: Required. The ID of the Dataform workspace where directory should be created.
@@ -974,15 +974,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
         return MakeDirectoryResponse.to_dict(make_directory_response)
 
 
-class DataformRemoveFileOperator(BaseOperator):
+class DataformRemoveFileOperator(GoogleCloudBaseOperator):
     """
     Removes file in specified workspace.
 
     :param project_id: Required. The ID of the Google Cloud project where workspace located.
     :param region: Required. The ID of the Google Cloud region where workspace located.
     :param repository_id: Required. The ID of the Dataform repository where workspace located.
     :param workspace_id: Required. The ID of the Dataform workspace where directory located.
@@ -1062,15 +1062,15 @@
             filepath=self.filepath,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class DataformRemoveDirectoryOperator(BaseOperator):
+class DataformRemoveDirectoryOperator(GoogleCloudBaseOperator):
     """
     Removes directory in specified workspace.
 
     :param project_id: Required. The ID of the Google Cloud project where workspace located.
     :param region: Required. The ID of the Google Cloud region where workspace located.
     :param repository_id: Required. The ID of the Dataform repository where workspace located.
     :param workspace_id: Required. The ID of the Dataform workspace where directory located.
@@ -1150,15 +1150,15 @@
             path=self.directory_path,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class DataformInstallNpmPackagesOperator(BaseOperator):
+class DataformInstallNpmPackagesOperator(GoogleCloudBaseOperator):
     """
     Installs npm dependencies in the provided workspace. Requires "package.json" to be created in workspace
 
     :param project_id: Required. The ID of the Google Cloud project where workspace located.
     :param region: Required. The ID of the Google Cloud region where workspace located.
     :param repository_id: Required. The ID of the Dataform repository where workspace located.
     :param workspace_id: Required. The ID of the Dataform workspace.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/datafusion.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/datafusion.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,21 +21,21 @@
 from time import sleep
 from typing import TYPE_CHECKING, Any, Sequence
 
 from google.api_core.retry import exponential_sleep_generator
 from googleapiclient.errors import HttpError
 
 from airflow import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.datafusion import SUCCESS_STATES, DataFusionHook, PipelineStates
 from airflow.providers.google.cloud.links.datafusion import (
     DataFusionInstanceLink,
     DataFusionPipelineLink,
     DataFusionPipelinesLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.triggers.datafusion import DataFusionStartPipelineTrigger
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 class DataFusionPipelineLinkHelper:
@@ -44,15 +44,15 @@
     @staticmethod
     def get_project_id(instance):
         instance = instance["name"]
         project_id = [x for x in instance.split("/") if x.startswith("airflow")][0]
         return project_id
 
 
-class CloudDataFusionRestartInstanceOperator(BaseOperator):
+class CloudDataFusionRestartInstanceOperator(GoogleCloudBaseOperator):
     """
     Restart a single Data Fusion instance.
     At the end of an operation instance is fully restarted.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionRestartInstanceOperator`
@@ -128,15 +128,15 @@
             task_instance=self,
             project_id=project_id,
             instance_name=self.instance_name,
             location=self.location,
         )
 
 
-class CloudDataFusionDeleteInstanceOperator(BaseOperator):
+class CloudDataFusionDeleteInstanceOperator(GoogleCloudBaseOperator):
     """
     Deletes a single Date Fusion instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionDeleteInstanceOperator`
 
@@ -201,15 +201,15 @@
             location=self.location,
             project_id=self.project_id,
         )
         hook.wait_for_operation(operation)
         self.log.info("Instance %s deleted successfully", self.instance_name)
 
 
-class CloudDataFusionCreateInstanceOperator(BaseOperator):
+class CloudDataFusionCreateInstanceOperator(GoogleCloudBaseOperator):
     """
     Creates a new Data Fusion instance in the specified project and location.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionCreateInstanceOperator`
 
@@ -307,15 +307,15 @@
             project_id=project_id,
             instance_name=self.instance_name,
             location=self.location,
         )
         return instance
 
 
-class CloudDataFusionUpdateInstanceOperator(BaseOperator):
+class CloudDataFusionUpdateInstanceOperator(GoogleCloudBaseOperator):
     """
     Updates a single Data Fusion instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionUpdateInstanceOperator`
 
@@ -405,15 +405,15 @@
             task_instance=self,
             project_id=project_id,
             instance_name=self.instance_name,
             location=self.location,
         )
 
 
-class CloudDataFusionGetInstanceOperator(BaseOperator):
+class CloudDataFusionGetInstanceOperator(GoogleCloudBaseOperator):
     """
     Gets details of a single Data Fusion instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionGetInstanceOperator`
 
@@ -487,15 +487,15 @@
             project_id=project_id,
             instance_name=self.instance_name,
             location=self.location,
         )
         return instance
 
 
-class CloudDataFusionCreatePipelineOperator(BaseOperator):
+class CloudDataFusionCreatePipelineOperator(GoogleCloudBaseOperator):
     """
     Creates a Cloud Data Fusion pipeline.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionCreatePipelineOperator`
 
@@ -586,15 +586,15 @@
             task_instance=self,
             uri=instance["serviceEndpoint"],
             pipeline_name=self.pipeline_name,
         )
         self.log.info("Pipeline %s created", self.pipeline_name)
 
 
-class CloudDataFusionDeletePipelineOperator(BaseOperator):
+class CloudDataFusionDeletePipelineOperator(GoogleCloudBaseOperator):
     """
     Deletes a Cloud Data Fusion pipeline.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionDeletePipelineOperator`
 
@@ -677,15 +677,15 @@
             version_id=self.version_id,
             instance_url=api_url,
             namespace=self.namespace,
         )
         self.log.info("Pipeline deleted")
 
 
-class CloudDataFusionListPipelinesOperator(BaseOperator):
+class CloudDataFusionListPipelinesOperator(GoogleCloudBaseOperator):
     """
     Lists Cloud Data Fusion pipelines.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionListPipelinesOperator`
 
@@ -774,15 +774,15 @@
         )
         self.log.info("Pipelines: %s", pipelines)
 
         DataFusionPipelinesLink.persist(context=context, task_instance=self, uri=service_endpoint)
         return pipelines
 
 
-class CloudDataFusionStartPipelineOperator(BaseOperator):
+class CloudDataFusionStartPipelineOperator(GoogleCloudBaseOperator):
     """
     Starts a Cloud Data Fusion pipeline. Works for both batch and stream pipelines.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionStartPipelineOperator`
 
@@ -949,15 +949,15 @@
             "%s completed with response %s ",
             self.task_id,
             event["message"],
         )
         return event["pipeline_id"]
 
 
-class CloudDataFusionStopPipelineOperator(BaseOperator):
+class CloudDataFusionStopPipelineOperator(GoogleCloudBaseOperator):
     """
     Stops a Cloud Data Fusion pipeline. Works for both batch and stream pipelines.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDataFusionStopPipelineOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataplex.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataplex.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,24 +26,24 @@
     from airflow.utils.context import Context
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry, exponential_sleep_generator
 from google.cloud.dataplex_v1.types import Lake, Task
 from googleapiclient.errors import HttpError
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.dataplex import DataplexHook
 from airflow.providers.google.cloud.links.dataplex import (
     DataplexLakeLink,
     DataplexTaskLink,
     DataplexTasksLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 
-class DataplexCreateTaskOperator(BaseOperator):
+class DataplexCreateTaskOperator(GoogleCloudBaseOperator):
     """
     Creates a task resource within a lake.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param lake_id: Required. The ID of the Google Cloud lake that the task belongs to.
     :param body:  Required. The Request body contains an instance of Task.
@@ -170,15 +170,15 @@
                 if task["state"] != "CREATING":
                     break
                 sleep(time_to_wait)
 
         return Task.to_dict(task)
 
 
-class DataplexDeleteTaskOperator(BaseOperator):
+class DataplexDeleteTaskOperator(GoogleCloudBaseOperator):
     """
     Delete the task resource.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param lake_id: Required. The ID of the Google Cloud lake that the task belongs to.
     :param dataplex_task_id: Required. Task identifier.
@@ -254,15 +254,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         hook.wait_for_operation(timeout=self.timeout, operation=operation)
         self.log.info("Dataplex task %s deleted successfully!", self.dataplex_task_id)
 
 
-class DataplexListTasksOperator(BaseOperator):
+class DataplexListTasksOperator(GoogleCloudBaseOperator):
     """
     Lists tasks under the given lake.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param lake_id: Required. The ID of the Google Cloud lake that the task belongs to.
     :param page_size: Optional. Maximum number of tasks to return. The service may return fewer than this
@@ -363,15 +363,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         return [Task.to_dict(task) for task in tasks]
 
 
-class DataplexGetTaskOperator(BaseOperator):
+class DataplexGetTaskOperator(GoogleCloudBaseOperator):
     """
     Get task resource.
 
     :param project_id: Required. The ID of the Google Cloud project that the task belongs to.
     :param region: Required. The ID of the Google Cloud region that the task belongs to.
     :param lake_id: Required. The ID of the Google Cloud lake that the task belongs to.
     :param dataplex_task_id: Required. Task identifier.
@@ -449,15 +449,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         DataplexTasksLink.persist(context=context, task_instance=self)
         return Task.to_dict(task)
 
 
-class DataplexCreateLakeOperator(BaseOperator):
+class DataplexCreateLakeOperator(GoogleCloudBaseOperator):
     """
     Creates a lake resource within a lake.
 
     :param project_id: Required. The ID of the Google Cloud project that the lake belongs to.
     :param region: Required. The ID of the Google Cloud region that the lake belongs to.
     :param lake_id: Required. Lake identifier.
     :param body:  Required. The Request body contains an instance of Lake.
@@ -581,15 +581,15 @@
         DataplexLakeLink.persist(
             context=context,
             task_instance=self,
         )
         return Lake.to_dict(lake)
 
 
-class DataplexDeleteLakeOperator(BaseOperator):
+class DataplexDeleteLakeOperator(GoogleCloudBaseOperator):
     """
     Delete the lake resource.
 
     :param project_id: Required. The ID of the Google Cloud project that the lake belongs to.
     :param region: Required. The ID of the Google Cloud region that the lake belongs to.
     :param lake_id: Required. Lake identifier.
     :param api_version: The version of the api that will be requested for example 'v1'.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataprep.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataprep.py`

 * *Files 11% similar despite different names*

```diff
@@ -16,23 +16,23 @@
 # specific language governing permissions and limitations
 # under the License.
 """This module contains a Google Dataprep operator."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Sequence
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.dataprep import GoogleDataprepHook
 from airflow.providers.google.cloud.links.dataprep import DataprepFlowLink, DataprepJobGroupLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class DataprepGetJobsForJobGroupOperator(BaseOperator):
+class DataprepGetJobsForJobGroupOperator(GoogleCloudBaseOperator):
     """
     Get information about the batch jobs within a Cloud Dataprep job.
     API documentation https://clouddataprep.com/documentation/api#section/Overview
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:DataprepGetJobsForJobGroupOperator`
@@ -58,15 +58,15 @@
         hook = GoogleDataprepHook(
             dataprep_conn_id="dataprep_default",
         )
         response = hook.get_jobs_for_job_group(job_id=int(self.job_group_id))
         return response
 
 
-class DataprepGetJobGroupOperator(BaseOperator):
+class DataprepGetJobGroupOperator(GoogleCloudBaseOperator):
     """
     Get the specified job group.
     A job group is a job that is executed from a specific node in a flow.
     API documentation https://clouddataprep.com/documentation/api#section/Overview
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -117,15 +117,15 @@
             job_group_id=int(self.job_group_id),
             embed=self.embed,
             include_deleted=self.include_deleted,
         )
         return response
 
 
-class DataprepRunJobGroupOperator(BaseOperator):
+class DataprepRunJobGroupOperator(GoogleCloudBaseOperator):
     """
     Create a ``jobGroup``, which launches the specified job as the authenticated user.
     This performs the same action as clicking on the Run Job button in the application.
     To get recipe_id please follow the Dataprep API documentation
     https://clouddataprep.com/documentation/api#operation/runJobGroup
 
     .. seealso::
@@ -166,15 +166,15 @@
                 project_id=self.project_id,
                 job_group_id=int(job_group_id),
             )
 
         return response
 
 
-class DataprepCopyFlowOperator(BaseOperator):
+class DataprepCopyFlowOperator(GoogleCloudBaseOperator):
     """
     Create a copy of the provided flow id, as well as all contained recipes.
 
     :param dataprep_conn_id: The Dataprep connection ID
     :param flow_id: ID of the flow to be copied
     :param name: Name for the copy of the flow
     :param description: Description of the copy of the flow
@@ -225,15 +225,15 @@
                 task_instance=self,
                 project_id=self.project_id,
                 flow_id=int(copied_flow_id),
             )
         return response
 
 
-class DataprepDeleteFlowOperator(BaseOperator):
+class DataprepDeleteFlowOperator(GoogleCloudBaseOperator):
     """
     Delete the flow with provided id.
 
     :param dataprep_conn_id: The Dataprep connection ID
     :param flow_id: ID of the flow to be copied
     """
 
@@ -252,15 +252,15 @@
 
     def execute(self, context: Context) -> None:
         self.log.info("Start delete operation of the flow with id: %d...", self.flow_id)
         hook = GoogleDataprepHook(dataprep_conn_id=self.dataprep_conn_id)
         hook.delete_flow(flow_id=int(self.flow_id))
 
 
-class DataprepRunFlowOperator(BaseOperator):
+class DataprepRunFlowOperator(GoogleCloudBaseOperator):
     """
     Runs the flow with the provided id copy of the provided flow id.
 
     :param dataprep_conn_id: The Dataprep connection ID
     :param flow_id: ID of the flow to be copied
     :param body_request: Body of the POST request to be sent.
     """
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataproc.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataproc.py`

 * *Files 2% similar despite different names*

```diff
@@ -33,32 +33,33 @@
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry, exponential_sleep_generator
 from google.cloud.dataproc_v1 import Batch, Cluster, ClusterStatus, JobStatus
 from google.protobuf.duration_pb2 import Duration
 from google.protobuf.field_mask_pb2 import FieldMask
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.dataproc import DataprocHook, DataProcJobBuilder
 from airflow.providers.google.cloud.hooks.gcs import GCSHook
 from airflow.providers.google.cloud.links.dataproc import (
     DATAPROC_BATCH_LINK,
     DATAPROC_BATCHES_LINK,
     DATAPROC_CLUSTER_LINK,
     DATAPROC_JOB_LOG_LINK,
     DATAPROC_WORKFLOW_LINK,
     DATAPROC_WORKFLOW_TEMPLATE_LINK,
     DataprocLink,
     DataprocListLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.triggers.dataproc import (
     DataprocBatchTrigger,
     DataprocClusterTrigger,
     DataprocDeleteClusterTrigger,
     DataprocSubmitTrigger,
+    DataprocWorkflowTrigger,
 )
 from airflow.utils import timezone
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
@@ -386,15 +387,15 @@
         """
         Helper method for easier migration.
         :return: Dict representing Dataproc cluster.
         """
         return self._build_cluster_data()
 
 
-class DataprocCreateClusterOperator(BaseOperator):
+class DataprocCreateClusterOperator(GoogleCloudBaseOperator):
     """
     Create a new cluster on Google Cloud Dataproc. The operator will wait until the
     creation is successful or an error occurs in the creation process. If the cluster
     already exists and ``use_if_exists`` is True then the operator will:
 
     - if cluster state is ERROR then delete it if specified and raise error
     - if cluster state is CREATING wait for it and then check for ERROR state
@@ -657,15 +658,15 @@
         if cluster_state == ClusterStatus.State.ERROR:
             raise AirflowException(f"Cluster is in ERROR state:\n{cluster_name}")
 
         self.log.info("%s completed successfully.", self.task_id)
         return event["cluster"]
 
 
-class DataprocScaleClusterOperator(BaseOperator):
+class DataprocScaleClusterOperator(GoogleCloudBaseOperator):
     """
     Scale, up or down, a cluster on Google Cloud Dataproc.
     The operator will wait until the cluster is re-scaled.
 
     **Example**: ::
 
         t1 = DataprocClusterScaleOperator(
@@ -793,15 +794,15 @@
             graceful_decommission_timeout=self._graceful_decommission_timeout_object,
             update_mask={"paths": update_mask},
         )
         operation.result()
         self.log.info("Cluster scaling finished")
 
 
-class DataprocDeleteClusterOperator(BaseOperator):
+class DataprocDeleteClusterOperator(GoogleCloudBaseOperator):
     """
     Deletes a cluster in a project.
 
     :param region: Required. The Cloud Dataproc region in which to handle the request (templated).
     :param cluster_name: Required. The cluster name (templated).
     :param project_id: Optional. The ID of the Google Cloud project that the cluster belongs to (templated).
     :param cluster_uuid: Optional. Specifying the ``cluster_uuid`` means the RPC should fail
@@ -872,20 +873,18 @@
             end_time: float = time.time() + self.timeout
             self.defer(
                 trigger=DataprocDeleteClusterTrigger(
                     gcp_conn_id=self.gcp_conn_id,
                     project_id=self.project_id,
                     region=self.region,
                     cluster_name=self.cluster_name,
-                    request_id=self.request_id,
-                    retry=self.retry,
                     end_time=end_time,
                     metadata=self.metadata,
                     impersonation_chain=self.impersonation_chain,
-                    polling_interval=self.polling_interval_seconds,
+                    polling_interval_seconds=self.polling_interval_seconds,
                 ),
                 method_name="execute_complete",
             )
 
     def execute_complete(self, context: Context, event: dict[str, Any] | None = None) -> Any:
         """
         Callback for when the trigger fires - returns immediately.
@@ -908,15 +907,15 @@
             request_id=self.request_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class DataprocJobBaseOperator(BaseOperator):
+class DataprocJobBaseOperator(GoogleCloudBaseOperator):
     """
     The base class for operators that launch job on DataProc.
 
     :param region: The specified region where the dataproc cluster is created.
     :param job_name: The job name used in the DataProc cluster. This name by default
         is the task_id appended with the execution data, but can be templated. The
         name will always be appended with a random number to avoid name clashes.
@@ -1612,15 +1611,15 @@
         job_template.add_args(self.arguments)
         job_template.add_archive_uris(self.archives)
         job_template.add_file_uris(self.files)
         job_template.add_python_file_uris(self.pyfiles)
         super().execute(context)
 
 
-class DataprocCreateWorkflowTemplateOperator(BaseOperator):
+class DataprocCreateWorkflowTemplateOperator(GoogleCloudBaseOperator):
     """
     Creates new workflow template.
 
     :param project_id: Optional. The ID of the Google Cloud project the cluster belongs to.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param template: The Dataproc workflow template to create. If a dict is provided,
         it must be of the same form as the protobuf message WorkflowTemplate.
@@ -1677,22 +1676,22 @@
             context=context,
             task_instance=self,
             url=DATAPROC_WORKFLOW_TEMPLATE_LINK,
             resource=self.template["id"],
         )
 
 
-class DataprocInstantiateWorkflowTemplateOperator(BaseOperator):
+class DataprocInstantiateWorkflowTemplateOperator(GoogleCloudBaseOperator):
     """
     Instantiate a WorkflowTemplate on Google Cloud Dataproc. The operator will wait
     until the WorkflowTemplate is finished executing.
 
     .. seealso::
         Please refer to:
-        https://cloud.google.com/dataproc/docs/reference/rest/v1beta2/projects.regions.workflowTemplates/instantiate
+        https://cloud.google.com/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/instantiate
 
     :param template_id: The id of the template. (templated)
     :param project_id: The ID of the google cloud project in which
         the template runs
     :param region: The specified region where the dataproc cluster is created.
     :param parameters: a map of parameters for Dataproc Template in key-value format:
         map (key: string, value: string)
@@ -1713,14 +1712,16 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
+    :param deferrable: Run operator in the deferrable mode.
+    :param polling_interval_seconds: Time (seconds) to wait between calls to check the run status.
     """
 
     template_fields: Sequence[str] = ("template_id", "impersonation_chain", "request_id", "parameters")
     template_fields_renderers = {"parameters": "json"}
     operator_extra_links = (DataprocLink(),)
 
     def __init__(
@@ -1733,29 +1734,34 @@
         request_id: str | None = None,
         parameters: dict[str, str] | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
+        deferrable: bool = False,
+        polling_interval_seconds: int = 10,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
-
+        if deferrable and polling_interval_seconds <= 0:
+            raise ValueError("Invalid value for polling_interval_seconds. Expected value greater than 0")
         self.template_id = template_id
         self.parameters = parameters
         self.version = version
         self.project_id = project_id
         self.region = region
         self.retry = retry
         self.timeout = timeout
         self.metadata = metadata
         self.request_id = request_id
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
+        self.deferrable = deferrable
+        self.polling_interval_seconds = polling_interval_seconds
 
     def execute(self, context: Context):
         hook = DataprocHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         self.log.info("Instantiating template %s", self.template_id)
         operation = hook.instantiate_workflow_template(
             project_id=self.project_id,
             region=self.region,
@@ -1768,19 +1774,45 @@
             metadata=self.metadata,
         )
         self.workflow_id = operation.operation.name.split("/")[-1]
         DataprocLink.persist(
             context=context, task_instance=self, url=DATAPROC_WORKFLOW_LINK, resource=self.workflow_id
         )
         self.log.info("Template instantiated. Workflow Id : %s", self.workflow_id)
-        operation.result()
-        self.log.info("Workflow %s completed successfully", self.workflow_id)
+        if not self.deferrable:
+            hook.wait_for_operation(timeout=self.timeout, result_retry=self.retry, operation=operation)
+            self.log.info("Workflow %s completed successfully", self.workflow_id)
+        else:
+            self.defer(
+                trigger=DataprocWorkflowTrigger(
+                    template_name=self.template_id,
+                    name=operation.operation.name,
+                    project_id=self.project_id,
+                    region=self.region,
+                    gcp_conn_id=self.gcp_conn_id,
+                    impersonation_chain=self.impersonation_chain,
+                    polling_interval_seconds=self.polling_interval_seconds,
+                ),
+                method_name="execute_complete",
+            )
+
+    def execute_complete(self, context, event=None) -> None:
+        """
+        Callback for when the trigger fires - returns immediately.
+        Relies on trigger to throw an exception, otherwise it assumes execution was
+        successful.
+        """
+        if event["status"] == "failed" or event["status"] == "error":
+            self.log.exception("Unexpected error in the operation.")
+            raise AirflowException(event["message"])
 
+        self.log.info("Workflow %s completed successfully", event["operation_name"])
 
-class DataprocInstantiateInlineWorkflowTemplateOperator(BaseOperator):
+
+class DataprocInstantiateInlineWorkflowTemplateOperator(GoogleCloudBaseOperator):
     """
     Instantiate a WorkflowTemplate Inline on Google Cloud Dataproc. The operator will
     wait until the WorkflowTemplate is finished executing.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:DataprocInstantiateInlineWorkflowTemplateOperator`
@@ -1864,15 +1896,15 @@
             context=context, task_instance=self, url=DATAPROC_WORKFLOW_LINK, resource=self.workflow_id
         )
         self.log.info("Template instantiated. Workflow Id : %s", self.workflow_id)
         operation.result()
         self.log.info("Workflow %s completed successfully", self.workflow_id)
 
 
-class DataprocSubmitJobOperator(BaseOperator):
+class DataprocSubmitJobOperator(GoogleCloudBaseOperator):
     """
     Submits a job to a cluster.
 
     :param project_id: Optional. The ID of the Google Cloud project that the job belongs to.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param job: Required. The job resource.
         If a dict is provided, it must be of the same form as the protobuf message
@@ -2005,15 +2037,15 @@
         return job_id
 
     def on_kill(self):
         if self.job_id and self.cancel_on_kill:
             self.hook.cancel_job(job_id=self.job_id, project_id=self.project_id, region=self.region)
 
 
-class DataprocUpdateClusterOperator(BaseOperator):
+class DataprocUpdateClusterOperator(GoogleCloudBaseOperator):
     """
     Updates a cluster in a project.
 
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param project_id: Optional. The ID of the Google Cloud project the cluster belongs to.
     :param cluster_name: Required. The cluster name.
     :param cluster: Required. The changes to the cluster.
@@ -2144,15 +2176,15 @@
         cluster_name = event["cluster_name"]
 
         if cluster_state == ClusterStatus.State.ERROR:
             raise AirflowException(f"Cluster is in ERROR state:\n{cluster_name}")
         self.log.info("%s completed successfully.", self.task_id)
 
 
-class DataprocCreateBatchOperator(BaseOperator):
+class DataprocCreateBatchOperator(GoogleCloudBaseOperator):
     """
     Creates a batch workload.
 
     :param project_id: Optional. The ID of the Google Cloud project that the cluster belongs to. (templated)
     :param region: Required. The Cloud Dataproc region in which to handle the request. (templated)
     :param batch: Required. The batch to create. (templated)
     :param batch_id: Optional. The ID to use for the batch, which will become the final component
@@ -2229,15 +2261,23 @@
         self.operation: operation.Operation | None = None
         self.asynchronous = asynchronous
         self.deferrable = deferrable
         self.polling_interval_seconds = polling_interval_seconds
 
     def execute(self, context: Context):
         hook = DataprocHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
-        self.log.info("Creating batch")
+        # batch_id might not be set and will be generated
+        if self.batch_id:
+            link = DATAPROC_BATCH_LINK.format(
+                region=self.region, project_id=self.project_id, resource=self.batch_id
+            )
+            self.log.info("Creating batch %s", self.batch_id)
+            self.log.info("Once started, the batch job will be available at %s", link)
+        else:
+            self.log.info("Starting batch job. The batch ID will be generated since it was not provided.")
         if self.region is None:
             raise AirflowException("Region should be set here")
         try:
             self.operation = hook.create_batch(
                 region=self.region,
                 project_id=self.project_id,
                 batch=self.batch,
@@ -2271,40 +2311,45 @@
                         polling_interval_seconds=self.polling_interval_seconds,
                     ),
                     method_name="execute_complete",
                 )
 
         except AlreadyExists:
             self.log.info("Batch with given id already exists")
-            if self.batch_id is None:
-                raise AirflowException("Batch Id should be set here")
-            result = hook.get_batch(
-                batch_id=self.batch_id,
-                region=self.region,
-                project_id=self.project_id,
-                retry=self.retry,
-                timeout=self.timeout,
-                metadata=self.metadata,
-            )
-            # The existing batch may be a number of states other than 'SUCCEEDED'
-            if result.state != Batch.State.SUCCEEDED:
-                if result.state == Batch.State.FAILED or result.state == Batch.State.CANCELLED:
-                    raise AirflowException(
-                        f"Existing Batch {self.batch_id} failed or cancelled. "
-                        f"Error: {result.state_message}"
-                    )
-                else:
-                    # Batch state is either: RUNNING, PENDING, CANCELLING, or UNSPECIFIED
-                    self.log.info(
-                        f"Batch {self.batch_id} is in state {result.state.name}."
-                        "Waiting for state change..."
-                    )
-                    result = hook.wait_for_operation(timeout=self.timeout, operation=result)
-
+            # This is only likely to happen if batch_id was provided
+            # Could be running if Airflow was restarted after task started
+            # poll until a final state is reached
+            if self.batch_id:
+                self.log.info("Attaching to the job (%s) if it is still running.", self.batch_id)
+                result = hook.wait_for_batch(
+                    batch_id=self.batch_id,
+                    region=self.region,
+                    project_id=self.project_id,
+                    retry=self.retry,
+                    timeout=self.timeout,
+                    metadata=self.metadata,
+                    wait_check_interval=self.polling_interval_seconds,
+                )
+        # It is possible we don't have a result in the case where batch_id was not provide, one was generated
+        # by chance, AlreadyExists was caught, but we can't reattach because we don't have the generated id
+        if result is None:
+            raise AirflowException("The job could not be reattached because the id was generated.")
+
+        # The existing batch may be a number of states other than 'SUCCEEDED'\
+        # wait_for_operation doesn't fail if the job is cancelled, so we will check for it here which also
+        # finds a cancelling|canceled|unspecified job from wait_for_batch
         batch_id = self.batch_id or result.name.split("/")[-1]
+        link = DATAPROC_BATCH_LINK.format(region=self.region, project_id=self.project_id, resource=batch_id)
+        if result.state == Batch.State.FAILED:
+            raise AirflowException(f"Batch job {batch_id} failed.  Driver Logs: {link}")
+        if result.state in (Batch.State.CANCELLED, Batch.State.CANCELLING):
+            raise AirflowException(f"Batch job {batch_id} was cancelled. Driver logs: {link}")
+        if result.state == Batch.State.STATE_UNSPECIFIED:
+            raise AirflowException(f"Batch job {batch_id} unspecified. Driver logs: {link}")
+        self.log.info("Batch job %s completed. Driver logs: %s", batch_id, link)
         DataprocLink.persist(context=context, task_instance=self, url=DATAPROC_BATCH_LINK, resource=batch_id)
         return Batch.to_dict(result)
 
     def execute_complete(self, context, event=None) -> None:
         """
         Callback for when the trigger fires - returns immediately.
         Relies on trigger to throw an exception, otherwise it assumes execution was
@@ -2322,15 +2367,15 @@
         self.log.info("%s completed successfully.", self.task_id)
 
     def on_kill(self):
         if self.operation:
             self.operation.cancel()
 
 
-class DataprocDeleteBatchOperator(BaseOperator):
+class DataprocDeleteBatchOperator(GoogleCloudBaseOperator):
     """
     Deletes the batch workload resource.
 
     :param batch_id: Required. The ID to use for the batch, which will become the final component
         of the batch's resource name.
         This value must be 4-63 characters. Valid characters are /[a-z][0-9]-/.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
@@ -2386,15 +2431,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         self.log.info("Batch deleted.")
 
 
-class DataprocGetBatchOperator(BaseOperator):
+class DataprocGetBatchOperator(GoogleCloudBaseOperator):
     """
     Gets the batch workload resource representation.
 
     :param batch_id: Required. The ID to use for the batch, which will become the final component
         of the batch's resource name.
         This value must be 4-63 characters. Valid characters are /[a-z][0-9]-/.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
@@ -2454,15 +2499,15 @@
         )
         DataprocLink.persist(
             context=context, task_instance=self, url=DATAPROC_BATCH_LINK, resource=self.batch_id
         )
         return Batch.to_dict(batch)
 
 
-class DataprocListBatchesOperator(BaseOperator):
+class DataprocListBatchesOperator(GoogleCloudBaseOperator):
     """
     Lists batch workloads.
 
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param project_id: Optional. The ID of the Google Cloud project that the cluster belongs to.
     :param page_size: Optional. The maximum number of batches to return in each response. The service may
         return fewer than this value. The default page size is 20; the maximum page size is 1000.
@@ -2524,15 +2569,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         DataprocListLink.persist(context=context, task_instance=self, url=DATAPROC_BATCHES_LINK)
         return [Batch.to_dict(result) for result in results]
 
 
-class DataprocCancelOperationOperator(BaseOperator):
+class DataprocCancelOperationOperator(GoogleCloudBaseOperator):
     """
     Cancel the batch workload resource.
 
     :param operation_name: Required. The name of the operation resource to be cancelled.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param project_id: Optional. The ID of the Google Cloud project that the cluster belongs to.
     :param retry: A retry object used to retry requests. If ``None`` is specified, requests will not be
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dataproc_metastore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dataproc_metastore.py`

 * *Files 1% similar despite different names*

```diff
@@ -29,14 +29,15 @@
 from google.protobuf.field_mask_pb2 import FieldMask
 from googleapiclient.errors import HttpError
 
 from airflow import AirflowException
 from airflow.models import BaseOperator, BaseOperatorLink
 from airflow.models.xcom import XCom
 from airflow.providers.google.cloud.hooks.dataproc_metastore import DataprocMetastoreHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.common.links.storage import StorageLink
 
 if TYPE_CHECKING:
     from airflow.models.taskinstance import TaskInstanceKey
     from airflow.utils.context import Context
 
 
@@ -139,15 +140,15 @@
                 resource=conf["resource"],
             )
             if conf
             else ""
         )
 
 
-class DataprocMetastoreCreateBackupOperator(BaseOperator):
+class DataprocMetastoreCreateBackupOperator(GoogleCloudBaseOperator):
     """
     Creates a new backup in a given project and location.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param service_id:  Required. The ID of the metastore service, which is used as the final component of
         the metastore service's name. This value must be between 2 and 63 characters long inclusive, begin
@@ -254,15 +255,15 @@
             )
         DataprocMetastoreDetailedLink.persist(
             context=context, task_instance=self, url=METASTORE_BACKUP_LINK, resource=self.backup_id
         )
         return Backup.to_dict(backup)
 
 
-class DataprocMetastoreCreateMetadataImportOperator(BaseOperator):
+class DataprocMetastoreCreateMetadataImportOperator(GoogleCloudBaseOperator):
     """
     Creates a new MetadataImport in a given project and location.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param service_id:  Required. The ID of the metastore service, which is used as the final component of
         the metastore service's name. This value must be between 2 and 63 characters long inclusive, begin
@@ -355,15 +356,15 @@
 
         DataprocMetastoreDetailedLink.persist(
             context=context, task_instance=self, url=METASTORE_IMPORT_LINK, resource=self.metadata_import_id
         )
         return MetadataImport.to_dict(metadata_import)
 
 
-class DataprocMetastoreCreateServiceOperator(BaseOperator):
+class DataprocMetastoreCreateServiceOperator(GoogleCloudBaseOperator):
     """
     Creates a metastore service in a project and location.
 
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param service:  Required. The Metastore service to create. The ``name`` field is ignored. The ID of
         the created metastore service must be provided in the request's ``service_id`` field.
@@ -457,15 +458,15 @@
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
         DataprocMetastoreLink.persist(context=context, task_instance=self, url=METASTORE_SERVICE_LINK)
         return Service.to_dict(service)
 
 
-class DataprocMetastoreDeleteBackupOperator(BaseOperator):
+class DataprocMetastoreDeleteBackupOperator(GoogleCloudBaseOperator):
     """
     Deletes a single backup.
 
     :param project_id: Required. The ID of the Google Cloud project that the backup belongs to.
     :param region: Required. The ID of the Google Cloud region that the backup belongs to.
     :param service_id: Required. The ID of the metastore service, which is used as the final component of
         the metastore service's name. This value must be between 2 and 63 characters long inclusive, begin
@@ -542,15 +543,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         hook.wait_for_operation(self.timeout, operation)
         self.log.info("Backup %s deleted successfully", self.project_id)
 
 
-class DataprocMetastoreDeleteServiceOperator(BaseOperator):
+class DataprocMetastoreDeleteServiceOperator(GoogleCloudBaseOperator):
     """
     Deletes a single service.
 
     :param request:  The request object. Request message for
         [DataprocMetastore.DeleteService][google.cloud.metastore.v1.DataprocMetastore.DeleteService].
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param retry: Designation of what errors, if any, should be retried.
@@ -600,15 +601,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         hook.wait_for_operation(self.timeout, operation)
         self.log.info("Service %s deleted successfully", self.project_id)
 
 
-class DataprocMetastoreExportMetadataOperator(BaseOperator):
+class DataprocMetastoreExportMetadataOperator(GoogleCloudBaseOperator):
     """
     Exports metadata from a service.
 
     :param destination_gcs_folder: A Cloud Storage URI of a folder, in the format
         ``gs://<bucket_name>/<path_inside_bucket>``. A sub-folder
         ``<export_folder>`` containing exported files will be
         created below it.
@@ -718,15 +719,15 @@
                 return metadata_export
             if metadata_export.state == MetadataExport.State.FAILED:
                 raise AirflowException(
                     f"Exporting metadata from Dataproc Metastore {metadata_export.name} FAILED"
                 )
 
 
-class DataprocMetastoreGetServiceOperator(BaseOperator):
+class DataprocMetastoreGetServiceOperator(GoogleCloudBaseOperator):
     """
     Gets the details of a single service.
 
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param service_id:  Required. The ID of the metastore service, which is used as the final component of
         the metastore service's name. This value must be between 2 and 63 characters long inclusive, begin
@@ -791,15 +792,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         DataprocMetastoreLink.persist(context=context, task_instance=self, url=METASTORE_SERVICE_LINK)
         return Service.to_dict(result)
 
 
-class DataprocMetastoreListBackupsOperator(BaseOperator):
+class DataprocMetastoreListBackupsOperator(GoogleCloudBaseOperator):
     """
     Lists backups in a service.
 
     :param project_id: Required. The ID of the Google Cloud project that the backup belongs to.
     :param region: Required. The ID of the Google Cloud region that the backup belongs to.
     :param service_id: Required. The ID of the metastore service, which is used as the final component of
         the metastore service's name. This value must be between 2 and 63 characters long inclusive, begin
@@ -876,15 +877,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         DataprocMetastoreLink.persist(context=context, task_instance=self, url=METASTORE_BACKUPS_LINK)
         return [Backup.to_dict(backup) for backup in backups]
 
 
-class DataprocMetastoreRestoreServiceOperator(BaseOperator):
+class DataprocMetastoreRestoreServiceOperator(GoogleCloudBaseOperator):
     """
     Restores a service from a backup.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param service_id: Required. The ID of the metastore service, which is used as the final component of
         the metastore service's name. This value must be between 2 and 63 characters long inclusive, begin
@@ -1004,15 +1005,15 @@
             restore_service: Restore = activities.restores[0]
             if restore_service.state == Restore.State.SUCCEEDED:
                 return restore_service
             if restore_service.state == Restore.State.FAILED:
                 raise AirflowException("Restoring service FAILED")
 
 
-class DataprocMetastoreUpdateServiceOperator(BaseOperator):
+class DataprocMetastoreUpdateServiceOperator(GoogleCloudBaseOperator):
     """
     Updates the parameters of a single service.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param service_id:  Required. The ID of the metastore service, which is used as the final component of
         the metastore service's name. This value must be between 2 and 63 characters long inclusive, begin
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/datastore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/datastore.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,28 +18,28 @@
 """This module contains Google Datastore operators."""
 from __future__ import annotations
 
 import warnings
 from typing import TYPE_CHECKING, Any, Sequence
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.datastore import DatastoreHook
 from airflow.providers.google.cloud.hooks.gcs import GCSHook
 from airflow.providers.google.cloud.links.datastore import (
     CloudDatastoreEntitiesLink,
     CloudDatastoreImportExportLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.common.links.storage import StorageLink
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudDatastoreExportEntitiesOperator(BaseOperator):
+class CloudDatastoreExportEntitiesOperator(GoogleCloudBaseOperator):
     """
     Export entities from Google Cloud Datastore to Cloud Storage
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreExportEntitiesOperator`
 
@@ -147,15 +147,15 @@
             task_instance=self,
             uri=f"{self.bucket}/{result['response']['outputUrl'].split('/')[3]}",
             project_id=self.project_id or ds_hook.project_id,
         )
         return result
 
 
-class CloudDatastoreImportEntitiesOperator(BaseOperator):
+class CloudDatastoreImportEntitiesOperator(GoogleCloudBaseOperator):
     """
     Import entities from Cloud Storage to Google Cloud Datastore
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreImportEntitiesOperator`
 
@@ -250,15 +250,15 @@
         if state != "SUCCESSFUL":
             raise AirflowException(f"Operation failed: result={result}")
 
         CloudDatastoreImportExportLink.persist(context=context, task_instance=self)
         return result
 
 
-class CloudDatastoreAllocateIdsOperator(BaseOperator):
+class CloudDatastoreAllocateIdsOperator(GoogleCloudBaseOperator):
     """
     Allocate IDs for incomplete keys. Return list of keys.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreAllocateIdsOperator`
 
@@ -318,15 +318,15 @@
             partial_keys=self.partial_keys,
             project_id=self.project_id,
         )
         CloudDatastoreEntitiesLink.persist(context=context, task_instance=self)
         return keys
 
 
-class CloudDatastoreBeginTransactionOperator(BaseOperator):
+class CloudDatastoreBeginTransactionOperator(GoogleCloudBaseOperator):
     """
     Begins a new transaction. Returns a transaction handle.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreBeginTransactionOperator`
 
@@ -384,15 +384,15 @@
         handle = hook.begin_transaction(
             transaction_options=self.transaction_options,
             project_id=self.project_id,
         )
         return handle
 
 
-class CloudDatastoreCommitOperator(BaseOperator):
+class CloudDatastoreCommitOperator(GoogleCloudBaseOperator):
     """
     Commit a transaction, optionally creating, deleting or modifying some entities.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreCommitOperator`
 
@@ -452,15 +452,15 @@
             body=self.body,
             project_id=self.project_id,
         )
         CloudDatastoreEntitiesLink.persist(context=context, task_instance=self)
         return response
 
 
-class CloudDatastoreRollbackOperator(BaseOperator):
+class CloudDatastoreRollbackOperator(GoogleCloudBaseOperator):
     """
     Roll back a transaction.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreRollbackOperator`
 
@@ -517,15 +517,15 @@
         )
         hook.rollback(
             transaction=self.transaction,
             project_id=self.project_id,
         )
 
 
-class CloudDatastoreRunQueryOperator(BaseOperator):
+class CloudDatastoreRunQueryOperator(GoogleCloudBaseOperator):
     """
     Run a query for entities. Returns the batch of query results.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreRunQueryOperator`
 
@@ -583,15 +583,15 @@
         response = hook.run_query(
             body=self.body,
             project_id=self.project_id,
         )
         return response
 
 
-class CloudDatastoreGetOperationOperator(BaseOperator):
+class CloudDatastoreGetOperationOperator(GoogleCloudBaseOperator):
     """
     Gets the latest state of a long-running operation.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreGetOperationOperator`
 
@@ -643,15 +643,15 @@
             gcp_conn_id=self.gcp_conn_id,
             impersonation_chain=self.impersonation_chain,
         )
         op = hook.get_operation(name=self.name)
         return op
 
 
-class CloudDatastoreDeleteOperationOperator(BaseOperator):
+class CloudDatastoreDeleteOperationOperator(GoogleCloudBaseOperator):
     """
     Deletes the long-running operation.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDatastoreDeleteOperationOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/dlp.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/dlp.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,47 +27,53 @@
 from google.api_core.exceptions import AlreadyExists, InvalidArgument, NotFound
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.dlp_v2.types import (
     ByteContentItem,
     ContentItem,
     DeidentifyConfig,
+    DeidentifyContentResponse,
     DeidentifyTemplate,
-    FieldMask,
+    DlpJob,
     InspectConfig,
+    InspectContentResponse,
     InspectJobConfig,
     InspectTemplate,
     JobTrigger,
+    ListInfoTypesResponse,
     RedactImageRequest,
+    RedactImageResponse,
+    ReidentifyContentResponse,
     RiskAnalysisJobConfig,
+    StoredInfoType,
     StoredInfoTypeConfig,
 )
-from google.protobuf.json_format import MessageToDict
+from google.protobuf.field_mask_pb2 import FieldMask
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.dlp import CloudDLPHook
 from airflow.providers.google.cloud.links.data_loss_prevention import (
     CloudDLPDeidentifyTemplateDetailsLink,
     CloudDLPDeidentifyTemplatesListLink,
     CloudDLPInfoTypeDetailsLink,
     CloudDLPInfoTypesListLink,
     CloudDLPInspectTemplateDetailsLink,
     CloudDLPInspectTemplatesListLink,
     CloudDLPJobDetailsLink,
     CloudDLPJobsListLink,
     CloudDLPJobTriggerDetailsLink,
     CloudDLPJobTriggersListLink,
     CloudDLPPossibleInfoTypesListLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudDLPCancelDLPJobOperator(BaseOperator):
+class CloudDLPCancelDLPJobOperator(GoogleCloudBaseOperator):
     """
     Starts asynchronous cancellation on a long-running DlpJob.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPCancelDLPJobOperator`
 
@@ -140,15 +146,15 @@
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 job_name=self.dlp_job_id,
             )
 
 
-class CloudDLPCreateDeidentifyTemplateOperator(BaseOperator):
+class CloudDLPCreateDeidentifyTemplateOperator(GoogleCloudBaseOperator):
     """
     Creates a DeidentifyTemplate for re-using frequently used configuration for
     de-identifying content, images, and storage.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPCreateDeidentifyTemplateOperator`
@@ -235,30 +241,30 @@
                 organization_id=self.organization_id,
                 project_id=self.project_id,
                 template_id=self.template_id,
                 retry=self.retry,
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
-        result = MessageToDict(template)
+        result = DeidentifyTemplate.to_dict(template)
 
         project_id = self.project_id or hook.project_id
         template_id = self.template_id or result["name"].split("/")[-1] if result["name"] else None
         if project_id and template_id:
             CloudDLPDeidentifyTemplateDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 template_name=template_id,
             )
 
         return result
 
 
-class CloudDLPCreateDLPJobOperator(BaseOperator):
+class CloudDLPCreateDLPJobOperator(GoogleCloudBaseOperator):
     """
     Creates a new job to inspect storage or calculate risk metrics.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPCreateDLPJobOperator`
 
@@ -348,29 +354,29 @@
                 project_id=self.project_id,
                 dlp_job_id=self.job_id,
                 retry=self.retry,
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
 
-        result = MessageToDict(job)
+        result = DlpJob.to_dict(job)
 
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudDLPJobDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 job_name=result["name"].split("/")[-1] if result["name"] else None,
             )
 
         return result
 
 
-class CloudDLPCreateInspectTemplateOperator(BaseOperator):
+class CloudDLPCreateInspectTemplateOperator(GoogleCloudBaseOperator):
     """
     Creates an InspectTemplate for re-using frequently used configuration for
     inspecting content, images, and storage.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPCreateInspectTemplateOperator`
@@ -458,30 +464,30 @@
                 project_id=self.project_id,
                 template_id=self.template_id,
                 retry=self.retry,
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
 
-        result = MessageToDict(template)
+        result = InspectTemplate.to_dict(template)
 
         template_id = self.template_id or result["name"].split("/")[-1] if result["name"] else None
         project_id = self.project_id or hook.project_id
         if project_id and template_id:
             CloudDLPInspectTemplateDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 template_name=template_id,
             )
 
         return result
 
 
-class CloudDLPCreateJobTriggerOperator(BaseOperator):
+class CloudDLPCreateJobTriggerOperator(GoogleCloudBaseOperator):
     """
     Creates a job trigger to run DLP actions such as scanning storage for sensitive
     information on a set schedule.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPCreateJobTriggerOperator`
@@ -564,30 +570,30 @@
                 project_id=self.project_id,
                 job_trigger_id=self.trigger_id,
                 retry=self.retry,
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
 
-        result = MessageToDict(trigger)
+        result = JobTrigger.to_dict(trigger)
 
         project_id = self.project_id or hook.project_id
         trigger_name = result["name"].split("/")[-1] if result["name"] else None
         if project_id:
             CloudDLPJobTriggerDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 trigger_name=trigger_name,
             )
 
         return result
 
 
-class CloudDLPCreateStoredInfoTypeOperator(BaseOperator):
+class CloudDLPCreateStoredInfoTypeOperator(GoogleCloudBaseOperator):
     """
     Creates a pre-built stored infoType to be used for inspection.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPCreateStoredInfoTypeOperator`
 
@@ -676,15 +682,15 @@
                 project_id=self.project_id,
                 stored_info_type_id=self.stored_info_type_id,
                 retry=self.retry,
                 timeout=self.timeout,
                 metadata=self.metadata,
             )
 
-        result = MessageToDict(info)
+        result = StoredInfoType.to_dict(info)
 
         project_id = self.project_id or hook.project_id
         stored_info_type_id = (
             self.stored_info_type_id or result["name"].split("/")[-1] if result["name"] else None
         )
         if project_id and stored_info_type_id:
             CloudDLPInfoTypeDetailsLink.persist(
@@ -693,15 +699,15 @@
                 project_id=project_id,
                 info_type_name=stored_info_type_id,
             )
 
         return result
 
 
-class CloudDLPDeidentifyContentOperator(BaseOperator):
+class CloudDLPDeidentifyContentOperator(GoogleCloudBaseOperator):
     """
     De-identifies potentially sensitive info from a ContentItem. This method has limits
     on input size and output size.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPDeidentifyContentOperator`
@@ -790,18 +796,18 @@
             item=self.item,
             inspect_template_name=self.inspect_template_name,
             deidentify_template_name=self.deidentify_template_name,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
-        return MessageToDict(response)
+        return DeidentifyContentResponse.to_dict(response)
 
 
-class CloudDLPDeleteDeidentifyTemplateOperator(BaseOperator):
+class CloudDLPDeleteDeidentifyTemplateOperator(GoogleCloudBaseOperator):
     """
     Deletes a DeidentifyTemplate.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPDeleteDeidentifyTemplateOperator`
 
@@ -881,15 +887,15 @@
                     task_instance=self,
                     project_id=project_id,
                 )
         except NotFound:
             self.log.error("Template %s not found.", self.template_id)
 
 
-class CloudDLPDeleteDLPJobOperator(BaseOperator):
+class CloudDLPDeleteDLPJobOperator(GoogleCloudBaseOperator):
     """
     Deletes a long-running DlpJob. This method indicates that the client is no longer
     interested in the DlpJob result. The job will be cancelled if possible.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPDeleteDLPJobOperator`
@@ -966,15 +972,15 @@
                     project_id=project_id,
                 )
 
         except NotFound:
             self.log.error("Job %s id not found.", self.dlp_job_id)
 
 
-class CloudDLPDeleteInspectTemplateOperator(BaseOperator):
+class CloudDLPDeleteInspectTemplateOperator(GoogleCloudBaseOperator):
     """
     Deletes an InspectTemplate.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPDeleteInspectTemplateOperator`
 
@@ -1056,15 +1062,15 @@
                     project_id=project_id,
                 )
 
         except NotFound:
             self.log.error("Template %s not found", self.template_id)
 
 
-class CloudDLPDeleteJobTriggerOperator(BaseOperator):
+class CloudDLPDeleteJobTriggerOperator(GoogleCloudBaseOperator):
     """
     Deletes a job trigger.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPDeleteJobTriggerOperator`
 
@@ -1140,15 +1146,15 @@
                     project_id=project_id,
                 )
 
         except NotFound:
             self.log.error("Trigger %s not found", self.job_trigger_id)
 
 
-class CloudDLPDeleteStoredInfoTypeOperator(BaseOperator):
+class CloudDLPDeleteStoredInfoTypeOperator(GoogleCloudBaseOperator):
     """
     Deletes a stored infoType.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPDeleteStoredInfoTypeOperator`
 
@@ -1229,15 +1235,15 @@
             CloudDLPInfoTypesListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
             )
 
 
-class CloudDLPGetDeidentifyTemplateOperator(BaseOperator):
+class CloudDLPGetDeidentifyTemplateOperator(GoogleCloudBaseOperator):
     """
     Gets a DeidentifyTemplate.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPGetDeidentifyTemplateOperator`
 
@@ -1313,18 +1319,18 @@
 
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudDLPDeidentifyTemplateDetailsLink.persist(
                 context=context, task_instance=self, project_id=project_id, template_name=self.template_id
             )
 
-        return MessageToDict(template)
+        return DeidentifyTemplate.to_dict(template)
 
 
-class CloudDLPGetDLPJobOperator(BaseOperator):
+class CloudDLPGetDLPJobOperator(GoogleCloudBaseOperator):
     """
     Gets the latest state of a long-running DlpJob.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPGetDLPJobOperator`
 
@@ -1397,18 +1403,18 @@
             CloudDLPJobDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 job_name=self.dlp_job_id,
             )
 
-        return MessageToDict(job)
+        return DlpJob.to_dict(job)
 
 
-class CloudDLPGetInspectTemplateOperator(BaseOperator):
+class CloudDLPGetInspectTemplateOperator(GoogleCloudBaseOperator):
     """
     Gets an InspectTemplate.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPGetInspectTemplateOperator`
 
@@ -1487,18 +1493,18 @@
             CloudDLPInspectTemplateDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 template_name=self.template_id,
             )
 
-        return MessageToDict(template)
+        return InspectTemplate.to_dict(template)
 
 
-class CloudDLPGetDLPJobTriggerOperator(BaseOperator):
+class CloudDLPGetDLPJobTriggerOperator(GoogleCloudBaseOperator):
     """
     Gets a job trigger.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPGetDLPJobTriggerOperator`
 
@@ -1571,18 +1577,18 @@
             CloudDLPJobTriggerDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 trigger_name=self.job_trigger_id,
             )
 
-        return MessageToDict(trigger)
+        return JobTrigger.to_dict(trigger)
 
 
-class CloudDLPGetStoredInfoTypeOperator(BaseOperator):
+class CloudDLPGetStoredInfoTypeOperator(GoogleCloudBaseOperator):
     """
     Gets a stored infoType.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPGetStoredInfoTypeOperator`
 
@@ -1661,18 +1667,18 @@
             CloudDLPInfoTypeDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 info_type_name=self.stored_info_type_id,
             )
 
-        return MessageToDict(info)
+        return StoredInfoType.to_dict(info)
 
 
-class CloudDLPInspectContentOperator(BaseOperator):
+class CloudDLPInspectContentOperator(GoogleCloudBaseOperator):
     """
     Finds potentially sensitive info in content. This method has limits on
     input size, processing time, and output size.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPInspectContentOperator`
@@ -1747,18 +1753,18 @@
             inspect_config=self.inspect_config,
             item=self.item,
             inspect_template_name=self.inspect_template_name,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
-        return MessageToDict(response)
+        return InspectContentResponse.to_dict(response)
 
 
-class CloudDLPListDeidentifyTemplatesOperator(BaseOperator):
+class CloudDLPListDeidentifyTemplatesOperator(GoogleCloudBaseOperator):
     """
     Lists DeidentifyTemplates.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPListDeidentifyTemplatesOperator`
 
@@ -1832,28 +1838,27 @@
             project_id=self.project_id,
             page_size=self.page_size,
             order_by=self.order_by,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
-        # the MessageToDict does not have the right type defined as possible to pass in constructor
 
         project_id = self.project_id or hook.project_id
         if project_id:
             CloudDLPDeidentifyTemplatesListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
             )
 
-        return [MessageToDict(template) for template in templates]  # type: ignore[arg-type]
+        return [DeidentifyTemplate.to_dict(template) for template in templates]  # type: ignore[arg-type]
 
 
-class CloudDLPListDLPJobsOperator(BaseOperator):
+class CloudDLPListDLPJobsOperator(GoogleCloudBaseOperator):
     """
     Lists DlpJobs that match the specified filter in the request.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPListDLPJobsOperator`
 
@@ -1938,19 +1943,19 @@
         if project_id:
             CloudDLPJobsListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
             )
 
-        # the MessageToDict does not have the right type defined as possible to pass in constructor
-        return [MessageToDict(job) for job in jobs]  # type: ignore[arg-type]
+        # the DlpJob.to_dict does not have the right type defined as possible to pass in constructor
+        return [DlpJob.to_dict(job) for job in jobs]  # type: ignore[arg-type]
 
 
-class CloudDLPListInfoTypesOperator(BaseOperator):
+class CloudDLPListInfoTypesOperator(GoogleCloudBaseOperator):
     """
     Returns a list of the sensitive information types that the DLP API supports.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPListInfoTypesOperator`
 
@@ -2023,18 +2028,18 @@
         if project_id:
             CloudDLPPossibleInfoTypesListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
             )
 
-        return MessageToDict(response)
+        return ListInfoTypesResponse.to_dict(response)
 
 
-class CloudDLPListInspectTemplatesOperator(BaseOperator):
+class CloudDLPListInspectTemplatesOperator(GoogleCloudBaseOperator):
     """
     Lists InspectTemplates.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPListInspectTemplatesOperator`
 
@@ -2117,18 +2122,18 @@
         if project_id:
             CloudDLPInspectTemplatesListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
             )
 
-        return [MessageToDict(t) for t in templates]
+        return [InspectTemplate.to_dict(t) for t in templates]
 
 
-class CloudDLPListJobTriggersOperator(BaseOperator):
+class CloudDLPListJobTriggersOperator(GoogleCloudBaseOperator):
     """
     Lists job triggers.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPListJobTriggersOperator`
 
@@ -2209,18 +2214,18 @@
         if project_id:
             CloudDLPJobTriggersListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
             )
 
-        return [MessageToDict(j) for j in jobs]
+        return [JobTrigger.to_dict(j) for j in jobs]
 
 
-class CloudDLPListStoredInfoTypesOperator(BaseOperator):
+class CloudDLPListStoredInfoTypesOperator(GoogleCloudBaseOperator):
     """
     Lists stored infoTypes.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPListStoredInfoTypesOperator`
 
@@ -2303,18 +2308,18 @@
         if project_id:
             CloudDLPInfoTypesListLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
             )
 
-        return [MessageToDict(i) for i in infos]
+        return [StoredInfoType.to_dict(i) for i in infos]
 
 
-class CloudDLPRedactImageOperator(BaseOperator):
+class CloudDLPRedactImageOperator(GoogleCloudBaseOperator):
     """
     Redacts potentially sensitive info from an image. This method has limits on
     input size, processing time, and output size.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPRedactImageOperator`
@@ -2395,18 +2400,18 @@
             image_redaction_configs=self.image_redaction_configs,
             include_findings=self.include_findings,
             byte_item=self.byte_item,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
-        return MessageToDict(response)
+        return RedactImageResponse.to_dict(response)
 
 
-class CloudDLPReidentifyContentOperator(BaseOperator):
+class CloudDLPReidentifyContentOperator(GoogleCloudBaseOperator):
     """
     Re-identifies content that has been de-identified.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPReidentifyContentOperator`
 
@@ -2492,18 +2497,18 @@
             item=self.item,
             inspect_template_name=self.inspect_template_name,
             reidentify_template_name=self.reidentify_template_name,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
-        return MessageToDict(response)
+        return ReidentifyContentResponse.to_dict(response)
 
 
-class CloudDLPUpdateDeidentifyTemplateOperator(BaseOperator):
+class CloudDLPUpdateDeidentifyTemplateOperator(GoogleCloudBaseOperator):
     """
     Updates the DeidentifyTemplate.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPUpdateDeidentifyTemplateOperator`
 
@@ -2592,18 +2597,18 @@
             CloudDLPDeidentifyTemplateDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 template_name=self.template_id,
             )
 
-        return MessageToDict(template)
+        return DeidentifyTemplate.to_dict(template)
 
 
-class CloudDLPUpdateInspectTemplateOperator(BaseOperator):
+class CloudDLPUpdateInspectTemplateOperator(GoogleCloudBaseOperator):
     """
     Updates the InspectTemplate.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPUpdateInspectTemplateOperator`
 
@@ -2692,18 +2697,18 @@
             CloudDLPInspectTemplateDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 template_name=self.template_id,
             )
 
-        return MessageToDict(template)
+        return InspectTemplate.to_dict(template)
 
 
-class CloudDLPUpdateJobTriggerOperator(BaseOperator):
+class CloudDLPUpdateJobTriggerOperator(GoogleCloudBaseOperator):
     """
     Updates a job trigger.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPUpdateJobTriggerOperator`
 
@@ -2742,15 +2747,15 @@
     operator_extra_links = (CloudDLPJobTriggerDetailsLink(),)
 
     def __init__(
         self,
         *,
         job_trigger_id,
         project_id: str | None = None,
-        job_trigger: JobTrigger | None = None,
+        job_trigger: dict | JobTrigger | None = None,
         update_mask: dict | FieldMask | None = None,
         retry: Retry | _MethodDefault = DEFAULT,
         timeout: float | None = None,
         metadata: Sequence[tuple[str, str]] = (),
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
         **kwargs,
@@ -2786,18 +2791,18 @@
             CloudDLPJobTriggerDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 trigger_name=self.job_trigger_id,
             )
 
-        return MessageToDict(trigger)
+        return JobTrigger.to_dict(trigger)
 
 
-class CloudDLPUpdateStoredInfoTypeOperator(BaseOperator):
+class CloudDLPUpdateStoredInfoTypeOperator(GoogleCloudBaseOperator):
     """
     Updates the stored infoType by creating a new version.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudDLPUpdateStoredInfoTypeOperator`
 
@@ -2887,8 +2892,8 @@
             CloudDLPInfoTypeDetailsLink.persist(
                 context=context,
                 task_instance=self,
                 project_id=project_id,
                 info_type_name=self.stored_info_type_id,
             )
 
-        return MessageToDict(info)
+        return StoredInfoType.to_dict(info)
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/functions.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/functions.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,20 +20,20 @@
 
 import re
 from typing import TYPE_CHECKING, Any, Sequence
 
 from googleapiclient.errors import HttpError
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.functions import CloudFunctionsHook
 from airflow.providers.google.cloud.links.cloud_functions import (
     CloudFunctionsDetailsLink,
     CloudFunctionsListLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.utils.field_validator import (
     GcpBodyFieldValidator,
     GcpFieldValidationException,
 )
 from airflow.version import version
 
 if TYPE_CHECKING:
@@ -98,15 +98,15 @@
                 ],
             ),
         ],
     ),
 ]
 
 
-class CloudFunctionDeployFunctionOperator(BaseOperator):
+class CloudFunctionDeployFunctionOperator(GoogleCloudBaseOperator):
     """
     Creates a function in Google Cloud Functions.
     If a function with this name already exists, it will be updated.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudFunctionDeployFunctionOperator`
@@ -323,15 +323,15 @@
             self.upload_function = False
 
 
 FUNCTION_NAME_PATTERN = "^projects/[^/]+/locations/[^/]+/functions/[^/]+$"
 FUNCTION_NAME_COMPILED_PATTERN = re.compile(FUNCTION_NAME_PATTERN)
 
 
-class CloudFunctionDeleteFunctionOperator(BaseOperator):
+class CloudFunctionDeleteFunctionOperator(GoogleCloudBaseOperator):
     """
     Deletes the specified function from Google Cloud Functions.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudFunctionDeleteFunctionOperator`
 
@@ -406,15 +406,15 @@
                 self.log.info("The function does not exist in this project")
                 return None
             else:
                 self.log.error("An error occurred. Exiting.")
                 raise e
 
 
-class CloudFunctionInvokeFunctionOperator(BaseOperator):
+class CloudFunctionInvokeFunctionOperator(GoogleCloudBaseOperator):
     """
     Invokes a deployed Cloud Function. To be used for testing
     purposes as very limited traffic is allowed.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudFunctionDeployFunctionOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/gcs.py`

 * *Files 0% similar despite different names*

```diff
@@ -31,21 +31,21 @@
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 from google.api_core.exceptions import Conflict
 from google.cloud.exceptions import GoogleCloudError
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.gcs import GCSHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.common.links.storage import FileDetailsLink, StorageLink
 from airflow.utils import timezone
 
 
-class GCSCreateBucketOperator(BaseOperator):
+class GCSCreateBucketOperator(GoogleCloudBaseOperator):
     """
     Creates a new bucket. Google Cloud Storage uses a flat namespace,
     so you can't create a bucket with a name that is already in use.
 
         .. seealso::
             For more information, see Bucket Naming Guidelines:
             https://cloud.google.com/storage/docs/bucketnaming.html#requirements
@@ -162,15 +162,15 @@
                 project_id=self.project_id,
                 labels=self.labels,
             )
         except Conflict:  # HTTP 409
             self.log.warning("Bucket %s already exists", self.bucket_name)
 
 
-class GCSListObjectsOperator(BaseOperator):
+class GCSListObjectsOperator(GoogleCloudBaseOperator):
     """
     List all objects from the bucket with the given string prefix and delimiter in name.
 
     This operator returns a python list with the name of objects which can be used by
     XCom in the downstream task.
 
     :param bucket: The Google Cloud Storage bucket to find the objects. (templated)
@@ -260,15 +260,15 @@
             uri=self.bucket,
             project_id=hook.project_id,
         )
 
         return hook.list(bucket_name=self.bucket, prefix=self.prefix, delimiter=self.delimiter)
 
 
-class GCSDeleteObjectsOperator(BaseOperator):
+class GCSDeleteObjectsOperator(GoogleCloudBaseOperator):
     """
     Deletes objects from a Google Cloud Storage bucket, either
     from an explicit list of object names or all objects
     matching a prefix.
 
     :param bucket_name: The GCS bucket to delete from
     :param objects: List of objects to delete. These should be the names
@@ -340,15 +340,15 @@
             objects = hook.list(bucket_name=self.bucket_name, prefix=self.prefix)
 
         self.log.info("Deleting %s objects from %s", len(objects), self.bucket_name)
         for object_name in objects:
             hook.delete(bucket_name=self.bucket_name, object_name=object_name)
 
 
-class GCSBucketCreateAclEntryOperator(BaseOperator):
+class GCSBucketCreateAclEntryOperator(GoogleCloudBaseOperator):
     """
     Creates a new ACL entry on the specified bucket.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:GCSBucketCreateAclEntryOperator`
 
@@ -413,15 +413,15 @@
             project_id=hook.project_id,
         )
         hook.insert_bucket_acl(
             bucket_name=self.bucket, entity=self.entity, role=self.role, user_project=self.user_project
         )
 
 
-class GCSObjectCreateAclEntryOperator(BaseOperator):
+class GCSObjectCreateAclEntryOperator(GoogleCloudBaseOperator):
     """
     Creates a new ACL entry on the specified object.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:GCSObjectCreateAclEntryOperator`
 
@@ -501,15 +501,15 @@
             entity=self.entity,
             role=self.role,
             generation=self.generation,
             user_project=self.user_project,
         )
 
 
-class GCSFileTransformOperator(BaseOperator):
+class GCSFileTransformOperator(GoogleCloudBaseOperator):
     """
     Copies data from a source GCS location to a temporary location on the
     local filesystem. Runs a transformation on this file as specified by
     the transformation script and uploads the output to a destination bucket.
     If the output bucket is not specified the original file will be
     overwritten.
 
@@ -607,15 +607,15 @@
             hook.upload(
                 bucket_name=self.destination_bucket,
                 object_name=self.destination_object,
                 filename=destination_file.name,
             )
 
 
-class GCSTimeSpanFileTransformOperator(BaseOperator):
+class GCSTimeSpanFileTransformOperator(GoogleCloudBaseOperator):
     """
     Determines a list of objects that were added or modified at a GCS source
     location during a specific time-span, copies them to a temporary location
     on the local file system, runs a transform on this file as specified by
     the transformation script and uploads the output to the destination bucket.
 
     .. seealso::
@@ -862,15 +862,15 @@
                     if self.upload_continue_on_fail:
                         continue
                     raise
 
             return files_uploaded
 
 
-class GCSDeleteBucketOperator(BaseOperator):
+class GCSDeleteBucketOperator(GoogleCloudBaseOperator):
     """
     Deletes bucket from a Google Cloud Storage.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:GCSDeleteBucketOperator`
 
@@ -911,15 +911,15 @@
         self.impersonation_chain = impersonation_chain
 
     def execute(self, context: Context) -> None:
         hook = GCSHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
         hook.delete_bucket(bucket_name=self.bucket_name, force=self.force)
 
 
-class GCSSynchronizeBucketsOperator(BaseOperator):
+class GCSSynchronizeBucketsOperator(GoogleCloudBaseOperator):
     """
     Synchronizes the contents of the buckets or bucket's directories in the Google Cloud Services.
 
     Parameters ``source_object`` and ``destination_object`` describe the root sync directory. If they are
     not passed, the entire bucket will be synchronized. They should point to directories.
 
     .. note::
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/kubernetes_engine.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/analytics.py`

 * *Files 15% similar despite different names*

```diff
@@ -11,422 +11,498 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an
 # "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 # KIND, either express or implied.  See the License for the
 # specific language governing permissions and limitations
 # under the License.
-"""This module contains Google Kubernetes Engine operators."""
+"""This module contains Google Analytics 360 operators."""
 from __future__ import annotations
 
-import os
-import tempfile
-import warnings
-from contextlib import contextmanager
-from typing import TYPE_CHECKING, Generator, Sequence
+import csv
+from tempfile import NamedTemporaryFile
+from typing import TYPE_CHECKING, Any, Sequence
 
-from google.cloud.container_v1.types import Cluster
-
-from airflow.exceptions import AirflowException
 from airflow.models import BaseOperator
-from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import KubernetesPodOperator
-from airflow.providers.google.cloud.hooks.kubernetes_engine import GKEHook
-from airflow.providers.google.cloud.links.kubernetes_engine import (
-    KubernetesEngineClusterLink,
-    KubernetesEnginePodLink,
-)
-from airflow.providers.google.common.hooks.base_google import GoogleBaseHook
-from airflow.utils.process_utils import execute_in_subprocess, patch_environ
+from airflow.providers.google.cloud.hooks.gcs import GCSHook
+from airflow.providers.google.marketing_platform.hooks.analytics import GoogleAnalyticsHook
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class GKEDeleteClusterOperator(BaseOperator):
+class GoogleAnalyticsListAccountsOperator(BaseOperator):
     """
-    Deletes the cluster, including the Kubernetes endpoint and all worker nodes.
-
-    To delete a certain cluster, you must specify the ``project_id``, the ``name``
-    of the cluster, the ``location`` that the cluster is in, and the ``task_id``.
-
-    **Operator Creation**: ::
-
-        operator = GKEClusterDeleteOperator(
-                    task_id='cluster_delete',
-                    project_id='my-project',
-                    location='cluster-location'
-                    name='cluster-name')
+    Lists all accounts to which the user has access.
 
     .. seealso::
-        For more detail about deleting clusters have a look at the reference:
-        https://google-cloud-python.readthedocs.io/en/latest/container/gapic/v1/api.html#google.cloud.container_v1.ClusterManagerClient.delete_cluster
+        Check official API docs:
+        https://developers.google.com/analytics/devguides/config/mgmt/v3/mgmtReference/management/accounts/list
+        and for python client
+        http://googleapis.github.io/google-api-python-client/docs/dyn/analytics_v3.management.accounts.html#list
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
-        :ref:`howto/operator:GKEDeleteClusterOperator`
+        :ref:`howto/operator:GoogleAnalyticsListAccountsOperator`
 
-    :param project_id: The Google Developers Console [project ID or project number]
-    :param name: The name of the resource to delete, in this case cluster name
-    :param location: The name of the Google Kubernetes Engine zone or region in which the cluster
-        resides.
-    :param gcp_conn_id: The connection ID to use connecting to Google Cloud.
-    :param api_version: The api version to use
+    :param api_version: The version of the api that will be requested for example 'v3'.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
     :param impersonation_chain: Optional service account to impersonate using short-term
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     """
 
     template_fields: Sequence[str] = (
-        "project_id",
-        "gcp_conn_id",
-        "name",
-        "location",
         "api_version",
+        "gcp_conn_id",
         "impersonation_chain",
     )
 
     def __init__(
         self,
         *,
-        name: str,
-        location: str,
-        project_id: str | None = None,
+        api_version: str = "v3",
         gcp_conn_id: str = "google_cloud_default",
-        api_version: str = "v2",
         impersonation_chain: str | Sequence[str] | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
 
-        self.project_id = project_id
-        self.gcp_conn_id = gcp_conn_id
-        self.location = location
         self.api_version = api_version
-        self.name = name
+        self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
-        self._check_input()
-
-    def _check_input(self) -> None:
-        if not all([self.project_id, self.name, self.location]):
-            self.log.error("One of (project_id, name, location) is missing or incorrect")
-            raise AirflowException("Operator has incorrect or missing input.")
 
-    def execute(self, context: Context) -> str | None:
-        hook = GKEHook(
+    def execute(self, context: Context) -> list[dict[str, Any]]:
+        hook = GoogleAnalyticsHook(
+            api_version=self.api_version,
             gcp_conn_id=self.gcp_conn_id,
-            location=self.location,
             impersonation_chain=self.impersonation_chain,
         )
-        delete_result = hook.delete_cluster(name=self.name, project_id=self.project_id)
-        return delete_result
+        result = hook.list_accounts()
+        return result
 
 
-class GKECreateClusterOperator(BaseOperator):
+class GoogleAnalyticsGetAdsLinkOperator(BaseOperator):
     """
-    Create a Google Kubernetes Engine Cluster of specified dimensions
-    The operator will wait until the cluster is created.
+    Returns a web property-Google Ads link to which the user has access.
 
-    The **minimum** required to define a cluster to create is:
+    .. seealso::
+        Check official API docs:
+        https://developers.google.com/analytics/devguides/config/mgmt/v3/mgmtReference/management/webPropertyAdWordsLinks/get
+
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:GoogleAnalyticsGetAdsLinkOperator`
+
+    :param account_id: ID of the account which the given web property belongs to.
+    :param web_property_ad_words_link_id: Web property-Google Ads link ID.
+    :param web_property_id: Web property ID to retrieve the Google Ads link for.
+    :param impersonation_chain: Optional service account to impersonate using short-term
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
+    """
 
-    ``dict()`` ::
-        cluster_def = {'name': 'my-cluster-name',
-                       'initial_node_count': 1}
+    template_fields: Sequence[str] = (
+        "api_version",
+        "gcp_conn_id",
+        "account_id",
+        "web_property_ad_words_link_id",
+        "web_property_id",
+        "impersonation_chain",
+    )
 
-    or
+    def __init__(
+        self,
+        *,
+        account_id: str,
+        web_property_ad_words_link_id: str,
+        web_property_id: str,
+        api_version: str = "v3",
+        gcp_conn_id: str = "google_cloud_default",
+        impersonation_chain: str | Sequence[str] | None = None,
+        **kwargs,
+    ):
+        super().__init__(**kwargs)
 
-    ``Cluster`` proto ::
-        from google.cloud.container_v1.types import Cluster
+        self.account_id = account_id
+        self.web_property_ad_words_link_id = web_property_ad_words_link_id
+        self.web_property_id = web_property_id
+        self.api_version = api_version
+        self.gcp_conn_id = gcp_conn_id
+        self.impersonation_chain = impersonation_chain
 
-        cluster_def = Cluster(name='my-cluster-name', initial_node_count=1)
+    def execute(self, context: Context) -> dict[str, Any]:
+        hook = GoogleAnalyticsHook(
+            api_version=self.api_version,
+            gcp_conn_id=self.gcp_conn_id,
+            impersonation_chain=self.impersonation_chain,
+        )
+        result = hook.get_ad_words_link(
+            account_id=self.account_id,
+            web_property_id=self.web_property_id,
+            web_property_ad_words_link_id=self.web_property_ad_words_link_id,
+        )
+        return result
 
-    **Operator Creation**: ::
 
-        operator = GKEClusterCreateOperator(
-                    task_id='cluster_create',
-                    project_id='my-project',
-                    location='my-location'
-                    body=cluster_def)
+class GoogleAnalyticsRetrieveAdsLinksListOperator(BaseOperator):
+    """
+    Lists webProperty-Google Ads links for a given web property
 
     .. seealso::
-        For more detail on about creating clusters have a look at the reference:
-        :class:`google.cloud.container_v1.types.Cluster`
+        Check official API docs:
+        https://developers.google.com/analytics/devguides/config/mgmt/v3/mgmtReference/management/webPropertyAdWordsLinks/list#http-request
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
-        :ref:`howto/operator:GKECreateClusterOperator`
+        :ref:`howto/operator:GoogleAnalyticsRetrieveAdsLinksListOperator`
 
-    :param project_id: The Google Developers Console [project ID or project number]
-    :param location: The name of the Google Kubernetes Engine zone or region in which the cluster
-        resides.
-    :param body: The Cluster definition to create, can be protobuf or python dict, if
-        dict it must match protobuf message Cluster
-    :param gcp_conn_id: The connection ID to use connecting to Google Cloud.
-    :param api_version: The api version to use
+    :param account_id: ID of the account which the given web property belongs to.
+    :param web_property_id: Web property UA-string to retrieve the Google Ads links for.
     :param impersonation_chain: Optional service account to impersonate using short-term
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     """
 
     template_fields: Sequence[str] = (
-        "project_id",
-        "gcp_conn_id",
-        "location",
         "api_version",
-        "body",
+        "gcp_conn_id",
+        "account_id",
+        "web_property_id",
         "impersonation_chain",
     )
-    operator_extra_links = (KubernetesEngineClusterLink(),)
 
     def __init__(
         self,
         *,
-        location: str,
-        body: dict | Cluster | None,
-        project_id: str | None = None,
+        account_id: str,
+        web_property_id: str,
+        api_version: str = "v3",
         gcp_conn_id: str = "google_cloud_default",
-        api_version: str = "v2",
         impersonation_chain: str | Sequence[str] | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
 
-        self.project_id = project_id
+        self.account_id = account_id
+        self.web_property_id = web_property_id
+        self.api_version = api_version
         self.gcp_conn_id = gcp_conn_id
-        self.location = location
+        self.impersonation_chain = impersonation_chain
+
+    def execute(self, context: Context) -> list[dict[str, Any]]:
+        hook = GoogleAnalyticsHook(
+            api_version=self.api_version,
+            gcp_conn_id=self.gcp_conn_id,
+            impersonation_chain=self.impersonation_chain,
+        )
+        result = hook.list_ad_words_links(
+            account_id=self.account_id,
+            web_property_id=self.web_property_id,
+        )
+        return result
+
+
+class GoogleAnalyticsDataImportUploadOperator(BaseOperator):
+    """
+    Take a file from Cloud Storage and uploads it to GA via data import API.
+
+    :param storage_bucket: The Google cloud storage bucket where the file is stored.
+    :param storage_name_object: The name of the object in the desired Google cloud
+          storage bucket. (templated) If the destination points to an existing
+          folder, the file will be taken from the specified folder.
+    :param account_id: The GA account Id (long) to which the data upload belongs.
+    :param web_property_id: The web property UA-string associated with the upload.
+    :param custom_data_source_id: The id to which the data import belongs
+    :param resumable_upload: flag to upload the file in a resumable fashion, using a
+        series of at least two requests.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
+    :param api_version: The version of the api that will be requested for example 'v3'.
+    :param impersonation_chain: Optional service account to impersonate using short-term
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
+    """
+
+    template_fields: Sequence[str] = (
+        "storage_bucket",
+        "storage_name_object",
+        "impersonation_chain",
+    )
+
+    def __init__(
+        self,
+        *,
+        storage_bucket: str,
+        storage_name_object: str,
+        account_id: str,
+        web_property_id: str,
+        custom_data_source_id: str,
+        resumable_upload: bool = False,
+        gcp_conn_id: str = "google_cloud_default",
+        delegate_to: str | None = None,
+        api_version: str = "v3",
+        impersonation_chain: str | Sequence[str] | None = None,
+        **kwargs,
+    ) -> None:
+        super().__init__(**kwargs)
+        self.storage_bucket = storage_bucket
+        self.storage_name_object = storage_name_object
+        self.account_id = account_id
+        self.web_property_id = web_property_id
+        self.custom_data_source_id = custom_data_source_id
+        self.resumable_upload = resumable_upload
+        self.gcp_conn_id = gcp_conn_id
+        self.delegate_to = delegate_to
         self.api_version = api_version
-        self.body = body
         self.impersonation_chain = impersonation_chain
-        self._check_input()
 
-    def _check_input(self) -> None:
-        if (
-            not all([self.project_id, self.location, self.body])
-            or (isinstance(self.body, dict) and "name" not in self.body)
-            or (
-                isinstance(self.body, dict)
-                and ("initial_node_count" not in self.body and "node_pools" not in self.body)
-            )
-            or (not (isinstance(self.body, dict)) and not (getattr(self.body, "name", None)))
-            or (
-                not (isinstance(self.body, dict))
-                and (
-                    not (getattr(self.body, "initial_node_count", None))
-                    and not (getattr(self.body, "node_pools", None))
-                )
-            )
-        ):
-            self.log.error(
-                "One of (project_id, location, body, body['name'], "
-                "body['initial_node_count']), body['node_pools'] is missing or incorrect"
-            )
-            raise AirflowException("Operator has incorrect or missing input.")
-        elif (
-            isinstance(self.body, dict) and ("initial_node_count" in self.body and "node_pools" in self.body)
-        ) or (
-            not (isinstance(self.body, dict))
-            and (getattr(self.body, "initial_node_count", None) and getattr(self.body, "node_pools", None))
-        ):
-            self.log.error("Only one of body['initial_node_count']) and body['node_pools'] may be specified")
-            raise AirflowException("Operator has incorrect or missing input.")
+    def execute(self, context: Context) -> None:
+        gcs_hook = GCSHook(
+            gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
+            impersonation_chain=self.impersonation_chain,
+        )
 
-    def execute(self, context: Context) -> str:
-        hook = GKEHook(
+        ga_hook = GoogleAnalyticsHook(
             gcp_conn_id=self.gcp_conn_id,
-            location=self.location,
+            delegate_to=self.delegate_to,
+            api_version=self.api_version,
             impersonation_chain=self.impersonation_chain,
         )
-        create_op = hook.create_cluster(cluster=self.body, project_id=self.project_id)
-        KubernetesEngineClusterLink.persist(context=context, task_instance=self, cluster=self.body)
-        return create_op
 
+        with NamedTemporaryFile("w+") as tmp_file:
+            self.log.info(
+                "Downloading file from GCS: %s/%s ",
+                self.storage_bucket,
+                self.storage_name_object,
+            )
+            gcs_hook.download(
+                bucket_name=self.storage_bucket,
+                object_name=self.storage_name_object,
+                filename=tmp_file.name,
+            )
 
-KUBE_CONFIG_ENV_VAR = "KUBECONFIG"
+            ga_hook.upload_data(
+                tmp_file.name,
+                self.account_id,
+                self.web_property_id,
+                self.custom_data_source_id,
+                self.resumable_upload,
+            )
 
 
-class GKEStartPodOperator(KubernetesPodOperator):
+class GoogleAnalyticsDeletePreviousDataUploadsOperator(BaseOperator):
     """
-    Executes a task in a Kubernetes pod in the specified Google Kubernetes
-    Engine cluster
+    Deletes previous GA uploads to leave the latest file to control the size of the Data Set Quota.
 
-    This Operator assumes that the system has gcloud installed and has configured a
-    connection id with a service account.
+    :param account_id: The GA account Id (long) to which the data upload belongs.
+    :param web_property_id: The web property UA-string associated with the upload.
+    :param custom_data_source_id: The id to which the data import belongs.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
+    :param api_version: The version of the api that will be requested for example 'v3'.
+    :param impersonation_chain: Optional service account to impersonate using short-term
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
+    """
 
-    The **minimum** required to define a cluster to create are the variables
-    ``task_id``, ``project_id``, ``location``, ``cluster_name``, ``name``,
-    ``namespace``, and ``image``
+    template_fields: Sequence[str] = ("impersonation_chain",)
 
-    .. seealso::
-        For more detail about Kubernetes Engine authentication have a look at the reference:
-        https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-access-for-kubectl#internal_ip
+    def __init__(
+        self,
+        account_id: str,
+        web_property_id: str,
+        custom_data_source_id: str,
+        gcp_conn_id: str = "google_cloud_default",
+        delegate_to: str | None = None,
+        api_version: str = "v3",
+        impersonation_chain: str | Sequence[str] | None = None,
+        **kwargs,
+    ) -> None:
+        super().__init__(**kwargs)
 
-    .. seealso::
-        For more information on how to use this operator, take a look at the guide:
-        :ref:`howto/operator:GKEStartPodOperator`
+        self.account_id = account_id
+        self.web_property_id = web_property_id
+        self.custom_data_source_id = custom_data_source_id
+        self.gcp_conn_id = gcp_conn_id
+        self.delegate_to = delegate_to
+        self.api_version = api_version
+        self.impersonation_chain = impersonation_chain
+
+    def execute(self, context: Context) -> None:
+        ga_hook = GoogleAnalyticsHook(
+            gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
+            api_version=self.api_version,
+            impersonation_chain=self.impersonation_chain,
+        )
+
+        uploads = ga_hook.list_uploads(
+            account_id=self.account_id,
+            web_property_id=self.web_property_id,
+            custom_data_source_id=self.custom_data_source_id,
+        )
 
-    :param location: The name of the Google Kubernetes Engine zone or region in which the
-        cluster resides, e.g. 'us-central1-a'
-    :param cluster_name: The name of the Google Kubernetes Engine cluster the pod
-        should be spawned in
-    :param use_internal_ip: Use the internal IP address as the endpoint.
-    :param project_id: The Google Developers Console project id
-    :param gcp_conn_id: The google cloud connection id to use. This allows for
-        users to specify a service account.
+        cids = [upload["id"] for upload in uploads]
+        delete_request_body = {"customDataImportUids": cids}
+
+        ga_hook.delete_upload_data(
+            self.account_id,
+            self.web_property_id,
+            self.custom_data_source_id,
+            delete_request_body,
+        )
+
+
+class GoogleAnalyticsModifyFileHeadersDataImportOperator(BaseOperator):
+    """
+    GA has a very particular naming convention for Data Import. Ability to
+    prefix "ga:" to all column headers and also a dict to rename columns to
+    match the custom dimension ID in GA i.e clientId : dimensionX.
+
+    :param storage_bucket: The Google cloud storage bucket where the file is stored.
+    :param storage_name_object: The name of the object in the desired Google cloud
+          storage bucket. (templated) If the destination points to an existing
+          folder, the file will be taken from the specified folder.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
+    :param custom_dimension_header_mapping: Dictionary to handle when uploading
+          custom dimensions which have generic IDs ie. 'dimensionX' which are
+          set by GA. Dictionary maps the current CSV header to GA ID which will
+          be the new header for the CSV to upload to GA eg clientId : dimension1.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
     :param impersonation_chain: Optional service account to impersonate using short-term
-        credentials, or list of accounts required to get the access_token
+        credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-    :param regional: The location param is region name.
-    :param is_delete_operator_pod: What to do when the pod reaches its final
-        state, or the execution is interrupted. If True, delete the
-        pod; if False, leave the pod.  Current default is False, but this will be
-        changed in the next major release of this provider.
     """
 
-    template_fields: Sequence[str] = tuple(
-        {"project_id", "location", "cluster_name"} | set(KubernetesPodOperator.template_fields)
+    template_fields: Sequence[str] = (
+        "storage_bucket",
+        "storage_name_object",
+        "impersonation_chain",
     )
-    operator_extra_links = (KubernetesEnginePodLink(),)
 
     def __init__(
         self,
-        *,
-        location: str,
-        cluster_name: str,
-        use_internal_ip: bool = False,
-        project_id: str | None = None,
+        storage_bucket: str,
+        storage_name_object: str,
         gcp_conn_id: str = "google_cloud_default",
+        delegate_to: str | None = None,
+        custom_dimension_header_mapping: dict[str, str] | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
-        regional: bool = False,
-        is_delete_operator_pod: bool | None = None,
         **kwargs,
     ) -> None:
-        if is_delete_operator_pod is None:
-            warnings.warn(
-                f"You have not set parameter `is_delete_operator_pod` in class {self.__class__.__name__}. "
-                "Currently the default for this parameter is `False` but in a future release the default "
-                "will be changed to `True`. To ensure pods are not deleted in the future you will need to "
-                "set `is_delete_operator_pod=False` explicitly.",
-                DeprecationWarning,
-                stacklevel=2,
-            )
-            is_delete_operator_pod = False
-
-        super().__init__(is_delete_operator_pod=is_delete_operator_pod, **kwargs)
-        self.project_id = project_id
-        self.location = location
-        self.cluster_name = cluster_name
+        super().__init__(**kwargs)
+        self.storage_bucket = storage_bucket
+        self.storage_name_object = storage_name_object
         self.gcp_conn_id = gcp_conn_id
-        self.use_internal_ip = use_internal_ip
+        self.delegate_to = delegate_to
+        self.custom_dimension_header_mapping = custom_dimension_header_mapping or {}
         self.impersonation_chain = impersonation_chain
-        self.regional = regional
 
-        if self.gcp_conn_id is None:
-            raise AirflowException(
-                "The gcp_conn_id parameter has become required. If you want to use Application Default "
-                "Credentials (ADC) strategy for authorization, create an empty connection "
-                "called `google_cloud_default`.",
-            )
-        # There is no need to manage the kube_config file, as it will be generated automatically.
-        # All Kubernetes parameters (except config_file) are also valid for the GKEStartPodOperator.
-        if self.config_file:
-            raise AirflowException("config_file is not an allowed parameter for the GKEStartPodOperator.")
-
-    @staticmethod
-    @contextmanager
-    def get_gke_config_file(
-        gcp_conn_id,
-        project_id: str | None,
-        cluster_name: str,
-        impersonation_chain: str | Sequence[str] | None,
-        regional: bool,
-        location: str,
-        use_internal_ip: bool,
-    ) -> Generator[str, None, None]:
-
-        hook = GoogleBaseHook(gcp_conn_id=gcp_conn_id)
-        project_id = project_id or hook.project_id
-
-        if not project_id:
-            raise AirflowException(
-                "The project id must be passed either as "
-                "keyword project_id parameter or as project_id extra "
-                "in Google Cloud connection definition. Both are not set!"
-            )
-
-        # Write config to a temp file and set the environment variable to point to it.
-        # This is to avoid race conditions of reading/writing a single file
-        with tempfile.NamedTemporaryFile() as conf_file, patch_environ(
-            {KUBE_CONFIG_ENV_VAR: conf_file.name}
-        ), hook.provide_authorized_gcloud():
-            # Attempt to get/update credentials
-            # We call gcloud directly instead of using google-cloud-python api
-            # because there is no way to write kubernetes config to a file, which is
-            # required by KubernetesPodOperator.
-            # The gcloud command looks at the env variable `KUBECONFIG` for where to save
-            # the kubernetes config file.
-            cmd = [
-                "gcloud",
-                "container",
-                "clusters",
-                "get-credentials",
-                cluster_name,
-                "--project",
-                project_id,
-            ]
-            if impersonation_chain:
-                if isinstance(impersonation_chain, str):
-                    impersonation_account = impersonation_chain
-                elif len(impersonation_chain) == 1:
-                    impersonation_account = impersonation_chain[0]
-                else:
-                    raise AirflowException(
-                        "Chained list of accounts is not supported, please specify only one service account"
-                    )
-
-                cmd.extend(
-                    [
-                        "--impersonate-service-account",
-                        impersonation_account,
-                    ]
+    def _modify_column_headers(
+        self, tmp_file_location: str, custom_dimension_header_mapping: dict[str, str]
+    ) -> None:
+        # Check headers
+        self.log.info("Checking if file contains headers")
+        with open(tmp_file_location) as check_header_file:
+            has_header = csv.Sniffer().has_header(check_header_file.read(1024))
+            if not has_header:
+                raise NameError(
+                    "CSV does not contain headers, please add them "
+                    "to use the modify column headers functionality"
                 )
-            if regional:
-                cmd.append("--region")
-            else:
-                cmd.append("--zone")
-            cmd.append(location)
-            if use_internal_ip:
-                cmd.append("--internal-ip")
-            execute_in_subprocess(cmd)
 
-            # Tell `KubernetesPodOperator` where the config file is located
-            yield os.environ[KUBE_CONFIG_ENV_VAR]
+        # Transform
+        self.log.info("Modifying column headers to be compatible for data upload")
+        with open(tmp_file_location) as read_file:
+            reader = csv.reader(read_file)
+            headers = next(reader)
+            new_headers = []
+            for header in headers:
+                if header in custom_dimension_header_mapping:
+                    header = custom_dimension_header_mapping.get(header)  # type: ignore
+                new_header = f"ga:{header}"
+                new_headers.append(new_header)
+            all_data = read_file.readlines()
+            final_headers = ",".join(new_headers) + "\n"
+            all_data.insert(0, final_headers)
+
+        # Save result
+        self.log.info("Saving transformed file")
+        with open(tmp_file_location, "w") as write_file:
+            write_file.writelines(all_data)
 
-    def execute(self, context: Context) -> str | None:
-
-        with GKEStartPodOperator.get_gke_config_file(
+    def execute(self, context: Context) -> None:
+        gcs_hook = GCSHook(
             gcp_conn_id=self.gcp_conn_id,
-            project_id=self.project_id,
-            cluster_name=self.cluster_name,
+            delegate_to=self.delegate_to,
             impersonation_chain=self.impersonation_chain,
-            regional=self.regional,
-            location=self.location,
-            use_internal_ip=self.use_internal_ip,
-        ) as config_file:
-            self.config_file = config_file
-            result = super().execute(context)
-            if not self.is_delete_operator_pod:
-                KubernetesEnginePodLink.persist(context=context, task_instance=self)
-            return result
+        )
+        with NamedTemporaryFile("w+") as tmp_file:
+            # Download file from GCS
+            self.log.info(
+                "Downloading file from GCS: %s/%s ",
+                self.storage_bucket,
+                self.storage_name_object,
+            )
+
+            gcs_hook.download(
+                bucket_name=self.storage_bucket,
+                object_name=self.storage_name_object,
+                filename=tmp_file.name,
+            )
+
+            # Modify file
+            self.log.info("Modifying temporary file %s", tmp_file.name)
+            self._modify_column_headers(
+                tmp_file_location=tmp_file.name,
+                custom_dimension_header_mapping=self.custom_dimension_header_mapping,
+            )
+
+            # Upload newly formatted file to cloud storage
+            self.log.info(
+                "Uploading file to GCS: %s/%s ",
+                self.storage_bucket,
+                self.storage_name_object,
+            )
+            gcs_hook.upload(
+                bucket_name=self.storage_bucket,
+                object_name=self.storage_name_object,
+                filename=tmp_file.name,
+            )
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/life_sciences.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/life_sciences.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,23 +17,23 @@
 # under the License.
 """Operators that interact with Google Cloud Life Sciences service."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Sequence
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.life_sciences import LifeSciencesHook
 from airflow.providers.google.cloud.links.life_sciences import LifeSciencesLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class LifeSciencesRunPipelineOperator(BaseOperator):
+class LifeSciencesRunPipelineOperator(GoogleCloudBaseOperator):
     """
     Runs a Life Sciences Pipeline
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:LifeSciencesRunPipelineOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/looker.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/looker.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,22 +17,22 @@
 # under the License.
 """This module contains Google Cloud Looker operators."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.looker import LookerHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class LookerStartPdtBuildOperator(BaseOperator):
+class LookerStartPdtBuildOperator(GoogleCloudBaseOperator):
     """
     Submits a PDT materialization job to Looker.
 
     :param looker_conn_id: Required. The connection ID to use connecting to Looker.
     :param model: Required. The model of the PDT to start building.
     :param view: Required. The view of the PDT to start building.
     :param query_params: Optional. Additional materialization parameters.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/mlengine.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/mlengine.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,23 +24,23 @@
 import time
 import warnings
 from typing import TYPE_CHECKING, Any, Sequence
 
 from googleapiclient.errors import HttpError
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.mlengine import MLEngineHook
 from airflow.providers.google.cloud.links.mlengine import (
     MLEngineJobDetailsLink,
     MLEngineJobSListLink,
     MLEngineModelLink,
     MLEngineModelsListLink,
     MLEngineModelVersionDetailsLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.cloud.triggers.mlengine import MLEngineStartTrainingJobTrigger
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 log = logging.getLogger(__name__)
@@ -73,15 +73,15 @@
 
     # Clean up last substring or the full string if no templates
     cleansed_job_id += re.sub(r"[^0-9a-zA-Z]+", "_", job[tracker:])
 
     return cleansed_job_id
 
 
-class MLEngineStartBatchPredictionJobOperator(BaseOperator):
+class MLEngineStartBatchPredictionJobOperator(GoogleCloudBaseOperator):
     """
     Start a Google Cloud ML Engine prediction job.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineStartBatchPredictionJobOperator`
 
@@ -290,15 +290,15 @@
         if finished_prediction_job["state"] != "SUCCEEDED":
             self.log.error("MLEngine batch prediction job failed: %s", str(finished_prediction_job))
             raise RuntimeError(finished_prediction_job["errorMessage"])
 
         return finished_prediction_job["predictionOutput"]
 
 
-class MLEngineManageModelOperator(BaseOperator):
+class MLEngineManageModelOperator(GoogleCloudBaseOperator):
     """
     Operator for managing a Google Cloud ML Engine model.
 
     .. warning::
        This operator is deprecated. Consider using operators for specific operations:
        MLEngineCreateModelOperator, MLEngineGetModelOperator.
 
@@ -376,15 +376,15 @@
             return hook.create_model(project_id=self._project_id, model=self._model)
         elif self._operation == "get":
             return hook.get_model(project_id=self._project_id, model_name=self._model["name"])
         else:
             raise ValueError(f"Unknown operation: {self._operation}")
 
 
-class MLEngineCreateModelOperator(BaseOperator):
+class MLEngineCreateModelOperator(GoogleCloudBaseOperator):
     """
     Creates a new model.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineCreateModelOperator`
 
@@ -451,15 +451,15 @@
                 project_id=project_id,
                 model_id=self._model["name"],
             )
 
         return hook.create_model(project_id=self._project_id, model=self._model)
 
 
-class MLEngineGetModelOperator(BaseOperator):
+class MLEngineGetModelOperator(GoogleCloudBaseOperator):
     """
     Gets a particular model
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineGetModelOperator`
 
@@ -525,15 +525,15 @@
                 project_id=project_id,
                 model_id=self._model_name,
             )
 
         return hook.get_model(project_id=self._project_id, model_name=self._model_name)
 
 
-class MLEngineDeleteModelOperator(BaseOperator):
+class MLEngineDeleteModelOperator(GoogleCloudBaseOperator):
     """
     Deletes a model.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineDeleteModelOperator`
 
@@ -606,15 +606,15 @@
             )
 
         return hook.delete_model(
             project_id=self._project_id, model_name=self._model_name, delete_contents=self._delete_contents
         )
 
 
-class MLEngineManageVersionOperator(BaseOperator):
+class MLEngineManageVersionOperator(GoogleCloudBaseOperator):
     """
     Operator for managing a Google Cloud ML Engine version.
 
     .. warning::
        This operator is deprecated. Consider using operators for specific operations:
        MLEngineCreateVersionOperator, MLEngineSetDefaultVersionOperator,
        MLEngineListVersionsOperator, MLEngineDeleteVersionOperator.
@@ -734,15 +734,15 @@
             return hook.delete_version(
                 project_id=self._project_id, model_name=self._model_name, version_name=self._version["name"]
             )
         else:
             raise ValueError(f"Unknown operation: {self._operation}")
 
 
-class MLEngineCreateVersionOperator(BaseOperator):
+class MLEngineCreateVersionOperator(GoogleCloudBaseOperator):
     """
     Creates a new version in the model
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineCreateVersionOperator`
 
@@ -826,15 +826,15 @@
             )
 
         return hook.create_version(
             project_id=self._project_id, model_name=self._model_name, version_spec=self._version
         )
 
 
-class MLEngineSetDefaultVersionOperator(BaseOperator):
+class MLEngineSetDefaultVersionOperator(GoogleCloudBaseOperator):
     """
     Sets a version in the model.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineSetDefaultVersionOperator`
 
@@ -918,15 +918,15 @@
             )
 
         return hook.set_default_version(
             project_id=self._project_id, model_name=self._model_name, version_name=self._version_name
         )
 
 
-class MLEngineListVersionsOperator(BaseOperator):
+class MLEngineListVersionsOperator(GoogleCloudBaseOperator):
     """
     Lists all available versions of the model
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineListVersionsOperator`
 
@@ -1003,15 +1003,15 @@
 
         return hook.list_versions(
             project_id=self._project_id,
             model_name=self._model_name,
         )
 
 
-class MLEngineDeleteVersionOperator(BaseOperator):
+class MLEngineDeleteVersionOperator(GoogleCloudBaseOperator):
     """
     Deletes the version from the model.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineDeleteVersionOperator`
 
@@ -1094,15 +1094,15 @@
             )
 
         return hook.delete_version(
             project_id=self._project_id, model_name=self._model_name, version_name=self._version_name
         )
 
 
-class MLEngineStartTrainingJobOperator(BaseOperator):
+class MLEngineStartTrainingJobOperator(GoogleCloudBaseOperator):
     """
     Operator for launching a MLEngine training job.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MLEngineStartTrainingJobOperator`
 
@@ -1432,15 +1432,15 @@
     def on_kill(self) -> None:
         if self.job_id and self.cancel_on_kill:
             self.hook.cancel_job(job_id=self.job_id, project_id=self._project_id)  # type: ignore[union-attr]
         else:
             self.log.info("Skipping to cancel job: %s:%s.%s", self._project_id, self.job_id)
 
 
-class MLEngineTrainingCancelJobOperator(BaseOperator):
+class MLEngineTrainingCancelJobOperator(GoogleCloudBaseOperator):
     """
     Operator for cleaning up failed MLEngine training job.
 
     :param job_id: A unique templated id for the submitted Google MLEngine
         training job. (templated)
     :param project_id: The Google Cloud project name within which MLEngine training job should run.
         If set to None or missing, the default project_id from the Google Cloud connection is used.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/natural_language.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/natural_language.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,25 +22,25 @@
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.language_v1 import enums
 from google.cloud.language_v1.types import Document
 from google.protobuf.json_format import MessageToDict
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.natural_language import CloudNaturalLanguageHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 MetaData = Sequence[Tuple[str, str]]
 
 
-class CloudNaturalLanguageAnalyzeEntitiesOperator(BaseOperator):
+class CloudNaturalLanguageAnalyzeEntitiesOperator(GoogleCloudBaseOperator):
     """
     Finds named entities in the text along with entity types,
     salience, mentions for each entity, and other properties.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudNaturalLanguageAnalyzeEntitiesOperator`
@@ -104,15 +104,15 @@
             document=self.document, retry=self.retry, timeout=self.timeout, metadata=self.metadata
         )
         self.log.info("Finished analyzing entities")
 
         return MessageToDict(response)
 
 
-class CloudNaturalLanguageAnalyzeEntitySentimentOperator(BaseOperator):
+class CloudNaturalLanguageAnalyzeEntitySentimentOperator(GoogleCloudBaseOperator):
     """
     Finds entities, similar to AnalyzeEntities in the text and analyzes sentiment associated with each
     entity and its mentions.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudNaturalLanguageAnalyzeEntitySentimentOperator`
@@ -181,15 +181,15 @@
             metadata=self.metadata,
         )
         self.log.info("Finished entity sentiment analyze")
 
         return MessageToDict(response)
 
 
-class CloudNaturalLanguageAnalyzeSentimentOperator(BaseOperator):
+class CloudNaturalLanguageAnalyzeSentimentOperator(GoogleCloudBaseOperator):
     """
     Analyzes the sentiment of the provided text.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudNaturalLanguageAnalyzeSentimentOperator`
 
@@ -253,15 +253,15 @@
             document=self.document, retry=self.retry, timeout=self.timeout, metadata=self.metadata
         )
         self.log.info("Finished sentiment analyze")
 
         return MessageToDict(response)
 
 
-class CloudNaturalLanguageClassifyTextOperator(BaseOperator):
+class CloudNaturalLanguageClassifyTextOperator(GoogleCloudBaseOperator):
     """
     Classifies a document into categories.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudNaturalLanguageClassifyTextOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/pubsub.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/pubsub.py`

 * *Files 0% similar despite different names*

```diff
@@ -35,23 +35,23 @@
     ExpirationPolicy,
     MessageStoragePolicy,
     PushConfig,
     ReceivedMessage,
     RetryPolicy,
 )
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.pubsub import PubSubHook
 from airflow.providers.google.cloud.links.pubsub import PubSubSubscriptionLink, PubSubTopicLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class PubSubCreateTopicOperator(BaseOperator):
+class PubSubCreateTopicOperator(GoogleCloudBaseOperator):
     """Create a PubSub topic.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:PubSubCreateTopicOperator`
 
     By default, if the topic already exists, this operator will
@@ -183,15 +183,15 @@
             context=context,
             task_instance=self,
             topic_id=self.topic,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class PubSubCreateSubscriptionOperator(BaseOperator):
+class PubSubCreateSubscriptionOperator(GoogleCloudBaseOperator):
     """Create a PubSub subscription.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:PubSubCreateSubscriptionOperator`
 
     By default, the subscription will be created in ``project_id``. If
@@ -410,15 +410,15 @@
             task_instance=self,
             subscription_id=self.subscription or result,  # result returns subscription name
             project_id=self.project_id or hook.project_id,
         )
         return result
 
 
-class PubSubDeleteTopicOperator(BaseOperator):
+class PubSubDeleteTopicOperator(GoogleCloudBaseOperator):
     """Delete a PubSub topic.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:PubSubDeleteTopicOperator`
 
     By default, if the topic does not exist, this operator will
@@ -516,15 +516,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         self.log.info("Deleted topic %s", self.topic)
 
 
-class PubSubDeleteSubscriptionOperator(BaseOperator):
+class PubSubDeleteSubscriptionOperator(GoogleCloudBaseOperator):
     """Delete a PubSub subscription.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:PubSubDeleteSubscriptionOperator`
 
     By default, if the subscription does not exist, this operator will
@@ -624,15 +624,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         self.log.info("Deleted subscription %s", self.subscription)
 
 
-class PubSubPublishMessageOperator(BaseOperator):
+class PubSubPublishMessageOperator(GoogleCloudBaseOperator):
     """Publish messages to a PubSub topic.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:PubSubPublishMessageOperator`
 
     Each Task publishes all provided messages to the same topic
@@ -724,15 +724,15 @@
         )
 
         self.log.info("Publishing to topic %s", self.topic)
         hook.publish(project_id=self.project_id, topic=self.topic, messages=self.messages)
         self.log.info("Published to topic %s", self.topic)
 
 
-class PubSubPullOperator(BaseOperator):
+class PubSubPullOperator(GoogleCloudBaseOperator):
     """Pulls messages from a PubSub subscription and passes them through XCom.
     If the queue is empty, returns empty list - never waits for messages.
     If you do need to wait, please use :class:`airflow.providers.google.cloud.sensors.PubSubPullSensor`
     instead.
 
     .. seealso::
         For more information on how to use this operator and the PubSubPullSensor, take a look at the guide:
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/spanner.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/spanner.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,23 +17,23 @@
 # under the License.
 """This module contains Google Spanner operators."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Sequence
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.spanner import SpannerHook
 from airflow.providers.google.cloud.links.spanner import SpannerDatabaseLink, SpannerInstanceLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class SpannerDeployInstanceOperator(BaseOperator):
+class SpannerDeployInstanceOperator(GoogleCloudBaseOperator):
     """
     Creates a new Cloud Spanner instance, or if an instance with the same instance_id
     exists in the specified project, updates the Cloud Spanner instance.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:SpannerDeployInstanceOperator`
@@ -122,15 +122,15 @@
             context=context,
             task_instance=self,
             instance_id=self.instance_id,
             project_id=self.project_id or hook.project_id,
         )
 
 
-class SpannerDeleteInstanceOperator(BaseOperator):
+class SpannerDeleteInstanceOperator(GoogleCloudBaseOperator):
     """
     Deletes a Cloud Spanner instance. If an instance does not exist,
     no action is taken and the operator succeeds.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:SpannerDeleteInstanceOperator`
@@ -192,15 +192,15 @@
                 "Instance '%s' does not exist in project '%s'. Aborting delete.",
                 self.instance_id,
                 self.project_id,
             )
             return True
 
 
-class SpannerQueryDatabaseInstanceOperator(BaseOperator):
+class SpannerQueryDatabaseInstanceOperator(GoogleCloudBaseOperator):
     """
     Executes an arbitrary DML query (INSERT, UPDATE, DELETE).
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:SpannerQueryDatabaseInstanceOperator`
 
@@ -303,15 +303,15 @@
 
         :param queries: queries
         """
         if queries and queries[-1] == "":
             del queries[-1]
 
 
-class SpannerDeployDatabaseInstanceOperator(BaseOperator):
+class SpannerDeployDatabaseInstanceOperator(GoogleCloudBaseOperator):
     """
     Creates a new Cloud Spanner database, or if database exists,
     the operator does nothing.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:SpannerDeployDatabaseInstanceOperator`
@@ -408,15 +408,15 @@
                 self.database_id,
                 self.project_id,
                 self.instance_id,
             )
         return True
 
 
-class SpannerUpdateDatabaseInstanceOperator(BaseOperator):
+class SpannerUpdateDatabaseInstanceOperator(GoogleCloudBaseOperator):
     """
     Updates a Cloud Spanner database with the specified DDL statement.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:SpannerUpdateDatabaseInstanceOperator`
 
@@ -510,15 +510,15 @@
                 instance_id=self.instance_id,
                 database_id=self.database_id,
                 ddl_statements=self.ddl_statements,
                 operation_id=self.operation_id,
             )
 
 
-class SpannerDeleteDatabaseInstanceOperator(BaseOperator):
+class SpannerDeleteDatabaseInstanceOperator(GoogleCloudBaseOperator):
     """
     Deletes a Cloud Spanner database.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:SpannerDeleteDatabaseInstanceOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/speech_to_text.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/speech_to_text.py`

 * *Files 6% similar despite different names*

```diff
@@ -22,23 +22,23 @@
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.speech_v1.types import RecognitionConfig
 from google.protobuf.json_format import MessageToDict
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.speech_to_text import CloudSpeechToTextHook, RecognitionAudio
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.common.links.storage import FileDetailsLink
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudSpeechToTextRecognizeSpeechOperator(BaseOperator):
+class CloudSpeechToTextRecognizeSpeechOperator(GoogleCloudBaseOperator):
     """
     Recognizes speech from audio file and returns it as text.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudSpeechToTextRecognizeSpeechOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/stackdriver.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/stackdriver.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,26 +20,26 @@
 import warnings
 from typing import TYPE_CHECKING, Sequence
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.monitoring_v3 import AlertPolicy, NotificationChannel
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.stackdriver import StackdriverHook
 from airflow.providers.google.cloud.links.stackdriver import (
     StackdriverNotificationsLink,
     StackdriverPoliciesLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class StackdriverListAlertPoliciesOperator(BaseOperator):
+class StackdriverListAlertPoliciesOperator(GoogleCloudBaseOperator):
     """
     Fetches all the Alert Policies identified by the filter passed as
     filter parameter. The desired return type can be specified by the
     format parameter, the supported formats are "dict", "json" and None
     which returns python dictionary, stringified JSON and protobuf
     respectively.
 
@@ -155,15 +155,15 @@
             context=context,
             operator_instance=self,
             project_id=self.project_id or self.hook.project_id,
         )
         return [AlertPolicy.to_dict(policy) for policy in result]
 
 
-class StackdriverEnableAlertPoliciesOperator(BaseOperator):
+class StackdriverEnableAlertPoliciesOperator(GoogleCloudBaseOperator):
     """
     Enables one or more disabled alerting policies identified by filter
     parameter. Inoperative in case the policy is already enabled.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:StackdriverEnableAlertPoliciesOperator`
@@ -247,15 +247,15 @@
             context=context,
             operator_instance=self,
             project_id=self.project_id or self.hook.project_id,
         )
 
 
 # Disable Alert Operator
-class StackdriverDisableAlertPoliciesOperator(BaseOperator):
+class StackdriverDisableAlertPoliciesOperator(GoogleCloudBaseOperator):
     """
     Disables one or more enabled alerting policies identified by filter
     parameter. Inoperative in case the policy is already disabled.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:StackdriverDisableAlertPoliciesOperator`
@@ -338,15 +338,15 @@
         StackdriverPoliciesLink.persist(
             context=context,
             operator_instance=self,
             project_id=self.project_id or self.hook.project_id,
         )
 
 
-class StackdriverUpsertAlertOperator(BaseOperator):
+class StackdriverUpsertAlertOperator(GoogleCloudBaseOperator):
     """
     Creates a new alert or updates an existing policy identified
     the name field in the alerts parameter.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:StackdriverUpsertAlertOperator`
@@ -432,15 +432,15 @@
         StackdriverPoliciesLink.persist(
             context=context,
             operator_instance=self,
             project_id=self.project_id or self.hook.project_id,
         )
 
 
-class StackdriverDeleteAlertOperator(BaseOperator):
+class StackdriverDeleteAlertOperator(GoogleCloudBaseOperator):
     """
     Deletes an alerting policy.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:StackdriverDeleteAlertOperator`
 
@@ -515,15 +515,15 @@
             name=self.name,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class StackdriverListNotificationChannelsOperator(BaseOperator):
+class StackdriverListNotificationChannelsOperator(GoogleCloudBaseOperator):
     """
     Fetches all the Notification Channels identified by the filter passed as
     filter parameter. The desired return type can be specified by the
     format parameter, the supported formats are "dict", "json" and None
     which returns python dictionary, stringified JSON and protobuf
     respectively.
 
@@ -639,15 +639,15 @@
             context=context,
             operator_instance=self,
             project_id=self.project_id or self.hook.project_id,
         )
         return [NotificationChannel.to_dict(channel) for channel in channels]
 
 
-class StackdriverEnableNotificationChannelsOperator(BaseOperator):
+class StackdriverEnableNotificationChannelsOperator(GoogleCloudBaseOperator):
     """
     Enables one or more disabled alerting policies identified by filter
     parameter. Inoperative in case the policy is already enabled.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:StackdriverEnableNotificationChannelsOperator`
@@ -733,15 +733,15 @@
         StackdriverNotificationsLink.persist(
             context=context,
             operator_instance=self,
             project_id=self.project_id or self.hook.project_id,
         )
 
 
-class StackdriverDisableNotificationChannelsOperator(BaseOperator):
+class StackdriverDisableNotificationChannelsOperator(GoogleCloudBaseOperator):
     """
     Disables one or more enabled notification channels identified by filter
     parameter. Inoperative in case the policy is already disabled.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:StackdriverDisableNotificationChannelsOperator`
@@ -827,15 +827,15 @@
         StackdriverNotificationsLink.persist(
             context=context,
             operator_instance=self,
             project_id=self.project_id or self.hook.project_id,
         )
 
 
-class StackdriverUpsertNotificationChannelOperator(BaseOperator):
+class StackdriverUpsertNotificationChannelOperator(GoogleCloudBaseOperator):
     """
     Creates a new notification or updates an existing notification channel
     identified the name field in the alerts parameter.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:StackdriverUpsertNotificationChannelOperator`
@@ -923,15 +923,15 @@
         StackdriverNotificationsLink.persist(
             context=context,
             operator_instance=self,
             project_id=self.project_id or self.hook.project_id,
         )
 
 
-class StackdriverDeleteNotificationChannelOperator(BaseOperator):
+class StackdriverDeleteNotificationChannelOperator(GoogleCloudBaseOperator):
     """
     Deletes a notification channel.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:StackdriverDeleteNotificationChannelOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/tasks.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/tasks.py`

 * *Files 0% similar despite different names*

```diff
@@ -26,26 +26,26 @@
 
 from google.api_core.exceptions import AlreadyExists
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.tasks_v2.types import Queue, Task
 from google.protobuf.field_mask_pb2 import FieldMask
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.tasks import CloudTasksHook
 from airflow.providers.google.cloud.links.cloud_tasks import CloudTasksLink, CloudTasksQueueLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 MetaData = Sequence[Tuple[str, str]]
 
 
-class CloudTasksQueueCreateOperator(BaseOperator):
+class CloudTasksQueueCreateOperator(GoogleCloudBaseOperator):
     """
     Creates a queue in Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksQueueCreateOperator`
 
@@ -140,15 +140,15 @@
             operator_instance=self,
             context=context,
             queue_name=queue.name,
         )
         return Queue.to_dict(queue)
 
 
-class CloudTasksQueueUpdateOperator(BaseOperator):
+class CloudTasksQueueUpdateOperator(GoogleCloudBaseOperator):
     """
     Updates a queue in Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksQueueUpdateOperator`
 
@@ -239,15 +239,15 @@
             operator_instance=self,
             context=context,
             queue_name=queue.name,
         )
         return Queue.to_dict(queue)
 
 
-class CloudTasksQueueGetOperator(BaseOperator):
+class CloudTasksQueueGetOperator(GoogleCloudBaseOperator):
     """
     Gets a queue from Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksQueueGetOperator`
 
@@ -322,15 +322,15 @@
             operator_instance=self,
             context=context,
             queue_name=queue.name,
         )
         return Queue.to_dict(queue)
 
 
-class CloudTasksQueuesListOperator(BaseOperator):
+class CloudTasksQueuesListOperator(GoogleCloudBaseOperator):
     """
     Lists queues from Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksQueuesListOperator`
 
@@ -409,15 +409,15 @@
             operator_instance=self,
             context=context,
             project_id=self.project_id or hook.project_id,
         )
         return [Queue.to_dict(q) for q in queues]
 
 
-class CloudTasksQueueDeleteOperator(BaseOperator):
+class CloudTasksQueueDeleteOperator(GoogleCloudBaseOperator):
     """
     Deletes a queue from Cloud Tasks, even if it has tasks in it.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksQueueDeleteOperator`
 
@@ -484,15 +484,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudTasksQueuePurgeOperator(BaseOperator):
+class CloudTasksQueuePurgeOperator(GoogleCloudBaseOperator):
     """
     Purges a queue by deleting all of its tasks from Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksQueuePurgeOperator`
 
@@ -567,15 +567,15 @@
             operator_instance=self,
             context=context,
             queue_name=queue.name,
         )
         return Queue.to_dict(queue)
 
 
-class CloudTasksQueuePauseOperator(BaseOperator):
+class CloudTasksQueuePauseOperator(GoogleCloudBaseOperator):
     """
     Pauses a queue in Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksQueuePauseOperator`
 
@@ -650,15 +650,15 @@
             operator_instance=self,
             context=context,
             queue_name=queue.name,
         )
         return Queue.to_dict(queue)
 
 
-class CloudTasksQueueResumeOperator(BaseOperator):
+class CloudTasksQueueResumeOperator(GoogleCloudBaseOperator):
     """
     Resumes a queue in Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksQueueResumeOperator`
 
@@ -733,15 +733,15 @@
             operator_instance=self,
             context=context,
             queue_name=queue.name,
         )
         return Queue.to_dict(queue)
 
 
-class CloudTasksTaskCreateOperator(BaseOperator):
+class CloudTasksTaskCreateOperator(GoogleCloudBaseOperator):
     """
     Creates a task in Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksTaskCreateOperator`
 
@@ -833,15 +833,15 @@
             operator_instance=self,
             context=context,
             queue_name=task.name,
         )
         return Task.to_dict(task)
 
 
-class CloudTasksTaskGetOperator(BaseOperator):
+class CloudTasksTaskGetOperator(GoogleCloudBaseOperator):
     """
     Gets a task from Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksTaskGetOperator`
 
@@ -926,15 +926,15 @@
             operator_instance=self,
             context=context,
             queue_name=task.name,
         )
         return Task.to_dict(task)
 
 
-class CloudTasksTasksListOperator(BaseOperator):
+class CloudTasksTasksListOperator(GoogleCloudBaseOperator):
     """
     Lists the tasks in Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksTasksListOperator`
 
@@ -1020,15 +1020,15 @@
             context=context,
             queue_name=f"projects/{self.project_id or hook.project_id}/"
             f"locations/{self.location}/queues/{self.queue_name}",
         )
         return [Task.to_dict(t) for t in tasks]
 
 
-class CloudTasksTaskDeleteOperator(BaseOperator):
+class CloudTasksTaskDeleteOperator(GoogleCloudBaseOperator):
     """
     Deletes a task from Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksTaskDeleteOperator`
 
@@ -1100,15 +1100,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudTasksTaskRunOperator(BaseOperator):
+class CloudTasksTaskRunOperator(GoogleCloudBaseOperator):
     """
     Forces to run a task in Cloud Tasks.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTasksTaskRunOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/text_to_speech.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/text_to_speech.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,24 +22,24 @@
 from typing import TYPE_CHECKING, Sequence
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.texttospeech_v1.types import AudioConfig, SynthesisInput, VoiceSelectionParams
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.gcs import GCSHook
 from airflow.providers.google.cloud.hooks.text_to_speech import CloudTextToSpeechHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.common.links.storage import FileDetailsLink
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudTextToSpeechSynthesizeOperator(BaseOperator):
+class CloudTextToSpeechSynthesizeOperator(GoogleCloudBaseOperator):
     """
     Synthesizes text to speech and stores it in Google Cloud Storage
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTextToSpeechSynthesizeOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/translate.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/translate.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,22 +17,22 @@
 # under the License.
 """This module contains Google Translate operators."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Sequence
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.translate import CloudTranslateHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudTranslateTextOperator(BaseOperator):
+class CloudTranslateTextOperator(GoogleCloudBaseOperator):
     """
     Translate a string or list of strings.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudTranslateTextOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/translate_speech.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/translate_speech.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,24 +20,24 @@
 
 from typing import TYPE_CHECKING, Sequence
 
 from google.cloud.speech_v1.types import RecognitionAudio, RecognitionConfig
 from google.protobuf.json_format import MessageToDict
 
 from airflow.exceptions import AirflowException
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.speech_to_text import CloudSpeechToTextHook
 from airflow.providers.google.cloud.hooks.translate import CloudTranslateHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 from airflow.providers.google.common.links.storage import FileDetailsLink
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudTranslateSpeechOperator(BaseOperator):
+class CloudTranslateSpeechOperator(GoogleCloudBaseOperator):
     """
     Recognizes speech in audio input and translates it.
 
     Note that it uses the first result from the recognition api response - the one with the highest confidence
     In order to see other possible results please use
     :ref:`howto/operator:CloudSpeechToTextRecognizeSpeechOperator`
     and
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/auto_ml.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/auto_ml.py`

 * *Files 0% similar despite different names*

```diff
@@ -24,27 +24,27 @@
 from google.api_core.exceptions import NotFound
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.aiplatform import datasets
 from google.cloud.aiplatform.models import Model
 from google.cloud.aiplatform_v1.types.training_pipeline import TrainingPipeline
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.vertex_ai.auto_ml import AutoMLHook
 from airflow.providers.google.cloud.links.vertex_ai import (
     VertexAIModelLink,
     VertexAITrainingLink,
     VertexAITrainingPipelinesLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class AutoMLTrainingJobBaseOperator(BaseOperator):
+class AutoMLTrainingJobBaseOperator(GoogleCloudBaseOperator):
     """The base class for operators that launch AutoML jobs on VertexAI."""
 
     def __init__(
         self,
         *,
         project_id: str,
         region: str,
@@ -539,15 +539,15 @@
         else:
             result = model  # type: ignore
         self.xcom_push(context, key="training_id", value=training_id)
         VertexAITrainingLink.persist(context=context, task_instance=self, training_id=training_id)
         return result
 
 
-class DeleteAutoMLTrainingJobOperator(BaseOperator):
+class DeleteAutoMLTrainingJobOperator(GoogleCloudBaseOperator):
     """Deletes an AutoMLForecastingTrainingJob, AutoMLImageTrainingJob, AutoMLTabularTrainingJob,
     AutoMLTextTrainingJob, or AutoMLVideoTrainingJob.
     """
 
     template_fields = ("training_pipeline", "region", "project_id", "impersonation_chain")
 
     def __init__(
@@ -597,15 +597,15 @@
             )
             hook.wait_for_operation(timeout=self.timeout, operation=training_pipeline_operation)
             self.log.info("Training pipeline was deleted.")
         except NotFound:
             self.log.info("The Training Pipeline ID %s does not exist.", self.training_pipeline)
 
 
-class ListAutoMLTrainingJobOperator(BaseOperator):
+class ListAutoMLTrainingJobOperator(GoogleCloudBaseOperator):
     """Lists AutoMLForecastingTrainingJob, AutoMLImageTrainingJob, AutoMLTabularTrainingJob,
     AutoMLTextTrainingJob, or AutoMLVideoTrainingJob in a Location.
     """
 
     template_fields = (
         "region",
         "project_id",
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/batch_prediction_job.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/batch_prediction_job.py`

 * *Files 2% similar despite different names*

```diff
@@ -31,26 +31,26 @@
 
 from google.api_core.exceptions import NotFound
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.aiplatform import Model, explain
 from google.cloud.aiplatform_v1.types import BatchPredictionJob
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.vertex_ai.batch_prediction_job import BatchPredictionJobHook
 from airflow.providers.google.cloud.links.vertex_ai import (
     VertexAIBatchPredictionJobLink,
     VertexAIBatchPredictionJobListLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CreateBatchPredictionJobOperator(BaseOperator):
+class CreateBatchPredictionJobOperator(GoogleCloudBaseOperator):
     """
     Creates a BatchPredictionJob. A BatchPredictionJob once created will right away be attempted to start.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param batch_prediction_job: Required. The BatchPredictionJob to create.
     :param job_display_name: Required. The user-defined name of the BatchPredictionJob. The name can be
@@ -269,15 +269,15 @@
         Callback called when the operator is killed.
         Cancel any running job.
         """
         if self.hook:
             self.hook.cancel_batch_prediction_job()
 
 
-class DeleteBatchPredictionJobOperator(BaseOperator):
+class DeleteBatchPredictionJobOperator(GoogleCloudBaseOperator):
     """
     Deletes a BatchPredictionJob. Can only be called on jobs that already finished.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param batch_prediction_job_id: The ID of the BatchPredictionJob resource to be deleted.
     :param retry: Designation of what errors, if any, should be retried.
@@ -347,15 +347,15 @@
             )
             hook.wait_for_operation(timeout=self.timeout, operation=operation)
             self.log.info("Batch prediction job was deleted.")
         except NotFound:
             self.log.info("The Batch prediction job %s does not exist.", self.batch_prediction_job_id)
 
 
-class GetBatchPredictionJobOperator(BaseOperator):
+class GetBatchPredictionJobOperator(GoogleCloudBaseOperator):
     """
     Gets a BatchPredictionJob
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param batch_prediction_job: Required. The name of the BatchPredictionJob resource.
     :param retry: Designation of what errors, if any, should be retried.
@@ -429,15 +429,15 @@
                 context=context, task_instance=self, batch_prediction_job_id=self.batch_prediction_job
             )
             return BatchPredictionJob.to_dict(result)
         except NotFound:
             self.log.info("The Batch prediction job %s does not exist.", self.batch_prediction_job)
 
 
-class ListBatchPredictionJobsOperator(BaseOperator):
+class ListBatchPredictionJobsOperator(GoogleCloudBaseOperator):
     """
     Lists BatchPredictionJobs in a Location.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param filter: The standard list filter.
         Supported fields:
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/custom_job.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/custom_job.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,27 +24,27 @@
 from google.api_core.exceptions import NotFound
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.aiplatform.models import Model
 from google.cloud.aiplatform_v1.types.dataset import Dataset
 from google.cloud.aiplatform_v1.types.training_pipeline import TrainingPipeline
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.vertex_ai.custom_job import CustomJobHook
 from airflow.providers.google.cloud.links.vertex_ai import (
     VertexAIModelLink,
     VertexAITrainingLink,
     VertexAITrainingPipelinesLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CustomTrainingJobBaseOperator(BaseOperator):
+class CustomTrainingJobBaseOperator(GoogleCloudBaseOperator):
     """The base class for operators that launch Custom jobs on VertexAI."""
 
     def __init__(
         self,
         *,
         project_id: str,
         region: str,
@@ -1214,15 +1214,15 @@
         Callback called when the operator is killed.
         Cancel any running job.
         """
         if self.hook:
             self.hook.cancel_job()
 
 
-class DeleteCustomTrainingJobOperator(BaseOperator):
+class DeleteCustomTrainingJobOperator(GoogleCloudBaseOperator):
     """Deletes a CustomTrainingJob, CustomPythonTrainingJob, or CustomContainerTrainingJob.
 
     :param training_pipeline_id: Required. The name of the TrainingPipeline resource to be deleted.
     :param custom_job_id: Required. The name of the CustomJob to delete.
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param retry: Designation of what errors, if any, should be retried.
@@ -1307,15 +1307,15 @@
             )
             hook.wait_for_operation(timeout=self.timeout, operation=custom_job_operation)
             self.log.info("Custom job was deleted.")
         except NotFound:
             self.log.info("The Custom Job ID %s does not exist.", self.custom_job)
 
 
-class ListCustomTrainingJobOperator(BaseOperator):
+class ListCustomTrainingJobOperator(GoogleCloudBaseOperator):
     """Lists CustomTrainingJob, CustomPythonTrainingJob, or CustomContainerTrainingJob in a Location.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param filter: Optional. The standard list filter. Supported fields:
 
         -  ``display_name`` supports = and !=.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/dataset.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,23 +23,23 @@
 
 from google.api_core.exceptions import NotFound
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.aiplatform_v1.types import Dataset, ExportDataConfig, ImportDataConfig
 from google.protobuf.field_mask_pb2 import FieldMask
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.vertex_ai.dataset import DatasetHook
 from airflow.providers.google.cloud.links.vertex_ai import VertexAIDatasetLink, VertexAIDatasetListLink
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CreateDatasetOperator(BaseOperator):
+class CreateDatasetOperator(GoogleCloudBaseOperator):
     """
     Creates a Dataset.
 
     :param project_id: Required. The ID of the Google Cloud project the cluster belongs to.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param dataset:  Required. The Dataset to create. This corresponds to the ``dataset`` field on the
         ``request`` instance; if ``request`` is provided, this should not be set.
@@ -115,15 +115,15 @@
         self.log.info("Dataset was created. Dataset id: %s", dataset_id)
 
         self.xcom_push(context, key="dataset_id", value=dataset_id)
         VertexAIDatasetLink.persist(context=context, task_instance=self, dataset_id=dataset_id)
         return dataset
 
 
-class GetDatasetOperator(BaseOperator):
+class GetDatasetOperator(GoogleCloudBaseOperator):
     """
     Get a Dataset.
 
     :param project_id: Required. The ID of the Google Cloud project the cluster belongs to.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param dataset_id: Required. The ID of the Dataset to get.
     :param retry: Designation of what errors, if any, should be retried.
@@ -198,15 +198,15 @@
             VertexAIDatasetLink.persist(context=context, task_instance=self, dataset_id=self.dataset_id)
             self.log.info("Dataset was gotten.")
             return Dataset.to_dict(dataset_obj)
         except NotFound:
             self.log.info("The Dataset ID %s does not exist.", self.dataset_id)
 
 
-class DeleteDatasetOperator(BaseOperator):
+class DeleteDatasetOperator(GoogleCloudBaseOperator):
     """
     Deletes a Dataset.
 
     :param project_id: Required. The ID of the Google Cloud project the cluster belongs to.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param dataset_id: Required. The ID of the Dataset to delete.
     :param retry: Designation of what errors, if any, should be retried.
@@ -276,15 +276,15 @@
             )
             hook.wait_for_operation(timeout=self.timeout, operation=operation)
             self.log.info("Dataset was deleted.")
         except NotFound:
             self.log.info("The Dataset ID %s does not exist.", self.dataset_id)
 
 
-class ExportDataOperator(BaseOperator):
+class ExportDataOperator(GoogleCloudBaseOperator):
     """
     Exports data from a Dataset.
 
     :param project_id: Required. The ID of the Google Cloud project the cluster belongs to.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param dataset_id: Required. The ID of the Dataset to delete.
     :param export_config:  Required. The desired output location.
@@ -355,15 +355,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         hook.wait_for_operation(timeout=self.timeout, operation=operation)
         self.log.info("Export was done successfully")
 
 
-class ImportDataOperator(BaseOperator):
+class ImportDataOperator(GoogleCloudBaseOperator):
     """
     Imports data into a Dataset.
 
     :param project_id: Required. The ID of the Google Cloud project the cluster belongs to.
     :param region: Required. The Cloud Dataproc region in which to handle the request.
     :param dataset_id: Required. The ID of the Dataset to delete.
     :param import_configs:  Required. The desired input locations. The contents of all input locations will be
@@ -435,15 +435,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         hook.wait_for_operation(timeout=self.timeout, operation=operation)
         self.log.info("Import was done successfully")
 
 
-class ListDatasetsOperator(BaseOperator):
+class ListDatasetsOperator(GoogleCloudBaseOperator):
     """
     Lists Datasets in a Location.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param filter: The standard list filter.
     :param page_size: The standard list page size.
@@ -526,15 +526,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         VertexAIDatasetListLink.persist(context=context, task_instance=self)
         return [Dataset.to_dict(result) for result in results]
 
 
-class UpdateDatasetOperator(BaseOperator):
+class UpdateDatasetOperator(GoogleCloudBaseOperator):
     """
     Updates a Dataset.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param dataset_id: Required. The ID of the Dataset to update.
     :param dataset:  Required. The Dataset which replaces the resource on the server.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/endpoint_service.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/endpoint_service.py`

 * *Files 2% similar despite different names*

```diff
@@ -33,27 +33,27 @@
 
 from google.api_core.exceptions import NotFound
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.aiplatform_v1.types import DeployedModel, Endpoint, endpoint_service
 from google.protobuf.field_mask_pb2 import FieldMask
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.vertex_ai.endpoint_service import EndpointServiceHook
 from airflow.providers.google.cloud.links.vertex_ai import (
     VertexAIEndpointLink,
     VertexAIEndpointListLink,
     VertexAIModelLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CreateEndpointOperator(BaseOperator):
+class CreateEndpointOperator(GoogleCloudBaseOperator):
     """
     Creates an Endpoint.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param endpoint: Required. The Endpoint to create.
     :param endpoint_id: The ID of Endpoint. This value should be 1-10 characters, and valid characters
@@ -133,15 +133,15 @@
         self.log.info("Endpoint was created. Endpoint ID: %s", endpoint_id)
 
         self.xcom_push(context, key="endpoint_id", value=endpoint_id)
         VertexAIEndpointLink.persist(context=context, task_instance=self, endpoint_id=endpoint_id)
         return endpoint
 
 
-class DeleteEndpointOperator(BaseOperator):
+class DeleteEndpointOperator(GoogleCloudBaseOperator):
     """
     Deletes an Endpoint.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param endpoint_id: Required. The Endpoint ID to delete.
     :param retry: Designation of what errors, if any, should be retried.
@@ -211,15 +211,15 @@
             )
             hook.wait_for_operation(timeout=self.timeout, operation=operation)
             self.log.info("Endpoint was deleted.")
         except NotFound:
             self.log.info("The Endpoint ID %s does not exist.", self.endpoint_id)
 
 
-class DeployModelOperator(BaseOperator):
+class DeployModelOperator(GoogleCloudBaseOperator):
     """
     Deploys a Model into this Endpoint, creating a DeployedModel within it.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param endpoint_id:  Required. The name of the Endpoint resource into which to deploy a Model. Format:
         ``projects/{project}/locations/{location}/endpoints/{endpoint}``
@@ -316,15 +316,15 @@
         self.log.info("Model was deployed. Deployed Model ID: %s", deployed_model_id)
 
         self.xcom_push(context, key="deployed_model_id", value=deployed_model_id)
         VertexAIModelLink.persist(context=context, task_instance=self, model_id=deployed_model_id)
         return deploy_model
 
 
-class GetEndpointOperator(BaseOperator):
+class GetEndpointOperator(GoogleCloudBaseOperator):
     """
     Gets an Endpoint.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param endpoint_id: Required. The Endpoint ID to get.
     :param retry: Designation of what errors, if any, should be retried.
@@ -396,15 +396,15 @@
             VertexAIEndpointLink.persist(context=context, task_instance=self, endpoint_id=self.endpoint_id)
             self.log.info("Endpoint was gotten.")
             return Endpoint.to_dict(endpoint_obj)
         except NotFound:
             self.log.info("The Endpoint ID %s does not exist.", self.endpoint_id)
 
 
-class ListEndpointsOperator(BaseOperator):
+class ListEndpointsOperator(GoogleCloudBaseOperator):
     """
     Lists Endpoints in a Location.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param filter: The standard list filter.
         Supported fields:
@@ -503,15 +503,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         VertexAIEndpointListLink.persist(context=context, task_instance=self)
         return [Endpoint.to_dict(result) for result in results]
 
 
-class UndeployModelOperator(BaseOperator):
+class UndeployModelOperator(GoogleCloudBaseOperator):
     """
     Undeploys a Model from an Endpoint, removing a DeployedModel from it, and freeing all resources it's
     using.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param endpoint_id:  Required. The name of the Endpoint resource from which to undeploy a Model. Format:
@@ -593,15 +593,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         hook.wait_for_operation(timeout=self.timeout, operation=operation)
         self.log.info("DeployedModel was removed successfully")
 
 
-class UpdateEndpointOperator(BaseOperator):
+class UpdateEndpointOperator(GoogleCloudBaseOperator):
     """
     Updates an Endpoint.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param endpoint_id: Required. The ID of the Endpoint to update.
     :param endpoint:  Required. The Endpoint which replaces the resource on the server.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/hyperparameter_tuning_job.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/hyperparameter_tuning_job.py`

 * *Files 3% similar despite different names*

```diff
@@ -32,28 +32,28 @@
 
 from google.api_core.exceptions import NotFound
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.aiplatform import gapic, hyperparameter_tuning
 from google.cloud.aiplatform_v1.types import HyperparameterTuningJob
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.vertex_ai.hyperparameter_tuning_job import (
     HyperparameterTuningJobHook,
 )
 from airflow.providers.google.cloud.links.vertex_ai import (
     VertexAIHyperparameterTuningJobListLink,
     VertexAITrainingLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CreateHyperparameterTuningJobOperator(BaseOperator):
+class CreateHyperparameterTuningJobOperator(GoogleCloudBaseOperator):
     """
     Create Hyperparameter Tuning job
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param display_name: Required. The user-defined name of the HyperparameterTuningJob. The name can be
         up to 128 characters long and can be consist of any UTF-8 characters.
@@ -279,15 +279,15 @@
         Callback called when the operator is killed.
         Cancel any running job.
         """
         if self.hook:
             self.hook.cancel_hyperparameter_tuning_job()
 
 
-class GetHyperparameterTuningJobOperator(BaseOperator):
+class GetHyperparameterTuningJobOperator(GoogleCloudBaseOperator):
     """
     Gets a HyperparameterTuningJob
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param hyperparameter_tuning_job_id: Required. The name of the HyperparameterTuningJob resource.
     :param retry: Designation of what errors, if any, should be retried.
@@ -363,15 +363,15 @@
             return HyperparameterTuningJob.to_dict(result)
         except NotFound:
             self.log.info(
                 "The Hyperparameter tuning job %s does not exist.", self.hyperparameter_tuning_job_id
             )
 
 
-class DeleteHyperparameterTuningJobOperator(BaseOperator):
+class DeleteHyperparameterTuningJobOperator(GoogleCloudBaseOperator):
     """
     Deletes a HyperparameterTuningJob.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param hyperparameter_tuning_job_id: Required. The name of the HyperparameterTuningJob resource to be
         deleted.
@@ -431,15 +431,15 @@
             self.log.info("Hyperparameter Tuning job was deleted.")
         except NotFound:
             self.log.info(
                 "The Hyperparameter Tuning Job ID %s does not exist.", self.hyperparameter_tuning_job_id
             )
 
 
-class ListHyperparameterTuningJobOperator(BaseOperator):
+class ListHyperparameterTuningJobOperator(GoogleCloudBaseOperator):
     """
     Lists HyperparameterTuningJobs in a Location.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param filter: The standard list filter.
         Supported fields:
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vertex_ai/model_service.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vertex_ai/model_service.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,27 +28,27 @@
 from typing import TYPE_CHECKING, Sequence
 
 from google.api_core.exceptions import NotFound
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.aiplatform_v1.types import Model, model_service
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.vertex_ai.model_service import ModelServiceHook
 from airflow.providers.google.cloud.links.vertex_ai import (
     VertexAIModelExportLink,
     VertexAIModelLink,
     VertexAIModelListLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class DeleteModelOperator(BaseOperator):
+class DeleteModelOperator(GoogleCloudBaseOperator):
     """
     Deletes a Model.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param model_id: Required. The name of the Model resource to be deleted.
     :param retry: Designation of what errors, if any, should be retried.
@@ -118,15 +118,15 @@
             )
             hook.wait_for_operation(timeout=self.timeout, operation=operation)
             self.log.info("Model was deleted.")
         except NotFound:
             self.log.info("The Model ID %s does not exist.", self.model_id)
 
 
-class ExportModelOperator(BaseOperator):
+class ExportModelOperator(GoogleCloudBaseOperator):
     """
     Exports a trained, exportable Model to a location specified by the user.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param model_id: Required. The resource name of the Model to export.
     :param output_config:  Required. The desired output location and configuration.
@@ -202,15 +202,15 @@
             hook.wait_for_operation(timeout=self.timeout, operation=operation)
             VertexAIModelExportLink.persist(context=context, task_instance=self)
             self.log.info("Model was exported.")
         except NotFound:
             self.log.info("The Model ID %s does not exist.", self.model_id)
 
 
-class ListModelsOperator(BaseOperator):
+class ListModelsOperator(GoogleCloudBaseOperator):
     r"""
     Lists Models in a Location.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param retry: Designation of what errors, if any, should be retried.
     :param filter: An expression for filtering the results of the request. For field names both
@@ -305,15 +305,15 @@
             timeout=self.timeout,
             metadata=self.metadata,
         )
         VertexAIModelListLink.persist(context=context, task_instance=self)
         return [Model.to_dict(result) for result in results]
 
 
-class UploadModelOperator(BaseOperator):
+class UploadModelOperator(GoogleCloudBaseOperator):
     """
     Uploads a Model artifact into Vertex AI.
 
     :param project_id: Required. The ID of the Google Cloud project that the service belongs to.
     :param region: Required. The ID of the Google Cloud region that the service belongs to.
     :param model:  Required. The Model to create.
     :param retry: Designation of what errors, if any, should be retried.
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/video_intelligence.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/video_intelligence.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,22 +22,22 @@
 
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.videointelligence_v1 import enums
 from google.cloud.videointelligence_v1.types import VideoContext
 from google.protobuf.json_format import MessageToDict
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.video_intelligence import CloudVideoIntelligenceHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class CloudVideoIntelligenceDetectVideoLabelsOperator(BaseOperator):
+class CloudVideoIntelligenceDetectVideoLabelsOperator(GoogleCloudBaseOperator):
     """
     Performs video annotation, annotating video labels.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVideoIntelligenceDetectVideoLabelsOperator`.
 
@@ -119,15 +119,15 @@
         )
         self.log.info("Processing video for label annotations")
         result = MessageToDict(operation.result())
         self.log.info("Finished processing.")
         return result
 
 
-class CloudVideoIntelligenceDetectVideoExplicitContentOperator(BaseOperator):
+class CloudVideoIntelligenceDetectVideoExplicitContentOperator(GoogleCloudBaseOperator):
     """
     Performs video annotation, annotating explicit content.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVideoIntelligenceDetectVideoExplicitContentOperator`
 
@@ -209,15 +209,15 @@
         )
         self.log.info("Processing video for explicit content annotations")
         result = MessageToDict(operation.result())
         self.log.info("Finished processing.")
         return result
 
 
-class CloudVideoIntelligenceDetectVideoShotsOperator(BaseOperator):
+class CloudVideoIntelligenceDetectVideoShotsOperator(GoogleCloudBaseOperator):
     """
     Performs video annotation, annotating video shots.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVideoIntelligenceDetectVideoShotsOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/vision.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/vision.py`

 * *Files 4% similar despite different names*

```diff
@@ -29,25 +29,25 @@
     FieldMask,
     Image,
     Product,
     ProductSet,
     ReferenceImage,
 )
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.vision import CloudVisionHook
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
 MetaData = Sequence[Tuple[str, str]]
 
 
-class CloudVisionCreateProductSetOperator(BaseOperator):
+class CloudVisionCreateProductSetOperator(GoogleCloudBaseOperator):
     """
     Creates a new ProductSet resource.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionCreateProductSetOperator`
 
@@ -132,15 +132,15 @@
             self.log.info(
                 "Product set with id %s already exists. Exiting from the create operation.",
                 self.product_set_id,
             )
             return self.product_set_id
 
 
-class CloudVisionGetProductSetOperator(BaseOperator):
+class CloudVisionGetProductSetOperator(GoogleCloudBaseOperator):
     """
     Gets information associated with a ProductSet.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionGetProductSetOperator`
 
@@ -210,15 +210,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionUpdateProductSetOperator(BaseOperator):
+class CloudVisionUpdateProductSetOperator(GoogleCloudBaseOperator):
     """
     Makes changes to a `ProductSet` resource. Only display_name can be updated currently.
 
     .. note:: To locate the `ProductSet` resource, its `name` in the form
         `projects/PROJECT_ID/locations/LOC_ID/productSets/PRODUCT_SET_ID` is necessary.
 
     You can provide the `name` directly as an attribute of the `product_set` object.
@@ -311,15 +311,15 @@
             update_mask=self.update_mask,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionDeleteProductSetOperator(BaseOperator):
+class CloudVisionDeleteProductSetOperator(GoogleCloudBaseOperator):
     """
     Permanently deletes a `ProductSet`. `Products` and `ReferenceImages` in the
     `ProductSet` are not deleted. The actual image files are not deleted from Google
     Cloud Storage.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -391,15 +391,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionCreateProductOperator(BaseOperator):
+class CloudVisionCreateProductOperator(GoogleCloudBaseOperator):
     """
     Creates and returns a new product resource.
 
     Possible errors regarding the `Product` object provided:
 
     - Returns `INVALID_ARGUMENT` if `display_name` is missing or longer than 4096 characters.
     - Returns `INVALID_ARGUMENT` if `description` is longer than 4096 characters.
@@ -489,15 +489,15 @@
         except AlreadyExists:
             self.log.info(
                 "Product with id %s already exists. Exiting from the create operation.", self.product_id
             )
             return self.product_id
 
 
-class CloudVisionGetProductOperator(BaseOperator):
+class CloudVisionGetProductOperator(GoogleCloudBaseOperator):
     """
     Gets information associated with a `Product`.
 
     Possible errors:
 
     - Returns `NOT_FOUND` if the `Product` does not exist.
 
@@ -571,15 +571,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionUpdateProductOperator(BaseOperator):
+class CloudVisionUpdateProductOperator(GoogleCloudBaseOperator):
     """
     Makes changes to a Product resource. Only the display_name, description, and labels fields can be
     updated right now.
 
     If labels are updated, the change will not be reflected in queries until the next index time.
 
     .. note:: To locate the `Product` resource, its `name` in the form
@@ -683,15 +683,15 @@
             update_mask=self.update_mask,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionDeleteProductOperator(BaseOperator):
+class CloudVisionDeleteProductOperator(GoogleCloudBaseOperator):
     """
     Permanently deletes a product and its reference images.
 
     Metadata of the product and all its images will be deleted right away, but search queries against
     ProductSets containing the product may still work until all related caches are refreshed.
 
     Possible errors:
@@ -768,15 +768,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionImageAnnotateOperator(BaseOperator):
+class CloudVisionImageAnnotateOperator(GoogleCloudBaseOperator):
     """
     Run image detection and annotation for an image or a batch of images.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionImageAnnotateOperator`
 
@@ -836,15 +836,15 @@
             response = hook.batch_annotate_images(
                 requests=self.request, retry=self.retry, timeout=self.timeout
             )
 
         return response
 
 
-class CloudVisionCreateReferenceImageOperator(BaseOperator):
+class CloudVisionCreateReferenceImageOperator(GoogleCloudBaseOperator):
     """
     Creates and returns a new ReferenceImage ID resource.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionCreateReferenceImageOperator`
 
@@ -937,15 +937,15 @@
             self.log.info(
                 "ReferenceImage with id %s already exists. Exiting from the create operation.",
                 self.product_id,
             )
             return self.reference_image_id
 
 
-class CloudVisionDeleteReferenceImageOperator(BaseOperator):
+class CloudVisionDeleteReferenceImageOperator(GoogleCloudBaseOperator):
     """
     Deletes a ReferenceImage ID resource.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionDeleteReferenceImageOperator`
 
@@ -1023,15 +1023,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionAddProductToProductSetOperator(BaseOperator):
+class CloudVisionAddProductToProductSetOperator(GoogleCloudBaseOperator):
     """
     Adds a Product to the specified ProductSet. If the Product is already present, no change is made.
 
     One Product can be added to at most 100 ProductSets.
 
     Possible errors:
 
@@ -1112,15 +1112,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionRemoveProductFromProductSetOperator(BaseOperator):
+class CloudVisionRemoveProductFromProductSetOperator(GoogleCloudBaseOperator):
     """
     Removes a Product from the specified ProductSet.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionRemoveProductFromProductSetOperator`
 
@@ -1195,15 +1195,15 @@
             project_id=self.project_id,
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
 
 
-class CloudVisionDetectTextOperator(BaseOperator):
+class CloudVisionDetectTextOperator(GoogleCloudBaseOperator):
     """
     Detects Text in the image
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionDetectTextOperator`
 
@@ -1277,15 +1277,15 @@
             max_results=self.max_results,
             retry=self.retry,
             timeout=self.timeout,
             additional_properties=self.additional_properties,
         )
 
 
-class CloudVisionTextDetectOperator(BaseOperator):
+class CloudVisionTextDetectOperator(GoogleCloudBaseOperator):
     """
     Detects Document Text in the image
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionTextDetectOperator`
 
@@ -1358,15 +1358,15 @@
             max_results=self.max_results,
             retry=self.retry,
             timeout=self.timeout,
             additional_properties=self.additional_properties,
         )
 
 
-class CloudVisionDetectImageLabelsOperator(BaseOperator):
+class CloudVisionDetectImageLabelsOperator(GoogleCloudBaseOperator):
     """
     Detects Document Text in the image
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionDetectImageLabelsOperator`
 
@@ -1429,15 +1429,15 @@
             max_results=self.max_results,
             retry=self.retry,
             timeout=self.timeout,
             additional_properties=self.additional_properties,
         )
 
 
-class CloudVisionDetectImageSafeSearchOperator(BaseOperator):
+class CloudVisionDetectImageSafeSearchOperator(GoogleCloudBaseOperator):
     """
     Detects Document Text in the image
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:CloudVisionDetectImageSafeSearchOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/operators/workflows.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/operators/workflows.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,27 +27,27 @@
 from google.api_core.exceptions import AlreadyExists
 from google.api_core.gapic_v1.method import DEFAULT, _MethodDefault
 from google.api_core.retry import Retry
 from google.cloud.workflows.executions_v1beta import Execution
 from google.cloud.workflows_v1beta import Workflow
 from google.protobuf.field_mask_pb2 import FieldMask
 
-from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.workflows import WorkflowsHook
 from airflow.providers.google.cloud.links.workflows import (
     WorkflowsExecutionLink,
     WorkflowsListOfWorkflowsLink,
     WorkflowsWorkflowDetailsLink,
 )
+from airflow.providers.google.cloud.operators.cloud_base import GoogleCloudBaseOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class WorkflowsCreateWorkflowOperator(BaseOperator):
+class WorkflowsCreateWorkflowOperator(GoogleCloudBaseOperator):
     """
     Creates a new workflow. If a workflow with the specified name
     already exists in the specified project and location, the long
     running operation will return
     [ALREADY_EXISTS][google.rpc.Code.ALREADY_EXISTS] error.
 
     .. seealso::
@@ -148,15 +148,15 @@
             workflow_id=self.workflow_id,
             project_id=self.project_id or hook.project_id,
         )
 
         return Workflow.to_dict(workflow)
 
 
-class WorkflowsUpdateWorkflowOperator(BaseOperator):
+class WorkflowsUpdateWorkflowOperator(GoogleCloudBaseOperator):
     """
     Updates an existing workflow.
     Running this method has no impact on already running
     executions of the workflow. A new revision of the
     workflow may be created as a result of a successful
     update operation. In that case, such revision will be
     used in new workflow executions.
@@ -235,15 +235,15 @@
             workflow_id=self.workflow_id,
             project_id=self.project_id or hook.project_id,
         )
 
         return Workflow.to_dict(workflow)
 
 
-class WorkflowsDeleteWorkflowOperator(BaseOperator):
+class WorkflowsDeleteWorkflowOperator(GoogleCloudBaseOperator):
     """
     Deletes a workflow with the specified name.
     This method also cancels and deletes all running
     executions of the workflow.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
@@ -295,15 +295,15 @@
             retry=self.retry,
             timeout=self.timeout,
             metadata=self.metadata,
         )
         operation.result()
 
 
-class WorkflowsListWorkflowsOperator(BaseOperator):
+class WorkflowsListWorkflowsOperator(GoogleCloudBaseOperator):
     """
     Lists Workflows in a given project and location.
     The default order is not specified.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:WorkflowsListWorkflowsOperator`
@@ -369,15 +369,15 @@
             task_instance=self,
             project_id=self.project_id or hook.project_id,
         )
 
         return [Workflow.to_dict(w) for w in workflows_iter]
 
 
-class WorkflowsGetWorkflowOperator(BaseOperator):
+class WorkflowsGetWorkflowOperator(GoogleCloudBaseOperator):
     """
     Gets details of a single Workflow.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:WorkflowsGetWorkflowOperator`
 
@@ -437,15 +437,15 @@
             workflow_id=self.workflow_id,
             project_id=self.project_id or hook.project_id,
         )
 
         return Workflow.to_dict(workflow)
 
 
-class WorkflowsCreateExecutionOperator(BaseOperator):
+class WorkflowsCreateExecutionOperator(GoogleCloudBaseOperator):
     """
     Creates a new execution using the latest revision of
     the given workflow.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:WorkflowsCreateExecutionOperator`
@@ -514,15 +514,15 @@
             execution_id=execution_id,
             project_id=self.project_id or hook.project_id,
         )
 
         return Execution.to_dict(execution)
 
 
-class WorkflowsCancelExecutionOperator(BaseOperator):
+class WorkflowsCancelExecutionOperator(GoogleCloudBaseOperator):
     """
     Cancels an execution using the given ``workflow_id`` and ``execution_id``.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:WorkflowsCancelExecutionOperator`
 
@@ -587,15 +587,15 @@
             execution_id=self.execution_id,
             project_id=self.project_id or hook.project_id,
         )
 
         return Execution.to_dict(execution)
 
 
-class WorkflowsListExecutionsOperator(BaseOperator):
+class WorkflowsListExecutionsOperator(GoogleCloudBaseOperator):
     """
     Returns a list of executions which belong to the
     workflow with the given name. The method returns
     executions of all workflow revisions. Returned
     executions are ordered by their start time (newest
     first).
 
@@ -663,15 +663,15 @@
             workflow_id=self.workflow_id,
             project_id=self.project_id or hook.project_id,
         )
 
         return [Execution.to_dict(e) for e in execution_iter if e.start_time > self.start_date_filter]
 
 
-class WorkflowsGetExecutionOperator(BaseOperator):
+class WorkflowsGetExecutionOperator(GoogleCloudBaseOperator):
     """
     Returns an execution for the given ``workflow_id`` and ``execution_id``.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:WorkflowsGetExecutionOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/secrets/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/secrets/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/secrets/secret_manager.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/secrets/secret_manager.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/bigquery.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/display_video.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-#
 # Licensed to the Apache Software Foundation (ASF) under one
 # or more contributor license agreements.  See the NOTICE file
 # distributed with this work for additional information
 # regarding copyright ownership.  The ASF licenses this file
 # to you under the Apache License, Version 2.0 (the
 # "License"); you may not use this file except in compliance
 # with the License.  You may obtain a copy of the License at
@@ -11,236 +10,216 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an
 # "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 # KIND, either express or implied.  See the License for the
 # specific language governing permissions and limitations
 # under the License.
-"""This module contains Google BigQuery sensors."""
+"""Sensor for detecting the completion of DV360 reports."""
 from __future__ import annotations
 
 import warnings
-from datetime import timedelta
-from typing import TYPE_CHECKING, Any, Sequence
+from typing import TYPE_CHECKING, Sequence
 
-from airflow.exceptions import AirflowException
-from airflow.providers.google.cloud.hooks.bigquery import BigQueryHook
-from airflow.providers.google.cloud.triggers.bigquery import BigQueryTableExistenceTrigger
+from airflow import AirflowException
+from airflow.providers.google.marketing_platform.hooks.display_video import GoogleDisplayVideo360Hook
 from airflow.sensors.base import BaseSensorOperator
 
 if TYPE_CHECKING:
     from airflow.utils.context import Context
 
 
-class BigQueryTableExistenceSensor(BaseSensorOperator):
+class GoogleDisplayVideo360ReportSensor(BaseSensorOperator):
     """
-    Checks for the existence of a table in Google Bigquery.
+    Sensor for detecting the completion of DV360 reports.
+
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:GoogleDisplayVideo360ReportSensor`
 
-    :param project_id: The Google cloud project in which to look for the table.
-        The connection supplied to the hook must provide
-        access to the specified project.
-    :param dataset_id: The name of the dataset in which to look for the table.
-        storage bucket.
-    :param table_id: The name of the table to check the existence of.
-    :param gcp_conn_id: (Optional) The connection ID used to connect to Google Cloud.
+    :param report_id: Report ID to delete.
+    :param api_version: The version of the api that will be requested for example 'v3'.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
     :param delegate_to: The account to impersonate using domain-wide delegation of authority,
         if any. For this to work, the service account making the request must have
         domain-wide delegation enabled.
     :param impersonation_chain: Optional service account to impersonate using short-term
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     """
 
     template_fields: Sequence[str] = (
-        "project_id",
-        "dataset_id",
-        "table_id",
+        "report_id",
         "impersonation_chain",
     )
-    ui_color = "#f0eee4"
 
     def __init__(
         self,
         *,
-        project_id: str,
-        dataset_id: str,
-        table_id: str,
+        report_id: str,
+        api_version: str = "v1",
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
-
-        self.project_id = project_id
-        self.dataset_id = dataset_id
-        self.table_id = table_id
+        warnings.warn(
+            "This operator is deprecated. Please use `GoogleDisplayVideo360RunQuerySensor`",
+            DeprecationWarning,
+        )
+        self.report_id = report_id
+        self.api_version = api_version
         self.gcp_conn_id = gcp_conn_id
-        if delegate_to:
-            warnings.warn(
-                "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
-            )
         self.delegate_to = delegate_to
         self.impersonation_chain = impersonation_chain
 
     def poke(self, context: Context) -> bool:
-        table_uri = f"{self.project_id}:{self.dataset_id}.{self.table_id}"
-        self.log.info("Sensor checks existence of table: %s", table_uri)
-        hook = BigQueryHook(
+        hook = GoogleDisplayVideo360Hook(
             gcp_conn_id=self.gcp_conn_id,
             delegate_to=self.delegate_to,
+            api_version=self.api_version,
             impersonation_chain=self.impersonation_chain,
         )
-        return hook.table_exists(
-            project_id=self.project_id, dataset_id=self.dataset_id, table_id=self.table_id
-        )
 
+        response = hook.get_query(query_id=self.report_id)
+        if response and not response.get("metadata", {}).get("running"):
+            return True
+        return False
 
-class BigQueryTablePartitionExistenceSensor(BaseSensorOperator):
+
+class GoogleDisplayVideo360GetSDFDownloadOperationSensor(BaseSensorOperator):
     """
-    Checks for the existence of a partition within a table in Google Bigquery.
+    Sensor for detecting the completion of SDF operation.
+
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:GoogleDisplayVideo360GetSDFDownloadOperationSensor`
 
-    :param project_id: The Google cloud project in which to look for the table.
-        The connection supplied to the hook must provide
-        access to the specified project.
-    :param dataset_id: The name of the dataset in which to look for the table.
-        storage bucket.
-    :param table_id: The name of the table to check the existence of.
-    :param partition_id: The name of the partition to check the existence of.
-    :param gcp_conn_id: (Optional) The connection ID used to connect to Google Cloud.
-    :param delegate_to: The account to impersonate, if any.
-        For this to work, the service account making the request must
-        have domain-wide delegation enabled.
+    :param operation_name: The name of the operation resource
+    :param api_version: The version of the api that will be requested for example 'v1'.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
     :param impersonation_chain: Optional service account to impersonate using short-term
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
+
     """
 
     template_fields: Sequence[str] = (
-        "project_id",
-        "dataset_id",
-        "table_id",
-        "partition_id",
+        "operation_name",
         "impersonation_chain",
     )
-    ui_color = "#f0eee4"
 
     def __init__(
         self,
-        *,
-        project_id: str,
-        dataset_id: str,
-        table_id: str,
-        partition_id: str,
+        operation_name: str,
+        api_version: str = "v1",
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
+        mode: str = "reschedule",
+        poke_interval: int = 60 * 5,
         impersonation_chain: str | Sequence[str] | None = None,
+        *args,
         **kwargs,
     ) -> None:
-        super().__init__(**kwargs)
-
-        self.project_id = project_id
-        self.dataset_id = dataset_id
-        self.table_id = table_id
-        self.partition_id = partition_id
+        super().__init__(*args, **kwargs)
+        self.mode = mode
+        self.poke_interval = poke_interval
+        self.operation_name = operation_name
+        self.api_version = api_version
         self.gcp_conn_id = gcp_conn_id
-        if delegate_to:
-            warnings.warn(
-                "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
-            )
         self.delegate_to = delegate_to
         self.impersonation_chain = impersonation_chain
 
     def poke(self, context: Context) -> bool:
-        table_uri = f"{self.project_id}:{self.dataset_id}.{self.table_id}"
-        self.log.info('Sensor checks existence of partition: "%s" in table: %s', self.partition_id, table_uri)
-        hook = BigQueryHook(
+        hook = GoogleDisplayVideo360Hook(
             gcp_conn_id=self.gcp_conn_id,
             delegate_to=self.delegate_to,
+            api_version=self.api_version,
             impersonation_chain=self.impersonation_chain,
         )
-        return hook.table_partition_exists(
-            project_id=self.project_id,
-            dataset_id=self.dataset_id,
-            table_id=self.table_id,
-            partition_id=self.partition_id,
-        )
+        operation = hook.get_sdf_download_operation(operation_name=self.operation_name)
 
+        if "error" in operation:
+            raise AirflowException(f'The operation finished in error with {operation["error"]}')
+        if operation and operation.get("done"):
+            return True
+        return False
 
-class BigQueryTableExistenceAsyncSensor(BigQueryTableExistenceSensor):
+
+class GoogleDisplayVideo360RunQuerySensor(BaseSensorOperator):
     """
-    Checks for the existence of a table in Google Big Query.
+    Sensor for detecting the completion of DV360 reports for API v2.
+
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:GoogleDisplayVideo360RunQuerySensor`
 
-    :param project_id: The Google cloud project in which to look for the table.
-       The connection supplied to the hook must provide
-       access to the specified project.
-    :param dataset_id: The name of the dataset in which to look for the table.
-       storage bucket.
-    :param table_id: The name of the table to check the existence of.
-    :param gcp_conn_id: The connection ID used to connect to Google Cloud.
-    :param bigquery_conn_id: (Deprecated) The connection ID used to connect to Google Cloud.
-       This parameter has been deprecated. You should pass the gcp_conn_id parameter instead.
+    :param query_id: Query ID for which report was generated
+    :param report_id: Report ID for which you want to wait
+    :param api_version: The version of the api that will be requested for example 'v3'.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
     :param delegate_to: The account to impersonate using domain-wide delegation of authority,
-       if any. For this to work, the service account making the request must have
-       domain-wide delegation enabled.
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
     :param impersonation_chain: Optional service account to impersonate using short-term
-       credentials, or chained list of accounts required to get the access_token
-       of the last account in the list, which will be impersonated in the request.
-       If set as a string, the account must grant the originating account
-       the Service Account Token Creator IAM role.
-       If set as a sequence, the identities from the list must grant
-       Service Account Token Creator IAM role to the directly preceding identity, with first
-       account from the list granting this role to the originating account (templated).
-    :param polling_interval: The interval in seconds to wait between checks table existence.
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
     """
 
+    template_fields: Sequence[str] = (
+        "query_id",
+        "report_id",
+        "impersonation_chain",
+    )
+
     def __init__(
         self,
+        *,
+        query_id: str,
+        report_id: str,
+        api_version: str = "v2",
         gcp_conn_id: str = "google_cloud_default",
-        polling_interval: float = 5.0,
-        **kwargs: Any,
+        delegate_to: str | None = None,
+        impersonation_chain: str | Sequence[str] | None = None,
+        **kwargs,
     ) -> None:
         super().__init__(**kwargs)
-        self.polling_interval = polling_interval
+        self.query_id = query_id
+        self.report_id = report_id
+        self.api_version = api_version
         self.gcp_conn_id = gcp_conn_id
+        self.delegate_to = delegate_to
+        self.impersonation_chain = impersonation_chain
 
-    def execute(self, context: Context) -> None:
-        """Airflow runs this method on the worker and defers using the trigger."""
-        self.defer(
-            timeout=timedelta(seconds=self.timeout),
-            trigger=BigQueryTableExistenceTrigger(
-                dataset_id=self.dataset_id,
-                table_id=self.table_id,
-                project_id=self.project_id,
-                poll_interval=self.polling_interval,
-                gcp_conn_id=self.gcp_conn_id,
-                hook_params={
-                    "delegate_to": self.delegate_to,
-                    "impersonation_chain": self.impersonation_chain,
-                },
-            ),
-            method_name="execute_complete",
+    def poke(self, context: Context) -> bool:
+        hook = GoogleDisplayVideo360Hook(
+            gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
+            api_version=self.api_version,
+            impersonation_chain=self.impersonation_chain,
         )
 
-    def execute_complete(self, context: dict[str, Any], event: dict[str, str] | None = None) -> str:
-        """
-        Callback for when the trigger fires - returns immediately.
-        Relies on trigger to throw an exception, otherwise it assumes execution was
-        successful.
-        """
-        table_uri = f"{self.project_id}:{self.dataset_id}.{self.table_id}"
-        self.log.info("Sensor checks existence of table: %s", table_uri)
-        if event:
-            if event["status"] == "success":
-                return event["message"]
-            raise AirflowException(event["message"])
-        raise AirflowException("No event received in trigger callback")
+        response = hook.get_report(query_id=self.query_id, report_id=self.report_id)
+        status = response.get("metadata", {}).get("status", {}).get("state")
+        self.log.info(f"STATUS OF THE REPORT {self.report_id} FOR QUERY {self.query_id}: {status}")
+        if response and status in ["DONE", "FAILED"]:
+            return True
+        return False
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/bigquery_dts.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/bigquery_dts.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/bigtable.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/bigtable.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,16 +17,16 @@
 # under the License.
 """This module contains Google Cloud Bigtable sensor."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Sequence
 
 import google.api_core.exceptions
+from google.cloud.bigtable import enums
 from google.cloud.bigtable.table import ClusterState
-from google.cloud.bigtable_admin_v2 import enums
 
 from airflow.providers.google.cloud.hooks.bigtable import BigtableHook
 from airflow.providers.google.cloud.links.bigtable import BigtableTablesLink
 from airflow.providers.google.cloud.operators.bigtable import BigtableValidationMixin
 from airflow.sensors.base import BaseSensorOperator
 
 if TYPE_CHECKING:
@@ -99,15 +99,15 @@
             cluster_states = hook.get_cluster_states_for_table(instance=instance, table_id=self.table_id)
         except google.api_core.exceptions.NotFound:
             self.log.info(
                 "Dependency: table '%s' does not exist in instance '%s'.", self.table_id, self.instance_id
             )
             return False
 
-        ready_state = ClusterState(enums.Table.ClusterState.ReplicationState.READY)
+        ready_state = ClusterState(enums.Table.ReplicationState.READY)
 
         is_table_replicated = True
         for cluster_id in cluster_states.keys():
             if cluster_states[cluster_id] != ready_state:
                 self.log.info("Table '%s' is not yet replicated on cluster '%s'.", self.table_id, cluster_id)
                 is_table_replicated = False
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/cloud_composer.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/cloud_composer.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/cloud_storage_transfer_service.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/cloud_storage_transfer_service.py`

 * *Files 1% similar despite different names*

```diff
@@ -89,15 +89,15 @@
 
     def poke(self, context: Context) -> bool:
         hook = CloudDataTransferServiceHook(
             gcp_conn_id=self.gcp_cloud_conn_id,
             impersonation_chain=self.impersonation_chain,
         )
         operations = hook.list_transfer_operations(
-            request_filter={"project_id": self.project_id, "job_names": [self.job_name]}
+            request_filter={"project_id": self.project_id or hook.project_id, "job_names": [self.job_name]}
         )
 
         for operation in operations:
             self.log.info("Progress for operation %s: %s", operation[NAME], operation[METADATA][COUNTERS])
 
         check = CloudDataTransferServiceHook.operations_contain_expected_statuses(
             operations=operations, expected_statuses=self.expected_statuses
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataflow.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataflow.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataform.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataform.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/datafusion.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/datafusion.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataplex.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataplex.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataprep.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataprep.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/dataproc.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/dataproc.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/gcs.py`

 * *Files 5% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 """This module contains Google Cloud Storage sensors."""
 from __future__ import annotations
 
 import os
 import textwrap
 import warnings
 from datetime import datetime, timedelta
-from typing import TYPE_CHECKING, Callable, Sequence
+from typing import TYPE_CHECKING, Any, Callable, Sequence
 
 from google.api_core.retry import Retry
 from google.cloud.storage.retry import DEFAULT_RETRY
 
 from airflow.exceptions import AirflowException
 from airflow.providers.google.cloud.hooks.gcs import GCSHook
 from airflow.providers.google.cloud.triggers.gcs import GCSBlobTrigger
@@ -71,14 +71,15 @@
         *,
         bucket: str,
         object: str,
         google_cloud_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         retry: Retry = DEFAULT_RETRY,
+        deferrable: bool = False,
         **kwargs,
     ) -> None:
 
         super().__init__(**kwargs)
         self.bucket = bucket
         self.object = object
         self.google_cloud_conn_id = google_cloud_conn_id
@@ -86,27 +87,62 @@
             warnings.warn(
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         self.delegate_to = delegate_to
         self.impersonation_chain = impersonation_chain
         self.retry = retry
 
+        self.deferrable = deferrable
+
     def poke(self, context: Context) -> bool:
         self.log.info("Sensor checks existence of : %s, %s", self.bucket, self.object)
         hook = GCSHook(
             gcp_conn_id=self.google_cloud_conn_id,
             delegate_to=self.delegate_to,
             impersonation_chain=self.impersonation_chain,
         )
         return hook.exists(self.bucket, self.object, self.retry)
 
+    def execute(self, context: Context) -> None:
+        """Airflow runs this method on the worker and defers using the trigger."""
+        if not self.deferrable:
+            super().execute(context)
+        else:
+            self.defer(
+                timeout=timedelta(seconds=self.timeout),
+                trigger=GCSBlobTrigger(
+                    bucket=self.bucket,
+                    object_name=self.object,
+                    poke_interval=self.poke_interval,
+                    google_cloud_conn_id=self.google_cloud_conn_id,
+                    hook_params={
+                        "delegate_to": self.delegate_to,
+                        "impersonation_chain": self.impersonation_chain,
+                    },
+                ),
+                method_name="execute_complete",
+            )
+
+    def execute_complete(self, context: Context, event: dict[str, str]) -> str:
+        """
+        Callback for when the trigger fires - returns immediately.
+        Relies on trigger to throw an exception, otherwise it assumes execution was
+        successful.
+        """
+        if event["status"] == "error":
+            raise AirflowException(event["message"])
+        self.log.info("File %s was found in bucket %s.", self.object, self.bucket)
+        return event["message"]
+
 
 class GCSObjectExistenceAsyncSensor(GCSObjectExistenceSensor):
     """
-    Checks for the existence of a file in Google Cloud Storage .
+    Checks for the existence of a file in Google Cloud Storage.
+    Class `GCSObjectExistenceAsyncSensor` is deprecated and will be removed in a future release.
+    Please use `GCSObjectExistenceSensor` and set `deferrable` attribute to `True` instead
 
     :param bucket: The Google Cloud Storage bucket where the object is.
     :param object: The name of the object to check in the Google cloud storage bucket.
     :param google_cloud_conn_id: The connection ID to use when connecting to Google Cloud Storage.
     :param delegate_to: The account to impersonate using domain-wide delegation of authority,
         if any. For this to work, the service account making the request must have
         domain-wide delegation enabled.
@@ -116,41 +152,21 @@
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     """
 
-    def execute(self, context: Context) -> None:
-        """Airflow runs this method on the worker and defers using the trigger."""
-        self.defer(
-            timeout=timedelta(seconds=self.timeout),
-            trigger=GCSBlobTrigger(
-                bucket=self.bucket,
-                object_name=self.object,
-                poke_interval=self.poke_interval,
-                google_cloud_conn_id=self.google_cloud_conn_id,
-                hook_params={
-                    "delegate_to": self.delegate_to,
-                    "impersonation_chain": self.impersonation_chain,
-                },
-            ),
-            method_name="execute_complete",
+    def __init__(self, **kwargs: Any) -> None:
+        warnings.warn(
+            "Class `GCSObjectExistenceAsyncSensor` is deprecated and will be removed in a future release. "
+            "Please use `GCSObjectExistenceSensor` and set `deferrable` attribute to `True` instead",
+            DeprecationWarning,
         )
-
-    def execute_complete(self, context: Context, event: dict[str, str]) -> str:
-        """
-        Callback for when the trigger fires - returns immediately.
-        Relies on trigger to throw an exception, otherwise it assumes execution was
-        successful.
-        """
-        if event["status"] == "error":
-            raise AirflowException(event["message"])
-        self.log.info("File %s was found in bucket %s.", self.object, self.bucket)
-        return event["message"]
+        super().__init__(deferrable=True, **kwargs)
 
 
 def ts_function(context):
     """
     Default callback for the GoogleCloudStorageObjectUpdatedSensor. The default
     behaviour is check for the object being updated after the data interval's
     end, or execution_date + interval on Airflow versions prior to 2.2 (before
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/looker.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/looker.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/pubsub.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/pubsub.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/tasks.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/tasks.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/sensors/workflows.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/workflows.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/adls_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/adls_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/azure_fileshare_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/azure_fileshare_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_bigquery.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_bigquery.py`

 * *Files 2% similar despite different names*

```diff
@@ -30,14 +30,17 @@
 
 
 class BigQueryToBigQueryOperator(BaseOperator):
     """
     Copies data from one BigQuery table to another.
 
     .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:BigQueryToBigQueryOperator`
+    .. seealso::
         For more details about these parameters:
         https://cloud.google.com/bigquery/docs/reference/v2/jobs#configuration.copy
 
     :param source_project_dataset_tables: One or more
         dotted ``(project:|project.)<dataset>.<table>`` BigQuery tables to use as the
         source data. If ``<project>`` is not included, project will be the
         project defined in the connection json. Use a list if there are multiple
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_gcs.py`

 * *Files 2% similar despite different names*

```diff
@@ -36,14 +36,17 @@
 
 
 class BigQueryToGCSOperator(BaseOperator):
     """
     Transfers a BigQuery table to a Google Cloud Storage bucket.
 
     .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:BigQueryToGCSOperator`
+    .. seealso::
         For more details about these parameters:
         https://cloud.google.com/bigquery/docs/reference/v2/jobs
 
     :param source_project_dataset_table: The dotted
         ``(<project>.|<project>:)<dataset>.<table>`` BigQuery table to use as the
         source data. If ``<project>`` is not included, project will be the project
         defined in the connection json. (templated)
@@ -86,14 +89,15 @@
 
     template_fields: Sequence[str] = (
         "source_project_dataset_table",
         "destination_cloud_storage_uris",
         "export_format",
         "labels",
         "impersonation_chain",
+        "job_id",
     )
     template_ext: Sequence[str] = ()
     ui_color = "#e4e6f0"
     operator_extra_links = (BigQueryTableLink(),)
 
     def __init__(
         self,
@@ -185,20 +189,20 @@
         job_id: str,
         configuration: dict,
     ) -> BigQueryJob:
         # Submit a new job without waiting for it to complete.
 
         return hook.insert_job(
             configuration=configuration,
-            project_id=hook.project_id,
+            project_id=configuration["extract"]["sourceTable"]["projectId"],
             location=self.location,
             job_id=job_id,
             timeout=self.result_timeout,
             retry=self.result_retry,
-            nowait=True,
+            nowait=self.deferrable,
         )
 
     def execute(self, context: Context):
         self.log.info(
             "Executing extract of %s into: %s",
             self.source_project_dataset_table,
             self.destination_cloud_storage_uris,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_mssql.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_mssql.py`

 * *Files 2% similar despite different names*

```diff
@@ -32,14 +32,17 @@
 
 
 class BigQueryToMsSqlOperator(BaseOperator):
     """
     Fetches the data from a BigQuery table (alternatively fetch data for selected columns)
     and insert that data into a MSSQL table.
 
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:BigQueryToMsSqlOperator`
 
     .. note::
         If you pass fields to ``selected_fields`` which are in different order than the
         order of columns already in
         BQ table, the data will still be in the order of BQ table.
         For example if the BQ table has 3 columns as
         ``[A,B,C]`` and you pass 'B,A' in the ``selected_fields``
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_mysql.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/bigquery_to_mysql.py`

 * *Files 11% similar despite different names*

```diff
@@ -31,32 +31,37 @@
 
 
 class BigQueryToMySqlOperator(BaseOperator):
     """
     Fetches the data from a BigQuery table (alternatively fetch data for selected columns)
     and insert that data into a MySQL table.
 
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:BigQueryToMySqlOperator`
 
     .. note::
         If you pass fields to ``selected_fields`` which are in different order than the
         order of columns already in
         BQ table, the data will still be in the order of BQ table.
         For example if the BQ table has 3 columns as
         ``[A,B,C]`` and you pass 'B,A' in the ``selected_fields``
         the data would still be of the form ``'A,B'`` and passed through this form
         to MySQL
 
     **Example**: ::
 
+       # [START howto_operator_bigquery_to_mysql]
        transfer_data = BigQueryToMySqlOperator(
             task_id='task_id',
             dataset_table='origin_bq_table',
             mysql_table='dest_table_name',
             replace=True,
         )
+        # [END howto_operator_bigquery_to_mysql]
 
     :param dataset_table: A dotted ``<dataset>.<table>``: the big query table of origin
     :param selected_fields: List of fields to return (comma-separated). If
         unspecified, all fields are returned.
     :param gcp_conn_id: reference to a specific Google Cloud hook.
     :param delegate_to: The account to impersonate using domain-wide delegation of authority,
         if any. For this to work, the service account making the request must have
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/calendar_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/calendar_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/cassandra_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/cassandra_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/facebook_ads_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/facebook_ads_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py`

 * *Files 2% similar despite different names*

```diff
@@ -223,14 +223,15 @@
         deferrable: bool = False,
         result_retry: Retry = DEFAULT_RETRY,
         result_timeout: float | None = None,
         cancel_on_kill: bool = True,
         job_id: str | None = None,
         force_rerun: bool = True,
         reattach_states: set[str] | None = None,
+        project_id: str | None = None,
         **kwargs,
     ) -> None:
 
         super().__init__(**kwargs)
         self.hook: BigQueryHook | None = None
         self.configuration: dict[str, Any] = {}
 
@@ -245,14 +246,15 @@
 
         if schema_object_bucket is None:
             schema_object_bucket = bucket
         self.schema_object_bucket = schema_object_bucket
 
         # BQ config
         self.destination_project_dataset_table = destination_project_dataset_table
+        self.project_id = project_id
         self.schema_fields = schema_fields
         if source_format.upper() not in ALLOWED_FORMATS:
             raise ValueError(
                 f"{source_format} is not a valid source format. "
                 f"Please use one of the following types: {ALLOWED_FORMATS}."
             )
         else:
@@ -302,15 +304,15 @@
         self,
         hook: BigQueryHook,
         job_id: str,
     ) -> BigQueryJob:
         # Submit a new job without waiting for it to complete.
         return hook.insert_job(
             configuration=self.configuration,
-            project_id=hook.project_id,
+            project_id=self.project_id,
             location=self.location,
             job_id=job_id,
             timeout=self.result_timeout,
             retry=self.result_retry,
             nowait=True,
         )
 
@@ -503,17 +505,17 @@
                         max_id,
                     )
                     return str(max_id)
             else:
                 raise RuntimeError(f"The {select_command} returned no rows!")
 
     def _create_empty_table(self):
-        project_id, dataset_id, table_id = self.hook.split_tablename(
+        self.project_id, dataset_id, table_id = self.hook.split_tablename(
             table_input=self.destination_project_dataset_table,
-            default_project_id=self.hook.project_id or "",
+            default_project_id=self.project_id or self.hook.project_id,
         )
 
         external_config_api_repr = {
             "autodetect": self.autodetect,
             "sourceFormat": self.source_format,
             "sourceUris": self.source_uris,
             "compression": self.compression.upper(),
@@ -552,15 +554,15 @@
         if self.schema_fields:
             external_config.schema = [SchemaField.from_api_repr(f) for f in self.schema_fields]
         if self.max_bad_records:
             external_config.max_bad_records = self.max_bad_records
 
         # build table definition
         table = Table(
-            table_ref=TableReference.from_string(self.destination_project_dataset_table, project_id)
+            table_ref=TableReference.from_string(self.destination_project_dataset_table, self.project_id)
         )
         table.external_data_configuration = external_config
         if self.labels:
             table.labels = self.labels
 
         if self.description:
             table.description = self.description
@@ -569,23 +571,26 @@
             table.encryption_configuration = EncryptionConfiguration.from_api_repr(
                 self.encryption_configuration
             )
         table_obj_api_repr = table.to_api_repr()
 
         self.log.info("Creating external table: %s", self.destination_project_dataset_table)
         self.hook.create_empty_table(
-            table_resource=table_obj_api_repr, project_id=project_id, location=self.location, exists_ok=True
+            table_resource=table_obj_api_repr,
+            project_id=self.project_id,
+            location=self.location,
+            exists_ok=True,
         )
         self.log.info("External table created successfully: %s", self.destination_project_dataset_table)
         return table_obj_api_repr
 
     def _use_existing_table(self):
-        destination_project, destination_dataset, destination_table = self.hook.split_tablename(
+        self.project_id, destination_dataset, destination_table = self.hook.split_tablename(
             table_input=self.destination_project_dataset_table,
-            default_project_id=self.hook.project_id or "",
+            default_project_id=self.project_id or self.hook.project_id,
             var_name="destination_project_dataset_table",
         )
 
         # bigquery also allows you to define how you want a table's schema to change
         # as a side effect of a load
         # for more details:
         # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.load.schemaUpdateOptions
@@ -597,15 +602,15 @@
             )
 
         self.configuration = {
             "load": {
                 "autodetect": self.autodetect,
                 "createDisposition": self.create_disposition,
                 "destinationTable": {
-                    "projectId": destination_project,
+                    "projectId": self.project_id,
                     "datasetId": destination_dataset,
                     "tableId": destination_table,
                 },
                 "sourceFormat": self.source_format,
                 "sourceUris": self.source_uris,
                 "writeDisposition": self.write_disposition,
                 "ignoreUnknownValues": self.ignore_unknown_values,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gcs_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gcs_to_gcs.py`

 * *Files 0% similar despite different names*

```diff
@@ -146,15 +146,15 @@
             source_object='sales/sales-2017/*.avro',
             destination_bucket='data_backup',
             move_object=True,
             gcp_conn_id=google_cloud_conn_id
         )
 
     The following Operator would move all the Avro files from ``sales/sales-2019``
-     and ``sales/sales-2020` folder in ``data`` bucket to the same folder in the
+     and ``sales/sales-2020`` folder in ``data`` bucket to the same folder in the
      ``data_backup`` bucket, deleting the original files in the process. ::
 
         move_files = GCSToGCSOperator(
             task_id='move_files',
             source_bucket='data',
             source_objects=['sales/sales-2019/*.avro', 'sales/sales-2020'],
             destination_bucket='data_backup',
@@ -370,15 +370,15 @@
         if len(objects) == 1 and objects[0][-1] != "/":
             self._copy_file(hook=hook, source_object=objects[0])
         elif len(objects):
             self._copy_directory(hook=hook, source_objects=objects, prefix=prefix)
 
     def _copy_file(self, hook, source_object):
         destination_object = self.destination_object or source_object
-        if self.destination_object[-1] == "/":
+        if self.destination_object and self.destination_object[-1] == "/":
             file_name = source_object.split("/")[-1]
             destination_object += file_name
         self._copy_single_object(
             hook=hook, source_object=source_object, destination_object=destination_object
         )
 
     def _copy_directory(self, hook, source_objects, prefix):
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gcs_to_local.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gcs_to_local.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gcs_to_sftp.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gcs_to_sftp.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gdrive_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gdrive_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/gdrive_to_local.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/gdrive_to_local.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/local_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/local_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/mssql_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/mssql_to_gcs.py`

 * *Files 17% similar despite different names*

```diff
@@ -16,33 +16,39 @@
 # specific language governing permissions and limitations
 # under the License.
 """MsSQL to GCS operator."""
 from __future__ import annotations
 
 import datetime
 import decimal
+from typing import Sequence
 
 from airflow.providers.google.cloud.transfers.sql_to_gcs import BaseSQLToGCSOperator
 from airflow.providers.microsoft.mssql.hooks.mssql import MsSqlHook
 
 
 class MSSQLToGCSOperator(BaseSQLToGCSOperator):
     """Copy data from Microsoft SQL Server to Google Cloud Storage
     in JSON, CSV or Parquet format.
 
+    :param bit_fields: Sequence of fields names of MSSQL "BIT" data type,
+        to be interpreted in the schema as "BOOLEAN". "BIT" fields that won't
+        be included in this sequence, will be interpreted as "INTEGER" by
+        default.
     :param mssql_conn_id: Reference to a specific MSSQL hook.
 
     **Example**:
         The following operator will export data from the Customers table
         within the given MSSQL Database and then upload it to the
         'mssql-export' GCS bucket (along with a schema file). ::
 
             export_customers = MsSqlToGoogleCloudStorageOperator(
                 task_id='export_customers',
                 sql='SELECT * FROM dbo.Customers;',
+                bit_fields=['some_bit_field', 'another_bit_field'],
                 bucket='mssql-export',
                 filename='data/customers/export.json',
                 schema_filename='schemas/export.json',
                 mssql_conn_id='mssql_default',
                 gcp_conn_id='google_cloud_default',
                 dag=dag
             )
@@ -51,33 +57,43 @@
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:MSSQLToGCSOperator`
 
     """
 
     ui_color = "#e0a98c"
 
-    type_map = {3: "INTEGER", 4: "TIMESTAMP", 5: "NUMERIC"}
+    type_map = {2: "BOOLEAN", 3: "INTEGER", 4: "TIMESTAMP", 5: "NUMERIC"}
 
-    def __init__(self, *, mssql_conn_id="mssql_default", **kwargs):
+    def __init__(
+        self,
+        *,
+        bit_fields: Sequence[str] | None = None,
+        mssql_conn_id="mssql_default",
+        **kwargs,
+    ):
         super().__init__(**kwargs)
         self.mssql_conn_id = mssql_conn_id
+        self.bit_fields = bit_fields if bit_fields else []
 
     def query(self):
         """
         Queries MSSQL and returns a cursor of results.
 
         :return: mssql cursor
         """
         mssql = MsSqlHook(mssql_conn_id=self.mssql_conn_id)
         conn = mssql.get_conn()
         cursor = conn.cursor()
         cursor.execute(self.sql)
         return cursor
 
     def field_to_bigquery(self, field) -> dict[str, str]:
+        if field[0] in self.bit_fields:
+            field = (field[0], 2)
+
         return {
             "name": field[0].replace(" ", "_"),
             "type": self.type_map.get(field[1], "STRING"),
             "mode": "NULLABLE",
         }
 
     @classmethod
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/mysql_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/mysql_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/oracle_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/oracle_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/postgres_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/postgres_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/presto_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/presto_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/s3_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/s3_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/salesforce_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/salesforce_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/sftp_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/sftp_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/sheets_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/sheets_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/sql_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/sql_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/transfers/trino_to_gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/transfers/trino_to_gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/bigquery.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/bigquery.py`

 * *Files 16% similar despite different names*

```diff
@@ -525,7 +525,76 @@
                 )
                 response = await client.get()
                 return True if response else False
             except ClientResponseError as err:
                 if err.status == 404:
                     return False
                 raise err
+
+
+class BigQueryTablePartitionExistenceTrigger(BigQueryTableExistenceTrigger):
+    """
+    Initialize the BigQuery Table Partition Existence Trigger with needed parameters
+    :param partition_id: The name of the partition to check the existence of.
+    :param project_id: Google Cloud Project where the job is running
+    :param dataset_id: The dataset ID of the requested table.
+    :param table_id: The table ID of the requested table.
+    :param gcp_conn_id: Reference to google cloud connection id
+    :param hook_params: params for hook
+    :param poll_interval: polling period in seconds to check for the status
+    """
+
+    def __init__(self, partition_id: str, **kwargs):
+        super().__init__(**kwargs)
+        self.partition_id = partition_id
+
+    def serialize(self) -> tuple[str, dict[str, Any]]:
+        """Serializes BigQueryTablePartitionExistenceTrigger arguments and classpath."""
+        return (
+            "airflow.providers.google.cloud.triggers.bigquery.BigQueryTablePartitionExistenceTrigger",
+            {
+                "partition_id": self.partition_id,
+                "dataset_id": self.dataset_id,
+                "project_id": self.project_id,
+                "table_id": self.table_id,
+                "gcp_conn_id": self.gcp_conn_id,
+                "poll_interval": self.poll_interval,
+                "hook_params": self.hook_params,
+            },
+        )
+
+    async def run(self) -> AsyncIterator["TriggerEvent"]:  # type: ignore[override]
+        """Will run until the table exists in the Google Big Query."""
+        hook = BigQueryAsyncHook(gcp_conn_id=self.gcp_conn_id)
+        job_id = None
+        while True:
+            if job_id is not None:
+                status = await hook.get_job_status(job_id=job_id, project_id=self.project_id)
+                if status == "success":
+                    is_partition = await self._partition_exists(
+                        hook=hook, job_id=job_id, project_id=self.project_id
+                    )
+                    if is_partition:
+                        yield TriggerEvent(
+                            {
+                                "status": "success",
+                                "message": f"Partition: {self.partition_id} in table: {self.table_id}",
+                            }
+                        )
+                    job_id = None
+                elif status == "error":
+                    yield TriggerEvent({"status": "error", "message": status})
+                    return
+                self.log.info("Sleeping for %s seconds.", self.poll_interval)
+                await asyncio.sleep(self.poll_interval)
+
+            else:
+                job_id = await hook.create_job_for_partition_get(self.dataset_id, project_id=self.project_id)
+                self.log.info("Sleeping for %s seconds.", self.poll_interval)
+                await asyncio.sleep(self.poll_interval)
+
+    async def _partition_exists(self, hook: BigQueryAsyncHook, job_id: str | None, project_id: str):
+        query_results = await hook.get_job_output(job_id=job_id, project_id=project_id)
+        records = hook.get_records(query_results)
+        if records:
+            records = [row[0] for row in records]
+            return self.partition_id in records
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/bigquery_dts.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/bigquery_dts.py`

 * *Files 1% similar despite different names*

```diff
@@ -97,14 +97,15 @@
         hook = self._get_async_hook()
         while True:
             try:
                 transfer_run: TransferRun = await hook.get_transfer_run(
                     project_id=self.project_id,
                     config_id=self.config_id,
                     run_id=self.run_id,
+                    location=self.location,
                 )
                 state = transfer_run.state
                 self.log.info("Current state is %s", state)
 
                 if state == TransferState.SUCCEEDED:
                     self.log.info("Job has completed it's work.")
                     yield TriggerEvent(
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/cloud_build.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/cloud_build.py`

 * *Files 8% similar despite different names*

```diff
@@ -41,60 +41,65 @@
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
     :param delegate_to: The account to impersonate using domain-wide delegation of authority,
         if any. For this to work, the service account making the request must have
         domain-wide delegation enabled.
     :param poll_interval: polling period in seconds to check for the status
+    :param location: The location of the project.
     """
 
     def __init__(
         self,
         id_: str,
         project_id: str | None,
         gcp_conn_id: str = "google_cloud_default",
         impersonation_chain: str | Sequence[str] | None = None,
         delegate_to: str | None = None,
         poll_interval: float = 4.0,
+        location: str = "global",
     ):
         super().__init__()
         self.id_ = id_
         self.project_id = project_id
         self.gcp_conn_id = gcp_conn_id
         self.impersonation_chain = impersonation_chain
         if delegate_to:
             warnings.warn(
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         self.delegate_to = delegate_to
         self.poll_interval = poll_interval
+        self.location = location
 
     def serialize(self) -> tuple[str, dict[str, Any]]:
         """Serializes CloudBuildCreateBuildTrigger arguments and classpath."""
         return (
             "airflow.providers.google.cloud.triggers.cloud_build.CloudBuildCreateBuildTrigger",
             {
                 "id_": self.id_,
                 "project_id": self.project_id,
                 "gcp_conn_id": self.gcp_conn_id,
                 "impersonation_chain": self.impersonation_chain,
                 "delegate_to": self.delegate_to,
                 "poll_interval": self.poll_interval,
+                "location": self.location,
             },
         )
 
     async def run(self) -> AsyncIterator["TriggerEvent"]:  # type: ignore[override]
         """Gets current build execution status and yields a TriggerEvent"""
         hook = self._get_async_hook()
         while True:
             try:
                 # Poll for job execution status
                 cloud_build_instance = await hook.get_cloud_build(
                     id_=self.id_,
                     project_id=self.project_id,
+                    location=self.location,
                 )
                 if cloud_build_instance._pb.status in (Build.Status.SUCCESS,):
                     yield TriggerEvent(
                         {
                             "instance": Build.to_dict(cloud_build_instance),
                             "id_": self.id_,
                             "status": "success",
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/cloud_composer.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/cloud_composer.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/dataflow.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/dataflow.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/datafusion.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/datafusion.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/dataproc.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/sensors/bigquery.py`

 * *Files 24% similar despite different names*

```diff
@@ -11,302 +11,334 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an
 # "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 # KIND, either express or implied.  See the License for the
 # specific language governing permissions and limitations
 # under the License.
-"""This module contains Google Dataproc triggers."""
+"""This module contains Google BigQuery sensors."""
 from __future__ import annotations
 
-import asyncio
-import time
 import warnings
-from typing import Any, AsyncIterator, Sequence
+from datetime import timedelta
+from typing import TYPE_CHECKING, Any, Sequence
 
-from google.api_core.exceptions import NotFound
-from google.cloud.dataproc_v1 import Batch, ClusterStatus, JobStatus
+from airflow.exceptions import AirflowException
+from airflow.providers.google.cloud.hooks.bigquery import BigQueryHook
+from airflow.providers.google.cloud.triggers.bigquery import (
+    BigQueryTableExistenceTrigger,
+    BigQueryTablePartitionExistenceTrigger,
+)
+from airflow.sensors.base import BaseSensorOperator
 
-from airflow import AirflowException
-from airflow.providers.google.cloud.hooks.dataproc import DataprocAsyncHook
-from airflow.triggers.base import BaseTrigger, TriggerEvent
+if TYPE_CHECKING:
+    from airflow.utils.context import Context
 
 
-class DataprocSubmitTrigger(BaseTrigger):
+class BigQueryTableExistenceSensor(BaseSensorOperator):
     """
-    Trigger that periodically polls information from Dataproc API to verify job status.
-    Implementation leverages asynchronous transport.
+    Checks for the existence of a table in Google Bigquery.
+
+    :param project_id: The Google cloud project in which to look for the table.
+        The connection supplied to the hook must provide
+        access to the specified project.
+    :param dataset_id: The name of the dataset in which to look for the table.
+        storage bucket.
+    :param table_id: The name of the table to check the existence of.
+    :param gcp_conn_id: (Optional) The connection ID used to connect to Google Cloud.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
+    :param impersonation_chain: Optional service account to impersonate using short-term
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
     """
 
+    template_fields: Sequence[str] = (
+        "project_id",
+        "dataset_id",
+        "table_id",
+        "impersonation_chain",
+    )
+    ui_color = "#f0eee4"
+
     def __init__(
         self,
-        job_id: str,
-        region: str,
-        project_id: str | None = None,
+        *,
+        project_id: str,
+        dataset_id: str,
+        table_id: str,
         gcp_conn_id: str = "google_cloud_default",
-        impersonation_chain: str | Sequence[str] | None = None,
         delegate_to: str | None = None,
-        polling_interval_seconds: int = 30,
-    ):
-        super().__init__()
-        self.gcp_conn_id = gcp_conn_id
-        self.impersonation_chain = impersonation_chain
-        self.job_id = job_id
+        impersonation_chain: str | Sequence[str] | None = None,
+        deferrable: bool = False,
+        **kwargs,
+    ) -> None:
+        if deferrable and "poke_interval" not in kwargs:
+            # TODO: Remove once deprecated
+            if "polling_interval" in kwargs:
+                kwargs["poke_interval"] = kwargs["polling_interval"]
+                warnings.warn(
+                    "Argument `poll_interval` is deprecated and will be removed "
+                    "in a future release.  Please use `poke_interval` instead.",
+                    DeprecationWarning,
+                    stacklevel=2,
+                )
+            else:
+                kwargs["poke_interval"] = 5
+
+        super().__init__(**kwargs)
+
         self.project_id = project_id
-        self.region = region
-        self.polling_interval_seconds = polling_interval_seconds
+        self.dataset_id = dataset_id
+        self.table_id = table_id
+        self.gcp_conn_id = gcp_conn_id
         if delegate_to:
             warnings.warn(
                 "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
             )
         self.delegate_to = delegate_to
-        self.hook = DataprocAsyncHook(
-            delegate_to=self.delegate_to,
+        self.impersonation_chain = impersonation_chain
+
+        self.deferrable = deferrable
+
+    def poke(self, context: Context) -> bool:
+        table_uri = f"{self.project_id}:{self.dataset_id}.{self.table_id}"
+        self.log.info("Sensor checks existence of table: %s", table_uri)
+        hook = BigQueryHook(
             gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
             impersonation_chain=self.impersonation_chain,
         )
-
-    def serialize(self):
-        return (
-            "airflow.providers.google.cloud.triggers.dataproc.DataprocSubmitTrigger",
-            {
-                "job_id": self.job_id,
-                "project_id": self.project_id,
-                "region": self.region,
-                "gcp_conn_id": self.gcp_conn_id,
-                "delegate_to": self.delegate_to,
-                "impersonation_chain": self.impersonation_chain,
-                "polling_interval_seconds": self.polling_interval_seconds,
-            },
+        return hook.table_exists(
+            project_id=self.project_id, dataset_id=self.dataset_id, table_id=self.table_id
         )
 
-    async def run(self):
-        while True:
-            job = await self.hook.get_job(project_id=self.project_id, region=self.region, job_id=self.job_id)
-            state = job.status.state
-            self.log.info("Dataproc job: %s is in state: %s", self.job_id, state)
-            if state in (JobStatus.State.ERROR, JobStatus.State.DONE, JobStatus.State.CANCELLED):
-                if state in (JobStatus.State.DONE, JobStatus.State.CANCELLED):
-                    break
-                elif state == JobStatus.State.ERROR:
-                    raise AirflowException(f"Dataproc job execution failed {self.job_id}")
-            await asyncio.sleep(self.polling_interval_seconds)
-        yield TriggerEvent({"job_id": self.job_id, "job_state": state})
-
-
-class DataprocClusterTrigger(BaseTrigger):
-    """
-    Trigger that periodically polls information from Dataproc API to verify status.
-    Implementation leverages asynchronous transport.
-    """
-
-    def __init__(
-        self,
-        cluster_name: str,
-        region: str,
-        project_id: str | None = None,
-        gcp_conn_id: str = "google_cloud_default",
-        impersonation_chain: str | Sequence[str] | None = None,
-        polling_interval_seconds: int = 10,
-    ):
-        super().__init__()
-        self.gcp_conn_id = gcp_conn_id
-        self.impersonation_chain = impersonation_chain
-        self.cluster_name = cluster_name
-        self.project_id = project_id
-        self.region = region
-        self.polling_interval_seconds = polling_interval_seconds
-
-    def serialize(self) -> tuple[str, dict[str, Any]]:
-        return (
-            "airflow.providers.google.cloud.triggers.dataproc.DataprocClusterTrigger",
-            {
-                "cluster_name": self.cluster_name,
-                "project_id": self.project_id,
-                "region": self.region,
-                "gcp_conn_id": self.gcp_conn_id,
-                "impersonation_chain": self.impersonation_chain,
-                "polling_interval_seconds": self.polling_interval_seconds,
-            },
+    def execute(self, context: Context) -> None:
+        """Airflow runs this method on the worker and defers using the trigger."""
+        self.defer(
+            timeout=timedelta(seconds=self.timeout),
+            trigger=BigQueryTableExistenceTrigger(
+                dataset_id=self.dataset_id,
+                table_id=self.table_id,
+                project_id=self.project_id,
+                poll_interval=self.poke_interval,
+                gcp_conn_id=self.gcp_conn_id,
+                hook_params={
+                    "delegate_to": self.delegate_to,
+                    "impersonation_chain": self.impersonation_chain,
+                },
+            ),
+            method_name="execute_complete",
         )
 
-    async def run(self) -> AsyncIterator["TriggerEvent"]:
-        hook = self._get_hook()
-        while True:
-            cluster = await hook.get_cluster(
-                project_id=self.project_id, region=self.region, cluster_name=self.cluster_name
-            )
-            state = cluster.status.state
-            self.log.info("Dataproc cluster: %s is in state: %s", self.cluster_name, state)
-            if state in (
-                ClusterStatus.State.ERROR,
-                ClusterStatus.State.RUNNING,
-            ):
-                break
-            self.log.info("Sleeping for %s seconds.", self.polling_interval_seconds)
-            await asyncio.sleep(self.polling_interval_seconds)
-        yield TriggerEvent({"cluster_name": self.cluster_name, "cluster_state": state, "cluster": cluster})
-
-    def _get_hook(self) -> DataprocAsyncHook:
-        return DataprocAsyncHook(
-            gcp_conn_id=self.gcp_conn_id,
-            impersonation_chain=self.impersonation_chain,
-        )
+    def execute_complete(self, context: dict[str, Any], event: dict[str, str] | None = None) -> str:
+        """
+        Callback for when the trigger fires - returns immediately.
+        Relies on trigger to throw an exception, otherwise it assumes execution was
+        successful.
+        """
+        table_uri = f"{self.project_id}:{self.dataset_id}.{self.table_id}"
+        self.log.info("Sensor checks existence of table: %s", table_uri)
+        if event:
+            if event["status"] == "success":
+                return event["message"]
+            raise AirflowException(event["message"])
+        raise AirflowException("No event received in trigger callback")
 
 
-class DataprocBatchTrigger(BaseTrigger):
+class BigQueryTablePartitionExistenceSensor(BaseSensorOperator):
     """
-    DataprocCreateBatchTrigger run on the trigger worker to perform create Build operation
+    Checks for the existence of a partition within a table in Google Bigquery.
 
-    :param batch_id: The ID of the build.
-    :param project_id: Google Cloud Project where the job is running
-    :param region: The Cloud Dataproc region in which to handle the request.
-    :param gcp_conn_id: Optional, the connection ID used to connect to Google Cloud Platform.
+    :param project_id: The Google cloud project in which to look for the table.
+        The connection supplied to the hook must provide
+        access to the specified project.
+    :param dataset_id: The name of the dataset in which to look for the table.
+        storage bucket.
+    :param table_id: The name of the table to check the existence of.
+    :param partition_id: The name of the partition to check the existence of.
+    :param gcp_conn_id: (Optional) The connection ID used to connect to Google Cloud.
+    :param delegate_to: The account to impersonate, if any.
+        For this to work, the service account making the request must
+        have domain-wide delegation enabled.
     :param impersonation_chain: Optional service account to impersonate using short-term
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account (templated).
-    :param polling_interval_seconds: polling period in seconds to check for the status
     """
 
+    template_fields: Sequence[str] = (
+        "project_id",
+        "dataset_id",
+        "table_id",
+        "partition_id",
+        "impersonation_chain",
+    )
+    ui_color = "#f0eee4"
+
     def __init__(
         self,
-        batch_id: str,
-        region: str,
-        project_id: str | None,
+        *,
+        project_id: str,
+        dataset_id: str,
+        table_id: str,
+        partition_id: str,
         gcp_conn_id: str = "google_cloud_default",
+        delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
-        polling_interval_seconds: float = 5.0,
-    ):
-        super().__init__()
-        self.batch_id = batch_id
+        deferrable: bool = False,
+        **kwargs,
+    ) -> None:
+        if deferrable and "poke_interval" not in kwargs:
+            kwargs["poke_interval"] = 5
+        super().__init__(**kwargs)
+
         self.project_id = project_id
-        self.region = region
+        self.dataset_id = dataset_id
+        self.table_id = table_id
+        self.partition_id = partition_id
         self.gcp_conn_id = gcp_conn_id
+        if delegate_to:
+            warnings.warn(
+                "'delegate_to' parameter is deprecated, please use 'impersonation_chain'", DeprecationWarning
+            )
+        self.delegate_to = delegate_to
         self.impersonation_chain = impersonation_chain
-        self.polling_interval_seconds = polling_interval_seconds
 
-    def serialize(self) -> tuple[str, dict[str, Any]]:
-        """Serializes DataprocBatchTrigger arguments and classpath."""
-        return (
-            "airflow.providers.google.cloud.triggers.dataproc.DataprocBatchTrigger",
-            {
-                "batch_id": self.batch_id,
-                "project_id": self.project_id,
-                "region": self.region,
-                "gcp_conn_id": self.gcp_conn_id,
-                "impersonation_chain": self.impersonation_chain,
-                "polling_interval_seconds": self.polling_interval_seconds,
-            },
-        )
+        self.deferrable = deferrable
 
-    async def run(self):
-        hook = DataprocAsyncHook(
+    def poke(self, context: Context) -> bool:
+        table_uri = f"{self.project_id}:{self.dataset_id}.{self.table_id}"
+        self.log.info('Sensor checks existence of partition: "%s" in table: %s', self.partition_id, table_uri)
+        hook = BigQueryHook(
             gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
             impersonation_chain=self.impersonation_chain,
         )
+        return hook.table_partition_exists(
+            project_id=self.project_id,
+            dataset_id=self.dataset_id,
+            table_id=self.table_id,
+            partition_id=self.partition_id,
+        )
 
-        while True:
-            batch = await hook.get_batch(
-                project_id=self.project_id, region=self.region, batch_id=self.batch_id
+    def execute(self, context: Context) -> None:
+        """
+        Airflow runs this method on the worker and defers using the triggers
+        if deferrable is set to True.
+        """
+        if not self.deferrable:
+            super().execute(context)
+        else:
+            self.defer(
+                timeout=timedelta(seconds=self.timeout),
+                trigger=BigQueryTablePartitionExistenceTrigger(
+                    dataset_id=self.dataset_id,
+                    table_id=self.table_id,
+                    project_id=self.project_id,
+                    partition_id=self.partition_id,
+                    poll_interval=self.poke_interval,
+                    gcp_conn_id=self.gcp_conn_id,
+                    hook_params={
+                        "impersonation_chain": self.impersonation_chain,
+                    },
+                ),
+                method_name="execute_complete",
             )
-            state = batch.state
 
-            if state in (Batch.State.FAILED, Batch.State.SUCCEEDED, Batch.State.CANCELLED):
-                break
-            self.log.info("Current state is %s", state)
-            self.log.info("Sleeping for %s seconds.", self.polling_interval_seconds)
-            await asyncio.sleep(self.polling_interval_seconds)
-        yield TriggerEvent({"batch_id": self.batch_id, "batch_state": state})
+    def execute_complete(self, context: dict[str, Any], event: dict[str, str] | None = None) -> str:
+        """
+        Callback for when the trigger fires - returns immediately.
+        Relies on trigger to throw an exception, otherwise it assumes execution was
+        successful.
+        """
+        table_uri = f"{self.project_id}:{self.dataset_id}.{self.table_id}"
+        self.log.info('Sensor checks existence of partition: "%s" in table: %s', self.partition_id, table_uri)
+        if event:
+            if event["status"] == "success":
+                return event["message"]
+            raise AirflowException(event["message"])
+        raise AirflowException("No event received in trigger callback")
 
 
-class DataprocDeleteClusterTrigger(BaseTrigger):
+class BigQueryTableExistenceAsyncSensor(BigQueryTableExistenceSensor):
     """
-    Asynchronously checks the status of a cluster.
+    Checks for the existence of a table in Google Big Query.
 
-    :param cluster_name: The name of the cluster
-    :param end_time: Time in second left to check the cluster status
-    :param project_id: The ID of the Google Cloud project the cluster belongs to
-    :param region: The Cloud Dataproc region in which to handle the request
-    :param metadata: Additional metadata that is provided to the method
-    :param gcp_conn_id: The connection ID to use when fetching connection info.
+    :param project_id: The Google cloud project in which to look for the table.
+       The connection supplied to the hook must provide
+       access to the specified project.
+    :param dataset_id: The name of the dataset in which to look for the table.
+       storage bucket.
+    :param table_id: The name of the table to check the existence of.
+    :param gcp_conn_id: The connection ID used to connect to Google Cloud.
+    :param bigquery_conn_id: (Deprecated) The connection ID used to connect to Google Cloud.
+       This parameter has been deprecated. You should pass the gcp_conn_id parameter instead.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+       if any. For this to work, the service account making the request must have
+       domain-wide delegation enabled.
     :param impersonation_chain: Optional service account to impersonate using short-term
-        credentials, or chained list of accounts required to get the access_token
-        of the last account in the list, which will be impersonated in the request.
-        If set as a string, the account must grant the originating account
-        the Service Account Token Creator IAM role.
-        If set as a sequence, the identities from the list must grant
-        Service Account Token Creator IAM role to the directly preceding identity, with first
-        account from the list granting this role to the originating account.
-    :param polling_interval: Time in seconds to sleep between checks of cluster status
+       credentials, or chained list of accounts required to get the access_token
+       of the last account in the list, which will be impersonated in the request.
+       If set as a string, the account must grant the originating account
+       the Service Account Token Creator IAM role.
+       If set as a sequence, the identities from the list must grant
+       Service Account Token Creator IAM role to the directly preceding identity, with first
+       account from the list granting this role to the originating account (templated).
+    :param polling_interval: The interval in seconds to wait between checks table existence.
     """
 
-    def __init__(
-        self,
-        cluster_name: str,
-        end_time: float,
-        project_id: str | None = None,
-        region: str | None = None,
-        metadata: Sequence[tuple[str, str]] = (),
-        gcp_conn_id: str = "google_cloud_default",
-        impersonation_chain: str | Sequence[str] | None = None,
-        polling_interval: float = 5.0,
-        **kwargs: Any,
-    ):
-        super().__init__(**kwargs)
-        self.cluster_name = cluster_name
-        self.end_time = end_time
-        self.project_id = project_id
-        self.region = region
-        self.metadata = metadata
-        self.gcp_conn_id = gcp_conn_id
-        self.impersonation_chain = impersonation_chain
-        self.polling_interval = polling_interval
-
-    def serialize(self) -> tuple[str, dict[str, Any]]:
-        """Serializes DataprocDeleteClusterTrigger arguments and classpath."""
-        return (
-            "airflow.providers.google.cloud.triggers.dataproc.DataprocDeleteClusterTrigger",
-            {
-                "cluster_name": self.cluster_name,
-                "end_time": self.end_time,
-                "project_id": self.project_id,
-                "region": self.region,
-                "metadata": self.metadata,
-                "gcp_conn_id": self.gcp_conn_id,
-                "impersonation_chain": self.impersonation_chain,
-                "polling_interval": self.polling_interval,
-            },
+    def __init__(self, **kwargs):
+        warnings.warn(
+            "Class `BigQueryTableExistenceAsyncSensor` is deprecated and "
+            "will be removed in a future release. "
+            "Please use `BigQueryTableExistenceSensor` and "
+            "set `deferrable` attribute to `True` instead",
+            DeprecationWarning,
         )
+        super().__init__(deferrable=True, **kwargs)
 
-    async def run(self) -> AsyncIterator["TriggerEvent"]:
-        """Wait until cluster is deleted completely"""
-        hook = self._get_hook()
-        while self.end_time > time.time():
-            try:
-                cluster = await hook.get_cluster(
-                    region=self.region,  # type: ignore[arg-type]
-                    cluster_name=self.cluster_name,
-                    project_id=self.project_id,  # type: ignore[arg-type]
-                    metadata=self.metadata,
-                )
-                self.log.info(
-                    "Cluster status is %s. Sleeping for %s seconds.",
-                    cluster.status.state,
-                    self.polling_interval,
-                )
-                await asyncio.sleep(self.polling_interval)
-            except NotFound:
-                yield TriggerEvent({"status": "success", "message": ""})
-            except Exception as e:
-                yield TriggerEvent({"status": "error", "message": str(e)})
-        yield TriggerEvent({"status": "error", "message": "Timeout"})
 
-    def _get_hook(self) -> DataprocAsyncHook:
-        return DataprocAsyncHook(
-            gcp_conn_id=self.gcp_conn_id,
-            impersonation_chain=self.impersonation_chain,
+class BigQueryTableExistencePartitionAsyncSensor(BigQueryTablePartitionExistenceSensor):
+    """
+    Checks for the existence of a partition within a table in Google BigQuery.
+
+    :param project_id: The Google cloud project in which to look for the table.
+       The connection supplied to the hook must provide
+       access to the specified project.
+    :param dataset_id: The name of the dataset in which to look for the table.
+       storage bucket.
+    :param partition_id: The name of the partition to check the existence of.
+    :param table_id: The name of the table to check the existence of.
+    :param gcp_conn_id: The connection ID used to connect to Google Cloud.
+    :param bigquery_conn_id: (Deprecated) The connection ID used to connect to Google Cloud.
+       This parameter has been deprecated. You should pass the gcp_conn_id parameter instead.
+    :param impersonation_chain: Optional service account to impersonate using short-term
+       credentials, or chained list of accounts required to get the access_token
+       of the last account in the list, which will be impersonated in the request.
+       If set as a string, the account must grant the originating account
+       the Service Account Token Creator IAM role.
+       If set as a sequence, the identities from the list must grant
+       Service Account Token Creator IAM role to the directly preceding identity, with first
+       account from the list granting this role to the originating account (templated).
+    :param poke_interval: The interval in seconds to wait between checks table existence.
+    """
+
+    def __init__(self, **kwargs):
+        warnings.warn(
+            "Class `BigQueryTableExistencePartitionAsyncSensor` is deprecated and "
+            "will be removed in a future release. "
+            "Please use `BigQueryTableExistencePartitionSensor` and "
+            "set `deferrable` attribute to `True` instead",
+            DeprecationWarning,
         )
+        super().__init__(deferrable=True, **kwargs)
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/gcs.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/gcs.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/triggers/mlengine.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/triggers/mlengine.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/bigquery.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/bigquery.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/bigquery_get_data.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/bigquery_get_data.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/credentials_provider.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/credentials_provider.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/dataform.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/dataform.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/field_sanitizer.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/field_sanitizer.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/field_validator.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/field_validator.py`

 * *Files 0% similar despite different names*

```diff
@@ -202,15 +202,15 @@
     @staticmethod
     def _sanity_checks(
         children_validation_specs: dict,
         field_type: str,
         full_field_path: str,
         regexp: str,
         allow_empty: bool,
-        custom_validation: Callable,
+        custom_validation: Callable | None,
         value,
     ) -> None:
         if value is None and field_type != "union":
             raise GcpFieldValidationException(
                 f"The required body field '{full_field_path}' is missing. Please add it."
             )
         if regexp and field_type:
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/helpers.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/helpers.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/mlengine_operator_utils.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/mlengine_operator_utils.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/cloud/utils/mlengine_prediction_summary.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/cloud/utils/mlengine_prediction_summary.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/auth_backend/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/auth_backend/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/auth_backend/google_openid.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/auth_backend/google_openid.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/consts.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/consts.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/hooks/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/hooks/base_google.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/hooks/base_google.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/hooks/discovery_api.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/hooks/discovery_api.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/links/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/links/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/links/storage.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/links/storage.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/utils/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/common/utils/id_token_credentials.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/common/utils/id_token_credentials.py`

 * *Files 7% similar despite different names*

```diff
@@ -32,17 +32,34 @@
 
 import json
 import os
 
 import google.auth.transport
 import google.oauth2
 from google.auth import credentials as google_auth_credentials, environment_vars, exceptions
-from google.auth._default import _AUTHORIZED_USER_TYPE, _HELP_MESSAGE, _SERVICE_ACCOUNT_TYPE, _VALID_TYPES
 from google.oauth2 import credentials as oauth2_credentials, service_account
 
+# Valid types accepted for file-based credentials.
+# They are taken  from "google.auth._default" and since they are all "protected" and the imports might
+# change any time and fail the whole Google provider functionality - we should inline them
+_AUTHORIZED_USER_TYPE = "authorized_user"
+_SERVICE_ACCOUNT_TYPE = "service_account"
+_EXTERNAL_ACCOUNT_TYPE = "external_account"
+_EXTERNAL_ACCOUNT_AUTHORIZED_USER_TYPE = "external_account_authorized_user"
+_IMPERSONATED_SERVICE_ACCOUNT_TYPE = "impersonated_service_account"
+_GDCH_SERVICE_ACCOUNT_TYPE = "gdch_service_account"
+_VALID_TYPES = (
+    _AUTHORIZED_USER_TYPE,
+    _SERVICE_ACCOUNT_TYPE,
+    _EXTERNAL_ACCOUNT_TYPE,
+    _EXTERNAL_ACCOUNT_AUTHORIZED_USER_TYPE,
+    _IMPERSONATED_SERVICE_ACCOUNT_TYPE,
+    _GDCH_SERVICE_ACCOUNT_TYPE,
+)
+
 
 class IDTokenCredentialsAdapter(google_auth_credentials.Credentials):
     """Convert Credentials with ``openid`` scope to IDTokenCredentials."""
 
     def __init__(self, credentials: oauth2_credentials.Credentials):
         super().__init__()
         self.credentials = credentials
@@ -194,15 +211,20 @@
     )
 
     for checker in checkers:
         current_credentials = checker()
         if current_credentials is not None:
             return current_credentials
 
-    raise exceptions.DefaultCredentialsError(_HELP_MESSAGE)
+    raise exceptions.DefaultCredentialsError(
+        f"""Could not automatically determine credentials. Please set {environment_vars.CREDENTIALS} or
+        explicitly create credentials and re-run the application. For more information, please see
+        https://cloud.google.com/docs/authentication/getting-started
+""".strip()
+    )
 
 
 if __name__ == "__main__":
     from google.auth.transport import requests
 
     request_adapter = requests.Request()
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/config_templates/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/config_templates/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/hooks/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/hooks/firestore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/hooks/firestore.py`

 * *Files 2% similar despite different names*

```diff
@@ -49,15 +49,15 @@
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account.
     """
 
-    _conn = None
+    _conn: build | None = None
 
     def __init__(
         self,
         api_version: str = "v1",
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/operators/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/operators/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/firebase/operators/firestore.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/firebase/operators/firestore.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/get_provider_info.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/get_provider_info.py`

 * *Files 1% similar despite different names*

```diff
@@ -23,15 +23,20 @@
 
 
 def get_provider_info():
     return {
         "package-name": "apache-airflow-providers-google",
         "name": "Google",
         "description": "Google services including:\n\n  - `Google Ads <https://ads.google.com/>`__\n  - `Google Cloud (GCP) <https://cloud.google.com/>`__\n  - `Google Firebase <https://firebase.google.com/>`__\n  - `Google LevelDB <https://github.com/google/leveldb/>`__\n  - `Google Marketing Platform <https://marketingplatform.google.com/>`__\n  - `Google Workspace <https://workspace.google.com/>`__ (formerly Google Suite)\n",
+        "suspended": False,
         "versions": [
+            "9.0.0",
+            "8.12.0",
+            "8.11.0",
+            "8.10.0",
             "8.9.0",
             "8.8.0",
             "8.7.0",
             "8.6.0",
             "8.5.0",
             "8.4.0",
             "8.3.0",
@@ -61,33 +66,39 @@
             "apache-airflow>=2.3.0",
             "apache-airflow-providers-common-sql>=1.3.1",
             "PyOpenSSL",
             "asgiref>=3.5.2",
             "gcloud-aio-auth>=4.0.0,<5.0.0",
             "gcloud-aio-bigquery>=6.1.2",
             "gcloud-aio-storage",
-            "google-ads>=15.1.1",
-            "google-api-core>=2.7.0,<3.0.0",
+            "googleapis-common-protos<2.0.0,>=1.5.8",
+            "google-api-core==2.8.2",
+            "google-auth-oauthlib<1.0.0,>=0.3.0",
+            "grpcio<2.0.0,>=1.38.1",
+            "grpcio-status<2.0.0,>=1.38.1",
+            "PyYAML<7.0,>=5.1",
+            "proto-plus==1.19.6",
+            "protobuf!=3.18.*,!=3.19.*,<=3.20.0,>=3.12.0",
             "google-api-python-client>=1.6.0,<2.0.0",
             "google-auth>=1.0.0",
             "google-auth-httplib2>=0.0.1",
             "google-cloud-aiplatform>=1.7.1,<2.0.0",
             "google-cloud-automl>=2.1.0",
             "google-cloud-bigquery-datatransfer>=3.0.0",
-            "google-cloud-bigtable>=1.0.0,<2.0.0",
+            "google-cloud-bigtable>=2.0.0,<3.0.0",
             "google-cloud-build>=3.0.0",
             "google-cloud-compute>=0.1.0,<2.0.0",
             "google-cloud-container>=2.2.0,<3.0.0",
-            "google-cloud-dataflow-client>=0.5.2,<0.5.5",
+            "google-cloud-dataflow-client>=0.5.2",
             "google-cloud-dataform>=0.2.0",
             "google-cloud-datacatalog>=3.0.0",
             "google-cloud-dataplex>=0.1.0",
             "google-cloud-dataproc>=3.1.0",
             "google-cloud-dataproc-metastore>=1.2.0,<2.0.0",
-            "google-cloud-dlp>=0.11.0,<2.0.0",
+            "google-cloud-dlp>=3.0.0",
             "google-cloud-kms>=2.0.0",
             "google-cloud-language>=1.1.1,<2.0.0",
             "google-cloud-logging>=2.1.1",
             "google-cloud-memcache>=0.2.0",
             "google-cloud-monitoring>=2.0.0",
             "google-cloud-os-login>=2.0.0",
             "google-cloud-orchestration-airflow>=1.0.0,<2.0.0",
@@ -106,16 +117,14 @@
             "grpcio-gcp>=0.2.2",
             "httpx",
             "json-merge-patch>=0.2",
             "looker-sdk>=22.2.0",
             "pandas-gbq",
             "pandas>=0.17.1",
             "sqlalchemy-bigquery>=1.2.1",
-            "proto-plus>=1.19.6",
-            "protobuf<=3.20.0",
         ],
         "integrations": [
             {
                 "integration-name": "Google Analytics360",
                 "external-doc-url": "https://analytics.google.com/",
                 "logo": "/integration-logos/gcp/Google-Analytics.png",
                 "how-to-guide": [
@@ -162,14 +171,20 @@
                 "integration-name": "Google Cloud Build",
                 "external-doc-url": "https://cloud.google.com/build/",
                 "how-to-guide": ["/docs/apache-airflow-providers-google/operators/cloud/cloud_build.rst"],
                 "logo": "/integration-logos/gcp/Cloud-Build.png",
                 "tags": ["gcp"],
             },
             {
+                "integration-name": "Google Cloud Common",
+                "external-doc-url": "https://cloud.google.com/",
+                "tags": ["gcp"],
+                "logo": "/integration-logos/gcp/Google.png",
+            },
+            {
                 "integration-name": "Google Cloud Composer",
                 "external-doc-url": "https://cloud.google.com/composer",
                 "how-to-guide": ["/docs/apache-airflow-providers-google/operators/cloud/cloud_composer.rst"],
                 "tags": ["google"],
             },
             {
                 "integration-name": "Google Cloud Dataform",
@@ -506,15 +521,15 @@
                 "integration-name": "Google Cloud Workflows",
                 "external-doc-url": "https://cloud.google.com/workflows/",
                 "how-to-guide": ["/docs/apache-airflow-providers-google/operators/cloud/workflows.rst"],
                 "tags": ["gcp"],
             },
             {
                 "integration-name": "Google LevelDB",
-                "external-doc-url": "https://github.com/google/leveldb/blob/master/doc/index.md",
+                "external-doc-url": "https://github.com/google/leveldb/blob/main/doc/index.md",
                 "how-to-guide": ["/docs/apache-airflow-providers-google/operators/leveldb/leveldb.rst"],
                 "tags": ["google"],
             },
             {
                 "integration-name": "Google Vertex AI",
                 "external-doc-url": "https://cloud.google.com/vertex-ai",
                 "how-to-guide": ["/docs/apache-airflow-providers-google/operators/cloud/vertex_ai.rst"],
@@ -530,14 +545,18 @@
         ],
         "operators": [
             {
                 "integration-name": "Google Ads",
                 "python-modules": ["airflow.providers.google.ads.operators.ads"],
             },
             {
+                "integration-name": "Google Cloud Common",
+                "python-modules": ["airflow.providers.google.cloud.operators.cloud_base"],
+            },
+            {
                 "integration-name": "Google AutoML",
                 "python-modules": ["airflow.providers.google.cloud.operators.automl"],
             },
             {
                 "integration-name": "Google BigQuery",
                 "python-modules": ["airflow.providers.google.cloud.operators.bigquery"],
             },
@@ -1032,14 +1051,56 @@
                 "python-modules": ["airflow.providers.google.cloud.hooks.looker"],
             },
             {
                 "integration-name": "Google Cloud Dataform",
                 "python-modules": ["airflow.providers.google.cloud.hooks.dataform"],
             },
         ],
+        "triggers": [
+            {
+                "integration-name": "Google BigQuery Data Transfer Service",
+                "python-modules": ["airflow.providers.google.cloud.triggers.bigquery_dts"],
+            },
+            {
+                "integration-name": "Google BigQuery",
+                "python-modules": ["airflow.providers.google.cloud.triggers.bigquery"],
+            },
+            {
+                "integration-name": "Google Cloud Build",
+                "python-modules": ["airflow.providers.google.cloud.triggers.cloud_build"],
+            },
+            {
+                "integration-name": "Google Cloud Composer",
+                "python-modules": ["airflow.providers.google.cloud.triggers.cloud_composer"],
+            },
+            {
+                "integration-name": "Google Dataflow",
+                "python-modules": ["airflow.providers.google.cloud.triggers.dataflow"],
+            },
+            {
+                "integration-name": "Google Data Fusion",
+                "python-modules": ["airflow.providers.google.cloud.triggers.datafusion"],
+            },
+            {
+                "integration-name": "Google Dataproc",
+                "python-modules": ["airflow.providers.google.cloud.triggers.dataproc"],
+            },
+            {
+                "integration-name": "Google Cloud Storage (GCS)",
+                "python-modules": ["airflow.providers.google.cloud.triggers.gcs"],
+            },
+            {
+                "integration-name": "Google Kubernetes Engine",
+                "python-modules": ["airflow.providers.google.cloud.triggers.kubernetes_engine"],
+            },
+            {
+                "integration-name": "Google Machine Learning Engine",
+                "python-modules": ["airflow.providers.google.cloud.triggers.mlengine"],
+            },
+        ],
         "transfers": [
             {
                 "source-integration-name": "Presto",
                 "target-integration-name": "Google Cloud Storage (GCS)",
                 "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/presto_to_gcs.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.presto_to_gcs",
             },
@@ -1110,24 +1171,27 @@
                 "source-integration-name": "PostgreSQL",
                 "target-integration-name": "Google Cloud Storage (GCS)",
                 "python-module": "airflow.providers.google.cloud.transfers.postgres_to_gcs",
             },
             {
                 "source-integration-name": "Google BigQuery",
                 "target-integration-name": "MySQL",
+                "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/bigquery_to_mysql.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.bigquery_to_mysql",
             },
             {
                 "source-integration-name": "Google BigQuery",
                 "target-integration-name": "Microsoft SQL Server (MSSQL)",
+                "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/bigquery_to_mssql.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.bigquery_to_mssql",
             },
             {
                 "source-integration-name": "Google Cloud Storage (GCS)",
                 "target-integration-name": "Google BigQuery",
+                "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/gcs_to_bigquery.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.gcs_to_bigquery",
             },
             {
                 "source-integration-name": "Google Cloud Storage (GCS)",
                 "target-integration-name": "Google Cloud Storage (GCS)",
                 "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/gcs_to_gcs.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.gcs_to_gcs",
@@ -1148,14 +1212,15 @@
                 "source-integration-name": "Microsoft Azure Data Lake Storage",
                 "target-integration-name": "Google Cloud Storage (GCS)",
                 "python-module": "airflow.providers.google.cloud.transfers.adls_to_gcs",
             },
             {
                 "source-integration-name": "Google BigQuery",
                 "target-integration-name": "Google BigQuery",
+                "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/bigquery_to_bigquery.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.bigquery_to_bigquery",
             },
             {
                 "source-integration-name": "MySQL",
                 "target-integration-name": "Google Cloud Storage (GCS)",
                 "python-module": "airflow.providers.google.cloud.transfers.mysql_to_gcs",
                 "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/mysql_to_gcs.rst",
@@ -1183,14 +1248,15 @@
                 "target-integration-name": "Google Cloud Storage (GCS)",
                 "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/local_to_gcs.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.local_to_gcs",
             },
             {
                 "source-integration-name": "Google BigQuery",
                 "target-integration-name": "Google Cloud Storage (GCS)",
+                "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/bigquery_to_gcs.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.bigquery_to_gcs",
             },
             {
                 "source-integration-name": "Google Cloud Storage (GCS)",
                 "target-integration-name": "Local",
                 "how-to-guide": "/docs/apache-airflow-providers-google/operators/transfer/gcs_to_local.rst",
                 "python-module": "airflow.providers.google.cloud.transfers.gcs_to_local",
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/go_module_utils.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/go_module_utils.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/hooks/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/hooks/leveldb.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/hooks/leveldb.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/operators/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/operators/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/leveldb/operators/leveldb.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/leveldb/operators/leveldb.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/example_dags/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/example_dags/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/example_dags/example_display_video.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/example_dags/example_display_video.py`

 * *Files 18% similar despite different names*

```diff
@@ -25,36 +25,40 @@
 from typing import cast
 
 from airflow import models
 from airflow.models.xcom_arg import XComArg
 from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GCSToBigQueryOperator
 from airflow.providers.google.marketing_platform.hooks.display_video import GoogleDisplayVideo360Hook
 from airflow.providers.google.marketing_platform.operators.display_video import (
+    GoogleDisplayVideo360CreateQueryOperator,
     GoogleDisplayVideo360CreateReportOperator,
     GoogleDisplayVideo360CreateSDFDownloadTaskOperator,
     GoogleDisplayVideo360DeleteReportOperator,
     GoogleDisplayVideo360DownloadLineItemsOperator,
     GoogleDisplayVideo360DownloadReportOperator,
+    GoogleDisplayVideo360DownloadReportV2Operator,
+    GoogleDisplayVideo360RunQueryOperator,
     GoogleDisplayVideo360RunReportOperator,
     GoogleDisplayVideo360SDFtoGCSOperator,
     GoogleDisplayVideo360UploadLineItemsOperator,
 )
 from airflow.providers.google.marketing_platform.sensors.display_video import (
     GoogleDisplayVideo360GetSDFDownloadOperationSensor,
     GoogleDisplayVideo360ReportSensor,
+    GoogleDisplayVideo360RunQuerySensor,
 )
 
 # [START howto_display_video_env_variables]
 BUCKET = os.environ.get("GMP_DISPLAY_VIDEO_BUCKET", "gs://INVALID BUCKET NAME")
 ADVERTISER_ID = os.environ.get("GMP_ADVERTISER_ID", 1234567)
 OBJECT_NAME = os.environ.get("GMP_OBJECT_NAME", "files/report.csv")
 PATH_TO_UPLOAD_FILE = os.environ.get("GCP_GCS_PATH_TO_UPLOAD_FILE", "test-gcs-example.txt")
 PATH_TO_SAVED_FILE = os.environ.get("GCP_GCS_PATH_TO_SAVED_FILE", "test-gcs-example-download.txt")
 BUCKET_FILE_LOCATION = PATH_TO_UPLOAD_FILE.rpartition("/")[-1]
-SDF_VERSION = os.environ.get("GMP_SDF_VERSION", "SDF_VERSION_5_1")
+SDF_VERSION = os.environ.get("GMP_SDF_VERSION", "SDF_VERSION_5_5")
 BQ_DATA_SET = os.environ.get("GMP_BQ_DATA_SET", "airflow_test")
 GMP_PARTNER_ID = os.environ.get("GMP_PARTNER_ID", 123)
 ENTITY_TYPE = os.environ.get("GMP_ENTITY_TYPE", "LineItem")
 ERF_SOURCE_OBJECT = GoogleDisplayVideo360Hook.erf_uri(GMP_PARTNER_ID, ENTITY_TYPE)
 
 REPORT = {
     "kind": "doubleclickbidmanager#query",
@@ -70,15 +74,33 @@
         "filters": [{"type": "FILTER_PARTNER", "value": 1486931}],
         "metrics": ["METRIC_IMPRESSIONS", "METRIC_CLICKS"],
         "includeInviteData": True,
     },
     "schedule": {"frequency": "ONE_TIME"},
 }
 
-PARAMETERS = {"dataRange": "LAST_14_DAYS", "timezoneCode": "America/New_York"}
+REPORT_V2 = {
+    "metadata": {
+        "title": "Airflow Test Report",
+        "dataRange": {"range": "LAST_7_DAYS"},
+        "format": "CSV",
+        "sendNotification": False,
+    },
+    "params": {
+        "type": "STANDARD",
+        "groupBys": ["FILTER_DATE", "FILTER_PARTNER"],
+        "filters": [{"type": "FILTER_PARTNER", "value": ADVERTISER_ID}],
+        "metrics": ["METRIC_IMPRESSIONS", "METRIC_CLICKS"],
+    },
+    "schedule": {"frequency": "ONE_TIME"},
+}
+
+PARAMETERS = {
+    "dataRange": {"range": "LAST_7_DAYS"},
+}
 
 CREATE_SDF_DOWNLOAD_TASK_BODY_REQUEST: dict = {
     "version": SDF_VERSION,
     "advertiserId": ADVERTISER_ID,
     "inventorySourceFilter": {"inventorySourceIds": []},
 }
 
@@ -205,7 +227,50 @@
     )
     # [END howto_google_display_video_gcs_to_big_query_operator]
 
     create_sdf_download_task >> wait_for_operation >> save_sdf_in_gcs
 
     # Task dependency created via `XComArgs`:
     #   save_sdf_in_gcs >> upload_sdf_to_big_query
+
+with models.DAG(
+    "example_display_video_v2",
+    start_date=START_DATE,
+    catchup=False,
+) as dag:
+    # [START howto_google_display_video_create_query_operator]
+    create_query_v2 = GoogleDisplayVideo360CreateQueryOperator(body=REPORT_V2, task_id="create_query")
+
+    query_id = cast(str, XComArg(create_query_v2, key="query_id"))
+    # [END howto_google_display_video_create_query_operator]
+
+    # [START howto_google_display_video_run_query_report_operator]
+    run_query_v2 = GoogleDisplayVideo360RunQueryOperator(
+        query_id=query_id, parameters=PARAMETERS, task_id="run_report"
+    )
+
+    query_id = cast(str, XComArg(run_query_v2, key="query_id"))
+    report_id = cast(str, XComArg(run_query_v2, key="report_id"))
+    # [END howto_google_display_video_run_query_report_operator]
+
+    # [START howto_google_display_video_wait_run_query_sensor]
+    wait_for_query = GoogleDisplayVideo360RunQuerySensor(
+        task_id="wait_for_query",
+        query_id=query_id,
+        report_id=report_id,
+    )
+    # [END howto_google_display_video_wait_run_query_sensor]
+
+    # [START howto_google_display_video_get_report_operator]
+    get_report_v2 = GoogleDisplayVideo360DownloadReportV2Operator(
+        query_id=query_id,
+        report_id=report_id,
+        task_id="get_report",
+        bucket_name=BUCKET,
+        report_name="test1.csv",
+    )
+    # # [END howto_google_display_video_get_report_operator]
+    # # [START howto_google_display_video_delete_query_report_operator]
+    delete_report_v2 = GoogleDisplayVideo360DeleteReportOperator(report_id=report_id, task_id="delete_report")
+    # # [END howto_google_display_video_delete_query_report_operator]
+
+    create_query_v2 >> run_query_v2 >> wait_for_query >> get_report_v2 >> delete_report_v2
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/analytics.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/analytics.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/campaign_manager.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/campaign_manager.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/hooks/search_ads.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/hooks/search_ads.py`

 * *Files 4% similar despite different names*

```diff
@@ -24,15 +24,15 @@
 
 from airflow.providers.google.common.hooks.base_google import GoogleBaseHook
 
 
 class GoogleSearchAdsHook(GoogleBaseHook):
     """Hook for Google Search Ads 360."""
 
-    _conn = None
+    _conn: build | None = None
 
     def __init__(
         self,
         api_version: str = "v2",
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/campaign_manager.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/campaign_manager.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/display_video.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/display_video.py`

 * *Files 14% similar despite different names*

```diff
@@ -19,14 +19,15 @@
 from __future__ import annotations
 
 import csv
 import json
 import shutil
 import tempfile
 import urllib.request
+import warnings
 from typing import TYPE_CHECKING, Any, Sequence
 from urllib.parse import urlsplit
 
 from airflow.exceptions import AirflowException
 from airflow.models import BaseOperator
 from airflow.providers.google.cloud.hooks.gcs import GCSHook
 from airflow.providers.google.marketing_platform.hooks.display_video import GoogleDisplayVideo360Hook
@@ -78,14 +79,19 @@
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.body = body
+
+        warnings.warn(
+            "This operator is deprecated. Please use `GoogleDisplayVideo360CreateQueryOperator`",
+            DeprecationWarning,
+        )
         self.api_version = api_version
         self.gcp_conn_id = gcp_conn_id
         self.delegate_to = delegate_to
         self.impersonation_chain = impersonation_chain
 
     def prepare_template(self) -> None:
         # If .json is passed then we have to read the file
@@ -104,25 +110,98 @@
         response = hook.create_query(query=self.body)
         report_id = response["queryId"]
         self.xcom_push(context, key="report_id", value=report_id)
         self.log.info("Created report with ID: %s", report_id)
         return response
 
 
+class GoogleDisplayVideo360CreateQueryOperator(BaseOperator):
+    """
+    Creates a query.
+
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        ``GoogleDisplayVideo360CreateQueryOperator``
+
+    .. seealso::
+        Check also the official API docs:
+        `https://developers.google.com/bid-manager/v2/queries/create`
+
+    :param body: Report object passed to the request's body as described here:
+        https://developers.google.com/bid-manager/v2/queries#Query
+    :param api_version: The version of the api that will be requested for example 'v3'.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
+    :param impersonation_chain: Optional service account to impersonate using short-term
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
+    """
+
+    template_fields: Sequence[str] = (
+        "body",
+        "impersonation_chain",
+    )
+    template_ext: Sequence[str] = (".json",)
+
+    def __init__(
+        self,
+        *,
+        body: dict[str, Any],
+        api_version: str = "v2",
+        gcp_conn_id: str = "google_cloud_default",
+        delegate_to: str | None = None,
+        impersonation_chain: str | Sequence[str] | None = None,
+        **kwargs,
+    ) -> None:
+        super().__init__(**kwargs)
+        self.body = body
+        self.api_version = api_version
+        self.gcp_conn_id = gcp_conn_id
+        self.delegate_to = delegate_to
+        self.impersonation_chain = impersonation_chain
+
+    def prepare_template(self) -> None:
+        # If .json is passed then we have to read the file
+        if isinstance(self.body, str) and self.body.endswith(".json"):
+            with open(self.body) as file:
+                self.body = json.load(file)
+
+    def execute(self, context: Context) -> dict:
+        hook = GoogleDisplayVideo360Hook(
+            gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
+            api_version=self.api_version,
+            impersonation_chain=self.impersonation_chain,
+        )
+        self.log.info("Creating Display & Video 360 query.")
+        response = hook.create_query(query=self.body)
+        query_id = response["queryId"]
+        self.xcom_push(context, key="query_id", value=query_id)
+        self.log.info("Created query with ID: %s", query_id)
+        return response
+
+
 class GoogleDisplayVideo360DeleteReportOperator(BaseOperator):
     """
     Deletes a stored query as well as the associated stored reports.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:GoogleDisplayVideo360DeleteReportOperator`
 
     .. seealso::
         Check also the official API docs:
-        `https://developers.google.com/bid-manager/v1/queries/deletequery`
+        `https://developers.google.com/bid-manager/v2/queries/delete`
 
     :param report_id: Report ID to delete.
     :param report_name: Name of the report to delete.
     :param api_version: The version of the api that will be requested for example 'v3'.
     :param gcp_conn_id: The connection ID to use when fetching connection info.
     :param delegate_to: The account to impersonate using domain-wide delegation of authority,
         if any. For this to work, the service account making the request must have
@@ -143,23 +222,28 @@
     )
 
     def __init__(
         self,
         *,
         report_id: str | None = None,
         report_name: str | None = None,
-        api_version: str = "v1",
+        api_version: str = "v2",
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.report_id = report_id
         self.report_name = report_name
+        if api_version in ["v1", "v1.1"]:
+            warnings.warn(
+                f"API {api_version} is deprecated and shortly will be removed please use v2",
+                DeprecationWarning,
+            )
         self.api_version = api_version
         self.gcp_conn_id = gcp_conn_id
         self.delegate_to = delegate_to
         self.impersonation_chain = impersonation_chain
 
         if report_name and report_id:
             raise AirflowException("Use only one value - `report_name` or `report_id`.")
@@ -238,14 +322,18 @@
         api_version: str = "v1",
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
+        warnings.warn(
+            "This operator is deprecated. Please use `GoogleDisplayVideo360DownloadReportV2Operator`",
+            DeprecationWarning,
+        )
         self.report_id = report_id
         self.chunk_size = chunk_size
         self.gzip = gzip
         self.bucket_name = bucket_name
         self.report_name = report_name
         self.api_version = api_version
         self.gcp_conn_id = gcp_conn_id
@@ -306,14 +394,139 @@
             self.report_id,
             self.bucket_name,
             report_name,
         )
         self.xcom_push(context, key="report_name", value=report_name)
 
 
+class GoogleDisplayVideo360DownloadReportV2Operator(BaseOperator):
+    """
+    Retrieves a stored query.
+
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:GoogleDisplayVideo360DownloadReportV2Operator`
+
+    .. seealso::
+        Check also the official API docs:
+        `https://developers.google.com/bid-manager/v2/queries/get`
+
+    :param report_id: Report ID to retrieve.
+    :param bucket_name: The bucket to upload to.
+    :param report_name: The report name to set when uploading the local file.
+    :param chunk_size: File will be downloaded in chunks of this many bytes.
+    :param gzip: Option to compress local file or file data for upload
+    :param api_version: The version of the api that will be requested for example 'v3'.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
+    :param impersonation_chain: Optional service account to impersonate using short-term
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
+    """
+
+    template_fields: Sequence[str] = (
+        "query_id",
+        "report_id",
+        "bucket_name",
+        "report_name",
+        "impersonation_chain",
+    )
+
+    def __init__(
+        self,
+        *,
+        query_id: str,
+        report_id: str,
+        bucket_name: str,
+        report_name: str | None = None,
+        gzip: bool = True,
+        chunk_size: int = 10 * 1024 * 1024,
+        api_version: str = "v2",
+        gcp_conn_id: str = "google_cloud_default",
+        delegate_to: str | None = None,
+        impersonation_chain: str | Sequence[str] | None = None,
+        **kwargs,
+    ) -> None:
+        super().__init__(**kwargs)
+        self.query_id = query_id
+        self.report_id = report_id
+        self.chunk_size = chunk_size
+        self.gzip = gzip
+        self.bucket_name = bucket_name
+        self.report_name = report_name
+        self.api_version = api_version
+        self.gcp_conn_id = gcp_conn_id
+        self.delegate_to = delegate_to
+        self.impersonation_chain = impersonation_chain
+
+    def _resolve_file_name(self, name: str) -> str:
+        new_name = name if name.endswith(".csv") else f"{name}.csv"
+        new_name = f"{new_name}.gz" if self.gzip else new_name
+        return new_name
+
+    @staticmethod
+    def _set_bucket_name(name: str) -> str:
+        bucket = name if not name.startswith("gs://") else name[5:]
+        return bucket.strip("/")
+
+    def execute(self, context: Context):
+        hook = GoogleDisplayVideo360Hook(
+            gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
+            api_version=self.api_version,
+            impersonation_chain=self.impersonation_chain,
+        )
+        gcs_hook = GCSHook(
+            gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
+            impersonation_chain=self.impersonation_chain,
+        )
+
+        resource = hook.get_report(query_id=self.query_id, report_id=self.report_id)
+        status = resource.get("metadata", {}).get("status", {}).get("state")
+        if resource and status not in ["DONE", "FAILED"]:
+            raise AirflowException(f"Report {self.report_id} for query {self.query_id} is still running")
+
+        # If no custom report_name provided, use DV360 name
+        file_url = resource["metadata"]["googleCloudStoragePath"]
+        report_name = self.report_name or urlsplit(file_url).path.split("/")[-1]
+        report_name = self._resolve_file_name(report_name)
+
+        # Download the report
+        self.log.info("Starting downloading report %s", self.report_id)
+        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
+            with urllib.request.urlopen(file_url) as response:
+                shutil.copyfileobj(response, temp_file, length=self.chunk_size)
+
+            temp_file.flush()
+            # Upload the local file to bucket
+            bucket_name = self._set_bucket_name(self.bucket_name)
+            gcs_hook.upload(
+                bucket_name=bucket_name,
+                object_name=report_name,
+                gzip=self.gzip,
+                filename=temp_file.name,
+                mime_type="text/csv",
+            )
+        self.log.info(
+            "Report %s was saved in bucket %s as %s.",
+            self.report_id,
+            self.bucket_name,
+            report_name,
+        )
+        self.xcom_push(context, key="report_name", value=report_name)
+
+
 class GoogleDisplayVideo360RunReportOperator(BaseOperator):
     """
     Runs a stored query to generate a report.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:GoogleDisplayVideo360RunReportOperator`
@@ -355,14 +568,18 @@
         gcp_conn_id: str = "google_cloud_default",
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.report_id = report_id
+        warnings.warn(
+            "This operator is deprecated. Please use `GoogleDisplayVideo360RunQueryOperator`",
+            DeprecationWarning,
+        )
         self.api_version = api_version
         self.gcp_conn_id = gcp_conn_id
         self.delegate_to = delegate_to
         self.parameters = parameters
         self.impersonation_chain = impersonation_chain
 
     def execute(self, context: Context) -> None:
@@ -376,14 +593,87 @@
             "Running report %s with the following parameters:\n %s",
             self.report_id,
             self.parameters,
         )
         hook.run_query(query_id=self.report_id, params=self.parameters)
 
 
+class GoogleDisplayVideo360RunQueryOperator(BaseOperator):
+    """
+    Runs a stored query to generate a report.
+
+    .. seealso::
+        For more information on how to use this operator, take a look at the guide:
+        :ref:`howto/operator:GoogleDisplayVideo360RunQueryOperator`
+
+    .. seealso::
+        Check also the official API docs:
+        `https://developers.google.com/bid-manager/v2/queries/run`
+
+    :param report_id: Report ID to run.
+    :param parameters: Parameters for running a report as described here:
+        https://developers.google.com/bid-manager/v2/queries/run
+    :param api_version: The version of the api that will be requested for example 'v3'.
+    :param gcp_conn_id: The connection ID to use when fetching connection info.
+    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
+        if any. For this to work, the service account making the request must have
+        domain-wide delegation enabled.
+    :param impersonation_chain: Optional service account to impersonate using short-term
+        credentials, or chained list of accounts required to get the access_token
+        of the last account in the list, which will be impersonated in the request.
+        If set as a string, the account must grant the originating account
+        the Service Account Token Creator IAM role.
+        If set as a sequence, the identities from the list must grant
+        Service Account Token Creator IAM role to the directly preceding identity, with first
+        account from the list granting this role to the originating account (templated).
+    """
+
+    template_fields: Sequence[str] = (
+        "query_id",
+        "parameters",
+        "impersonation_chain",
+    )
+
+    def __init__(
+        self,
+        *,
+        query_id: str,
+        parameters: dict[str, Any] | None = None,
+        api_version: str = "v2",
+        gcp_conn_id: str = "google_cloud_default",
+        delegate_to: str | None = None,
+        impersonation_chain: str | Sequence[str] | None = None,
+        **kwargs,
+    ) -> None:
+        super().__init__(**kwargs)
+        self.query_id = query_id
+        self.api_version = api_version
+        self.gcp_conn_id = gcp_conn_id
+        self.delegate_to = delegate_to
+        self.parameters = parameters
+        self.impersonation_chain = impersonation_chain
+
+    def execute(self, context: Context) -> dict:
+        hook = GoogleDisplayVideo360Hook(
+            gcp_conn_id=self.gcp_conn_id,
+            delegate_to=self.delegate_to,
+            api_version=self.api_version,
+            impersonation_chain=self.impersonation_chain,
+        )
+        self.log.info(
+            "Running query %s with the following parameters:\n %s",
+            self.query_id,
+            self.parameters,
+        )
+        response = hook.run_query(query_id=self.query_id, params=self.parameters)
+        self.xcom_push(context, key="query_id", value=response["key"]["queryId"])
+        self.xcom_push(context, key="report_id", value=response["key"]["reportId"])
+        return response
+
+
 class GoogleDisplayVideo360DownloadLineItemsOperator(BaseOperator):
     """
     Retrieves line items in CSV format.
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:GoogleDisplayVideo360DownloadLineItemsOperator`
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/operators/search_ads.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/operators/search_ads.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/sensors/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/sensors/campaign_manager.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/campaign_manager.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/marketing_platform/sensors/search_ads.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/marketing_platform/sensors/search_ads.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/calendar.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/calendar.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/drive.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/drive.py`

 * *Files 10% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 # under the License.
 """Hook for Google Drive service"""
 from __future__ import annotations
 
 from typing import IO, Any, Sequence
 
 from googleapiclient.discovery import Resource, build
+from googleapiclient.errors import Error as GoogleApiClientError
 from googleapiclient.http import HttpRequest, MediaFileUpload
 
 from airflow.providers.google.common.hooks.base_google import GoogleBaseHook
 
 
 class GoogleDriveHook(GoogleBaseHook):
     """
@@ -68,31 +69,37 @@
         :return: Google Drive services object.
         """
         if not self._conn:
             http_authorized = self._authorize()
             self._conn = build("drive", self.api_version, http=http_authorized, cache_discovery=False)
         return self._conn
 
-    def _ensure_folders_exists(self, path: str) -> str:
+    def _ensure_folders_exists(self, path: str, folder_id: str) -> str:
         service = self.get_conn()
-        current_parent = "root"
+        current_parent = folder_id
         folders = path.split("/")
         depth = 0
         # First tries to enter directories
         for current_folder in folders:
             self.log.debug("Looking for %s directory with %s parent", current_folder, current_parent)
             conditions = [
                 "trashed=false",
                 "mimeType='application/vnd.google-apps.folder'",
                 f"name='{current_folder}'",
                 f"'{current_parent}' in parents",
             ]
             result = (
                 service.files()
-                .list(q=" and ".join(conditions), spaces="drive", fields="files(id, name)")
+                .list(
+                    q=" and ".join(conditions),
+                    spaces="drive",
+                    fields="files(id, name)",
+                    includeItemsFromAllDrives=True,
+                    supportsAllDrives=True,
+                )
                 .execute(num_retries=self.num_retries)
             )
             files = result.get("files", [])
             if not files:
                 self.log.info("Not found %s directory", current_folder)
                 # If the directory does not exist, break loops
                 break
@@ -106,15 +113,19 @@
                 file_metadata = {
                     "name": current_folder,
                     "mimeType": "application/vnd.google-apps.folder",
                     "parents": [current_parent],
                 }
                 file = (
                     service.files()
-                    .create(body=file_metadata, fields="id")
+                    .create(
+                        body=file_metadata,
+                        fields="id",
+                        supportsAllDrives=True,
+                    )
                     .execute(num_retries=self.num_retries)
                 )
                 self.log.info("Created %s directory", current_folder)
 
                 current_parent = file.get("id")
         # Return the ID of the last directory
         return current_parent
@@ -145,14 +156,60 @@
         """
         return bool(
             self.get_file_id(
                 folder_id=folder_id, file_name=file_name, include_trashed=include_trashed, drive_id=drive_id
             )
         )
 
+    def _get_file_info(self, file_id: str):
+        """
+        Returns Google API file_info object containing id, name, parents in the response
+        https://developers.google.com/drive/api/v3/reference/files/get
+
+        :param file_id: id as string representation of interested file
+        :return: file
+        """
+        file_info = (
+            self.get_conn()
+            .files()
+            .get(
+                fileId=file_id,
+                fields="id,name,parents",
+                supportsAllDrives=True,
+            )
+            .execute(num_retries=2)
+        )
+        return file_info
+
+    def _resolve_file_path(self, file_id: str) -> str:
+        """
+        Returns the full Google Drive path for given file_id
+
+        :param file_id: The id of a file in Google Drive
+        :return: Google Drive full path for a file
+        """
+        has_reached_root = False
+        current_file_id = file_id
+        path: str = ""
+        while not has_reached_root:
+            # current_file_id can be file or directory id, Google API treats them the same way.
+            file_info = self._get_file_info(current_file_id)
+            if current_file_id == file_id:
+                path = f'{file_info["name"]}'
+            else:
+                path = f'{file_info["name"]}/{path}'
+
+            # Google API returns parents array if there is at least one object inside
+            if "parents" in file_info and len(file_info["parents"]) == 1:
+                # https://developers.google.com/drive/api/guides/ref-single-parent
+                current_file_id = file_info["parents"][0]
+            else:
+                has_reached_root = True
+        return path
+
     def get_file_id(
         self, folder_id: str, file_name: str, drive_id: str | None = None, *, include_trashed: bool = True
     ) -> dict:
         """
         Returns the file id of a Google Drive file
 
         :param folder_id: The id of the Google Drive folder in which the file resides
@@ -198,45 +255,62 @@
 
     def upload_file(
         self,
         local_location: str,
         remote_location: str,
         chunk_size: int = 100 * 1024 * 1024,
         resumable: bool = False,
+        folder_id: str = "root",
+        show_full_target_path: bool = True,
     ) -> str:
         """
         Uploads a file that is available locally to a Google Drive service.
 
         :param local_location: The path where the file is available.
         :param remote_location: The path where the file will be send
         :param chunk_size: File will be uploaded in chunks of this many bytes. Only
             used if resumable=True. Pass in a value of -1 if the file is to be
             uploaded as a single chunk. Note that Google App Engine has a 5MB limit
             on request size, so you should never set your chunk size larger than 5MB,
             or to -1.
         :param resumable: True if this is a resumable upload. False means upload
             in a single request.
+        :param folder_id: The base/root folder id for remote_location (part of the drive URL of a folder).
+        :param show_full_target_path: If true then it reveals full available file path in the logs.
         :return: File ID
         """
         service = self.get_conn()
         directory_path, _, file_name = remote_location.rpartition("/")
         if directory_path:
-            parent = self._ensure_folders_exists(directory_path)
+            parent = self._ensure_folders_exists(path=directory_path, folder_id=folder_id)
         else:
-            parent = "root"
+            parent = folder_id
 
         file_metadata = {"name": file_name, "parents": [parent]}
         media = MediaFileUpload(local_location, chunksize=chunk_size, resumable=resumable)
         file = (
             service.files()
             .create(body=file_metadata, media_body=media, fields="id", supportsAllDrives=True)
             .execute(num_retries=self.num_retries)
         )
-        self.log.info("File %s uploaded to gdrive://%s.", local_location, remote_location)
-        return file.get("id")
+        file_id = file.get("id")
+
+        upload_location = remote_location
+
+        if folder_id != "root":
+            try:
+                upload_location = self._resolve_file_path(folder_id)
+            except GoogleApiClientError as e:
+                self.log.warning("A problem has been encountered when trying to resolve file path: ", e)
+
+        if show_full_target_path:
+            self.log.info("File %s uploaded to gdrive://%s.", local_location, upload_location)
+        else:
+            self.log.info("File %s has been uploaded successfully to gdrive", local_location)
+        return file_id
 
     def download_file(self, file_id: str, file_handle: IO, chunk_size: int = 100 * 1024 * 1024):
         """
         Download a file from Google Drive.
 
         :param file_id: the id of the file
         :param file_handle: file handle used to write the content to
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/hooks/sheets.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/hooks/sheets.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/operators/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/operators/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/operators/sheets.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/operators/sheets.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/sensors/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/sensors/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/sensors/drive.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/sensors/drive.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/__init__.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/__init__.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/gcs_to_gdrive.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/gcs_to_gdrive.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/gcs_to_sheets.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/gcs_to_sheets.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/local_to_drive.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/local_to_drive.py`

 * *Files 10% similar despite different names*

```diff
@@ -36,15 +36,16 @@
     The local files can be deleted after upload (optional)
 
     .. seealso::
         For more information on how to use this operator, take a look at the guide:
         :ref:`howto/operator:LocalFilesystemToGoogleDriveOperator`
 
     :param local_paths: Python list of local file paths
-    :param drive_folder: path of the Drive folder
+    :param drive_folder: path of the Drive folder, if folder_id param is given then drive_folder is a
+        sub path of folder_id.
     :param gcp_conn_id: Airflow Connection ID for GCP
     :param delete: should the local files be deleted after upload?
     :param ignore_if_missing: if True, then don't fail even if all files
         can't be uploaded.
     :param chunk_size: File will be uploaded in chunks of this many bytes. Only
         used if resumable=True. Pass in a value of -1 if the file is to be
         uploaded as a single chunk. Note that Google App Engine has a 5MB limit
@@ -59,14 +60,16 @@
         credentials, or chained list of accounts required to get the access_token
         of the last account in the list, which will be impersonated in the request.
         If set as a string, the account must grant the originating account
         the Service Account Token Creator IAM role.
         If set as a sequence, the identities from the list must grant
         Service Account Token Creator IAM role to the directly preceding identity, with first
         account from the list granting this role to the originating account
+    :param folder_id: The base/root folder id for each local path in the Drive folder
+    :param show_full_target_path: If true then it reveals full available file path in the logs.
     :return: Remote file ids after upload
     """
 
     template_fields = (
         "local_paths",
         "drive_folder",
     )
@@ -78,26 +81,30 @@
         gcp_conn_id: str = "google_cloud_default",
         delete: bool = False,
         ignore_if_missing: bool = False,
         chunk_size: int = 100 * 1024 * 1024,
         resumable: bool = False,
         delegate_to: str | None = None,
         impersonation_chain: str | Sequence[str] | None = None,
+        folder_id: str = "root",
+        show_full_target_path: bool = True,
         **kwargs,
     ) -> None:
         super().__init__(**kwargs)
         self.local_paths = local_paths
         self.drive_folder = drive_folder
         self.gcp_conn_id = gcp_conn_id
         self.delete = delete
         self.ignore_if_missing = ignore_if_missing
         self.chunk_size = chunk_size
         self.resumable = resumable
         self.delegate_to = delegate_to
         self.impersonation_chain = impersonation_chain
+        self.folder_id = folder_id
+        self.show_full_target_path = show_full_target_path
 
     def execute(self, context: Context) -> list[str]:
         hook = GoogleDriveHook(
             gcp_conn_id=self.gcp_conn_id,
             delegate_to=self.delegate_to,
             impersonation_chain=self.impersonation_chain,
         )
@@ -109,14 +116,16 @@
 
             try:
                 remote_file_id = hook.upload_file(
                     local_location=str(local_path),
                     remote_location=str(Path(self.drive_folder) / Path(local_path).name),
                     chunk_size=self.chunk_size,
                     resumable=self.resumable,
+                    folder_id=self.folder_id,
+                    show_full_target_path=self.show_full_target_path,
                 )
 
                 remote_file_ids.append(remote_file_id)
 
                 if self.delete:
                     os.remove(local_path)
                     self.log.info("Deleted local file: %s", local_path)
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/airflow/providers/google/suite/transfers/sql_to_sheets.py` & `apache-airflow-providers-google-9.0.0rc1/airflow/providers/google/suite/transfers/sql_to_sheets.py`

 * *Files identical despite different names*

### Comparing `apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/PKG-INFO` & `apache-airflow-providers-google-9.0.0rc1/README.rst`

 * *Files 6% similar despite different names*

```diff
@@ -1,58 +1,7 @@
-Metadata-Version: 2.1
-Name: apache-airflow-providers-google
-Version: 8.9.0rc1
-Summary: Provider for Apache Airflow. Implements apache-airflow-providers-google package
-Home-page: https://airflow.apache.org/
-Author: Apache Software Foundation
-Author-email: dev@airflow.apache.org
-License: Apache License 2.0
-Download-URL: https://archive.apache.org/dist/airflow/providers
-Project-URL: Documentation, https://airflow.apache.org/docs/apache-airflow-providers-google/8.9.0/
-Project-URL: Bug Tracker, https://github.com/apache/airflow/issues
-Project-URL: Source Code, https://github.com/apache/airflow
-Project-URL: Slack Chat, https://s.apache.org/airflow-slack
-Project-URL: Twitter, https://twitter.com/ApacheAirflow
-Project-URL: YouTube, https://www.youtube.com/channel/UCSXwxpWZQ7XZ1WL3wqevChA/
-Platform: UNKNOWN
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Environment :: Console
-Classifier: Environment :: Web Environment
-Classifier: Intended Audience :: Developers
-Classifier: Intended Audience :: System Administrators
-Classifier: Framework :: Apache Airflow
-Classifier: Framework :: Apache Airflow :: Provider
-Classifier: License :: OSI Approved :: Apache Software License
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Topic :: System :: Monitoring
-Requires-Python: ~=3.7
-Description-Content-Type: text/x-rst
-Provides-Extra: amazon
-Provides-Extra: apache.beam
-Provides-Extra: apache.cassandra
-Provides-Extra: cncf.kubernetes
-Provides-Extra: common.sql
-Provides-Extra: facebook
-Provides-Extra: microsoft.azure
-Provides-Extra: microsoft.mssql
-Provides-Extra: mysql
-Provides-Extra: oracle
-Provides-Extra: postgres
-Provides-Extra: presto
-Provides-Extra: salesforce
-Provides-Extra: sftp
-Provides-Extra: ssh
-Provides-Extra: trino
-Provides-Extra: leveldb
-License-File: LICENSE
-License-File: NOTICE
-
 
 .. Licensed to the Apache Software Foundation (ASF) under one
    or more contributor license agreements.  See the NOTICE file
    distributed with this work for additional information
    regarding copyright ownership.  The ASF licenses this file
    to you under the Apache License, Version 2.0 (the
    "License"); you may not use this file except in compliance
@@ -66,15 +15,15 @@
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.
 
 
 Package ``apache-airflow-providers-google``
 
-Release: ``8.9.0rc1``
+Release: ``9.0.0rc1``
 
 
 Google services including:
 
   - `Google Ads <https://ads.google.com/>`__
   - `Google Cloud (GCP) <https://cloud.google.com/>`__
   - `Google Firebase <https://firebase.google.com/>`__
@@ -86,58 +35,64 @@
 Provider package
 ----------------
 
 This is a provider package for ``google`` provider. All classes for this provider package
 are in ``airflow.providers.google`` python package.
 
 You can find package information and changelog for the provider
-in the `documentation <https://airflow.apache.org/docs/apache-airflow-providers-google/8.9.0/>`_.
+in the `documentation <https://airflow.apache.org/docs/apache-airflow-providers-google/9.0.0/>`_.
 
 
 Installation
 ------------
 
 You can install this package on top of an existing Airflow 2 installation (see ``Requirements`` below
 for the minimum Airflow version supported) via
 ``pip install apache-airflow-providers-google``
 
 The package supports the following python versions: 3.7,3.8,3.9,3.10
 
 Requirements
 ------------
 
-=======================================  ===================
+=======================================  ======================================
 PIP package                              Version required
-=======================================  ===================
+=======================================  ======================================
 ``apache-airflow``                       ``>=2.3.0``
 ``apache-airflow-providers-common-sql``  ``>=1.3.1``
 ``PyOpenSSL``
 ``asgiref``                              ``>=3.5.2``
 ``gcloud-aio-auth``                      ``>=4.0.0,<5.0.0``
 ``gcloud-aio-bigquery``                  ``>=6.1.2``
 ``gcloud-aio-storage``
-``google-ads``                           ``>=15.1.1``
-``google-api-core``                      ``>=2.7.0,<3.0.0``
+``googleapis-common-protos``             ``<2.0.0,>=1.5.8``
+``google-api-core``                      ``==2.8.2``
+``google-auth-oauthlib``                 ``<1.0.0,>=0.3.0``
+``grpcio``                               ``<2.0.0,>=1.38.1``
+``grpcio-status``                        ``<2.0.0,>=1.38.1``
+``PyYAML``                               ``<7.0,>=5.1``
+``proto-plus``                           ``==1.19.6``
+``protobuf!``                            ``=3.18.*,!=3.19.*,<=3.20.0,>=3.12.0``
 ``google-api-python-client``             ``>=1.6.0,<2.0.0``
 ``google-auth``                          ``>=1.0.0``
 ``google-auth-httplib2``                 ``>=0.0.1``
 ``google-cloud-aiplatform``              ``>=1.7.1,<2.0.0``
 ``google-cloud-automl``                  ``>=2.1.0``
 ``google-cloud-bigquery-datatransfer``   ``>=3.0.0``
-``google-cloud-bigtable``                ``>=1.0.0,<2.0.0``
+``google-cloud-bigtable``                ``>=2.0.0,<3.0.0``
 ``google-cloud-build``                   ``>=3.0.0``
 ``google-cloud-compute``                 ``>=0.1.0,<2.0.0``
 ``google-cloud-container``               ``>=2.2.0,<3.0.0``
-``google-cloud-dataflow-client``         ``>=0.5.2,<0.5.5``
+``google-cloud-dataflow-client``         ``>=0.5.2``
 ``google-cloud-dataform``                ``>=0.2.0``
 ``google-cloud-datacatalog``             ``>=3.0.0``
 ``google-cloud-dataplex``                ``>=0.1.0``
 ``google-cloud-dataproc``                ``>=3.1.0``
 ``google-cloud-dataproc-metastore``      ``>=1.2.0,<2.0.0``
-``google-cloud-dlp``                     ``>=0.11.0,<2.0.0``
+``google-cloud-dlp``                     ``>=3.0.0``
 ``google-cloud-kms``                     ``>=2.0.0``
 ``google-cloud-language``                ``>=1.1.1,<2.0.0``
 ``google-cloud-logging``                 ``>=2.1.1``
 ``google-cloud-memcache``                ``>=0.2.0``
 ``google-cloud-monitoring``              ``>=2.0.0``
 ``google-cloud-os-login``                ``>=2.0.0``
 ``google-cloud-orchestration-airflow``   ``>=1.0.0,<2.0.0``
@@ -156,17 +111,15 @@
 ``grpcio-gcp``                           ``>=0.2.2``
 ``httpx``
 ``json-merge-patch``                     ``>=0.2``
 ``looker-sdk``                           ``>=22.2.0``
 ``pandas-gbq``
 ``pandas``                               ``>=0.17.1``
 ``sqlalchemy-bigquery``                  ``>=1.2.1``
-``proto-plus``                           ``>=1.19.6``
-``protobuf``                             ``<=3.20.0``
-=======================================  ===================
+=======================================  ======================================
 
 Cross provider package dependencies
 -----------------------------------
 
 Those are dependencies that might be needed in order to use all the features of the package.
 You need to install the specified provider packages in order to use them.
 
@@ -219,14 +172,146 @@
    Please, only add notes to the Changelog just below the "Changelog" header when there are some breaking changes
    and you want to add an explanation to the users on how they are supposed to deal with them.
    The changelog is updated and maintained semi-automatically by release manager.
 
 Changelog
 ---------
 
+9.0.0
+.....
+
+Breaking changes
+~~~~~~~~~~~~~~~~
+
+Google  announced sunset of Bid manager API v1 and v1.1 by April 27, 2023 for more information
+please check: `docs <https://developers.google.com/bid-manager/v1.1>`_  As a result default value of api_version
+in GoogleDisplayVideo360Hook and related operators updated to v2
+
+This version of provider contains a temporary workaround to issue with ``v11`` version of
+google-ads API being discontinued, while the google provider dependencies preventing installing
+any google-ads client supporting ``v12`` API. This version contains vendored-in version of google-ads
+library ``20.0.0`` v12 support only. The workaround (and vendored-in library) will be removed
+as soon as dependencies of the provider will allow to use google-ads supporting newer
+API versions of google-ads.
+
+.. note::
+
+  ONLY v12 version of google ads is supported. You should set v12 when your create an operator or client.
+
+* ``Update DV360 operators to use API v2 (#30326)``
+* ``Fix dynamic imports in google ads vendored in library (#30544)``
+
+Features
+~~~~~~~~
+
+* ``Add deferrable mode to GKEStartPodOperator (#29266)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``BigQueryHook list_rows/get_datasets_list can return iterator (#30543)``
+* ``Fix cloud build async credentials (#30441)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``Add mechanism to suspend providers (#30422)``
+   * ``Small quotation fix (#30448)``
+
+8.12.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add missing 'poll_interval' in Bigquery operator (#30132)``
+* ``Add poll_interval param in BigQueryInsertJobOperator (#30091)``
+* ``Add 'job_id' to 'BigQueryToGCSOperator' templated_fields (#30006)``
+* ``Support deleting the local log files when using remote logging (#29772)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``fix setting project_id for gs to bq and bq to gs (#30053)``
+* ``Fix location on cloud build operators (#29937)``
+* ``'GoogleDriveHook': Fixing log message + adding more verbose documentation (#29694)``
+* ``Add "BOOLEAN" to type_map of MSSQLToGCSOperator, fix incorrect bit->int type conversion by specifying BIT fields explicitly (#29902)``
+* ``Google Cloud Providers - Fix _MethodDefault deepcopy failure (#29518)``
+* ``Handling project location param on async BigQuery dts trigger (#29786)``
+* ``Support CloudDataTransferServiceJobStatusSensor without specifying a project_id (#30035)``
+* ``Wait insert_job result in normal mode (#29925)``
+
+Misc
+~~~~
+
+* ``merge BigQueryTableExistenceAsyncSensor into BigQueryTableExistenceSensor (#30235)``
+* ``Remove  unnecessary upper constraints from google provider (#29915)``
+* ``Merge BigQueryTableExistencePartitionAsyncSensor into BigQueryTableExistencePartitionSensor (#30231)``
+* ``Merge GCSObjectExistenceAsyncSensor logic to GCSObjectExistenceSensor (#30014)``
+* ``Align cncf provider file names with AIP-21 (#29905)``
+* ``Switch to using vendored-in google ads. (#30410)``
+* ``Merging of the google ads vendored-in code. (#30399)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``adding trigger info to provider yaml (#29950)``
+
+8.11.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add deferrable mode to BigQueryTablePartitionExistenceSensor. (#29735)``
+* ``Add a new param for BigQuery operators to support additional actions when resource exists (#29394)``
+* ``Add deferrable mode to DataprocInstantiateWorkflowTemplateOperator (#28618)``
+* ``Dataproc batches (#29136)``
+* ``Add 'CloudSQLCloneInstanceOperator' (#29726)``
+
+Bug Fixes
+~~~~~~~~~
+
+* ``Fix 'NoneType' object is not subscriptable. (#29820)``
+* ``Fix and augment 'check-for-inclusive-language' CI check (#29549)``
+* ``Don't push secret in XCOM in BigQueryCreateDataTransferOperator (#29348)``
+
+Misc
+~~~~
+
+* ``Google Cloud Providers - Introduce GoogleCloudBaseOperator (#29680)``
+* ``Update google cloud dlp package and adjust hook and operators (#29234)``
+* ``Refactor Dataproc Trigger (#29364)``
+* ``Remove <2.0.0 limit on google-cloud-bigtable (#29644)``
+* ``Move help message to the google auth code (#29888)``
+
+8.10.0
+......
+
+Features
+~~~~~~~~
+
+* ``Add defer mode to GKECreateClusterOperator and GKEDeleteClusterOperator (#28406)``
+
+Bug Fixes
+~~~~~~~~~
+* ``Move cloud_sql_binary_path from connection to Hook (#29499)``
+* ``Check that cloud sql provider version is valid (#29497)``
+* ``'GoogleDriveHook': Add folder_id param to upload_file (#29477)``
+
+Misc
+~~~~
+* ``Add documentation for BigQuery transfer operators (#29466)``
+
+.. Below changes are excluded from the changelog. Move them to
+   appropriate section above if needed. Do not delete the lines(!):
+   * ``Upgrade Mypy to 1.0 (#29468)``
+   * ``Restore trigger logging (#29482)``
+   * ``Revert "Enable individual trigger logging (#27758)" (#29472)``
+   * ``Revert "Upgrade mypy to 0.991 (#28926)" (#29470)``
+   * ``Upgrade mypy to 0.991 (#28926)``
+
 8.9.0
 .....
 
 Features
 ~~~~~~~~
 
 * ``Add deferrable capability to existing ''DataprocDeleteClusterOperator'' (#29349)``
@@ -1464,9 +1549,7 @@
 * ``Fix Data Catalog operators (#13096)``
 
 
 1.0.0
 .....
 
 Initial version of the provider.
-
-
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/apache_airflow_providers_google.egg-info/requires.txt` & `apache-airflow-providers-google-9.0.0rc1/apache_airflow_providers_google.egg-info/requires.txt`

 * *Files 4% similar despite different names*

```diff
@@ -1,33 +1,34 @@
 PyOpenSSL
+PyYAML<7.0,>=5.1
 apache-airflow-providers-common-sql>=1.3.1.dev0
 apache-airflow>=2.3.0.dev0
 asgiref>=3.5.2
 gcloud-aio-auth<5.0.0,>=4.0.0
 gcloud-aio-bigquery>=6.1.2
 gcloud-aio-storage
-google-ads>=15.1.1
-google-api-core<3.0.0,>=2.7.0
+google-api-core==2.8.2
 google-api-python-client<2.0.0,>=1.6.0
 google-auth-httplib2>=0.0.1
+google-auth-oauthlib<1.0.0,>=0.3.0
 google-auth>=1.0.0
 google-cloud-aiplatform<2.0.0,>=1.7.1
 google-cloud-automl>=2.1.0
 google-cloud-bigquery-datatransfer>=3.0.0
-google-cloud-bigtable<2.0.0,>=1.0.0
+google-cloud-bigtable<3.0.0,>=2.0.0
 google-cloud-build>=3.0.0
 google-cloud-compute<2.0.0,>=0.1.0
 google-cloud-container<3.0.0,>=2.2.0
 google-cloud-datacatalog>=3.0.0
-google-cloud-dataflow-client<0.5.5,>=0.5.2
+google-cloud-dataflow-client>=0.5.2
 google-cloud-dataform>=0.2.0
 google-cloud-dataplex>=0.1.0
 google-cloud-dataproc-metastore<2.0.0,>=1.2.0
 google-cloud-dataproc>=3.1.0
-google-cloud-dlp<2.0.0,>=0.11.0
+google-cloud-dlp>=3.0.0
 google-cloud-kms>=2.0.0
 google-cloud-language<2.0.0,>=1.1.1
 google-cloud-logging>=2.1.1
 google-cloud-memcache>=0.2.0
 google-cloud-monitoring>=2.0.0
 google-cloud-orchestration-airflow<2.0.0,>=1.0.0
 google-cloud-os-login>=2.0.0
@@ -39,22 +40,25 @@
 google-cloud-storage<3.0.0,>=1.30
 google-cloud-tasks>=2.0.0
 google-cloud-texttospeech<2.0.0,>=0.4.0
 google-cloud-translate<2.0.0,>=1.5.0
 google-cloud-videointelligence<2.0.0,>=1.7.0
 google-cloud-vision<2.0.0,>=0.35.2
 google-cloud-workflows<2.0.0,>=0.1.0
+googleapis-common-protos<2.0.0,>=1.5.8
 grpcio-gcp>=0.2.2
+grpcio-status<2.0.0,>=1.38.1
+grpcio<2.0.0,>=1.38.1
 httpx
 json-merge-patch>=0.2
 looker-sdk>=22.2.0
 pandas-gbq
 pandas>=0.17.1
-proto-plus>=1.19.6
-protobuf<=3.20.0
+proto-plus==1.19.6
+protobuf!=3.18.*,!=3.19.*,<=3.20.0,>=3.12.0
 sqlalchemy-bigquery>=1.2.1
 
 [amazon]
 apache-airflow-providers-amazon>=2.6.0
 
 [apache.beam]
 apache-airflow-providers-apache-beam
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/pyproject.toml` & `apache-airflow-providers-google-9.0.0rc1/pyproject.toml`

 * *Files 21% similar despite different names*

```diff
@@ -19,24 +19,24 @@
 target-version = ['py37', 'py38', 'py39', 'py310']
 # The build system section is needed in order to workaround the side-effect introduced by recent
 # setup tools version. The recent setuptools version update (64.0.0) broke paths of editable installations
 # and we have to pin it to 63.4.3 version
 # The problem is tracked (and this limitation might be removed if it is solved) in:
 # https://github.com/pypa/setuptools/issues/3548
 [build-system]
-requires = ['setuptools==63.4.3']
+requires = ['setuptools==67.2.0']
 build-backend = "setuptools.build_meta"
 
 [tool.ruff]
 typing-modules = ["airflow.typing_compat"]
 line-length = 110
 extend-exclude = [
     ".eggs",
     "airflow/_vendor/*",
-
+    "airflow/providers/google/ads/_vendor/*",
     # The files generated by stubgen aren't 100% valid syntax it turns out, and we don't ship them, so we can
     # ignore them in ruff
     "airflow/providers/common/sql/*/*.pyi"
 ]
 
 # TODO: Bump to Python 3.8 when support for Python 3.7 is dropped in Airflow.
 target-version = "py37"
@@ -63,14 +63,46 @@
     "D212",
     "D213",
     "D214",
     "D215",
     "E731",
 ]
 
+[tool.pytest.ini_options]
+# * Disable `flaky` plugin for pytest. This plugin conflicts with `rerunfailures` because provide same marker.
+# * Disable `nose` builtin plugin for pytest. This feature deprecated in 7.2 and will be removed in pytest>=8
+# * And we focus on use native pytest capabilities rather than adopt another frameworks.
+addopts = "-rasl --verbosity=2 -p no:flaky -p no:nose --asyncio-mode=strict"
+norecursedirs = [
+    ".eggs",
+    "airflow",
+    "tests/dags_with_system_exit",
+    "tests/test_utils",
+    "tests/dags_corrupted",
+    "tests/dags",
+    "tests/system/providers/google/cloud/dataproc/resources",
+    "tests/system/providers/google/cloud/gcs/resources",
+]
+log_level = "INFO"
+filterwarnings = [
+    "error::pytest.PytestCollectionWarning",
+    "ignore::DeprecationWarning:flask_appbuilder.filemanager",
+    "ignore::DeprecationWarning:flask_appbuilder.widgets",
+    # https://github.com/dpgaspar/Flask-AppBuilder/pull/1940
+    "ignore::DeprecationWarning:flask_sqlalchemy",
+    # https://github.com/dpgaspar/Flask-AppBuilder/pull/1903
+    "ignore::DeprecationWarning:apispec.utils",
+]
+python_files = [
+    "*.py",
+]
+testpaths = [
+    "tests",
+]
+
 [tool.ruff.isort]
 known-first-party = ["airflow", "airflow_breeze", "docker_tests", "docs", "kubernetes_tests", "tests"]
 required-imports = ["from __future__ import annotations"]
 combine-as-imports = true
 
 # TODO: for now, https://github.com/charliermarsh/ruff/issues/1817
 known-third-party = [
@@ -101,14 +133,18 @@
 "airflow/models/sqla_models.py" = ["F401"]
 
 
 # The test_python.py is needed because adding __future__.annotations breaks runtime checks that are
 # needed for the test to work
 "tests/decorators/test_python.py" = ["I002"]
 
+# The Pydantic representations of SqlAlchemy Models are not parsed well with Pydantic
+# when __future__.annotations is used so we need to skip them from upgrading
+"airflow/serialization/pydantic/*.py" = ["I002"]
+
 # Ignore pydoc style from these
 "*.pyi" = ["D"]
 "tests/*" = ["D"]
 "scripts/*" = ["D"]
 "dev/*" = ["D"]
 "docs/*" = ["D"]
 "provider_packages/*" = ["D"]
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/setup.cfg` & `apache-airflow-providers-google-9.0.0rc1/setup.cfg`

 * *Files 16% similar despite different names*

```diff
@@ -23,15 +23,15 @@
 	License :: OSI Approved :: Apache Software License
 	Programming Language :: Python :: 3.7
 	Programming Language :: Python :: 3.8
 	Programming Language :: Python :: 3.9
 	Programming Language :: Python :: 3.10
 	Topic :: System :: Monitoring
 project_urls = 
-	Documentation=https://airflow.apache.org/docs/apache-airflow-providers-google/8.9.0/
+	Documentation=https://airflow.apache.org/docs/apache-airflow-providers-google/9.0.0/
 	Bug Tracker=https://github.com/apache/airflow/issues
 	Source Code=https://github.com/apache/airflow
 	Slack Chat=https://s.apache.org/airflow-slack
 	Twitter=https://twitter.com/ApacheAirflow
 	YouTube=https://www.youtube.com/channel/UCSXwxpWZQ7XZ1WL3wqevChA/
 
 [bdist_wheel]
@@ -43,39 +43,40 @@
 python_requires = ~=3.7
 packages = find:
 setup_requires = 
 	setuptools
 	wheel
 install_requires = 
 	PyOpenSSL
+	PyYAML<7.0,>=5.1
 	apache-airflow-providers-common-sql>=1.3.1.dev0
 	apache-airflow>=2.3.0.dev0
 	asgiref>=3.5.2
 	gcloud-aio-auth>=4.0.0,<5.0.0
 	gcloud-aio-bigquery>=6.1.2
 	gcloud-aio-storage
-	google-ads>=15.1.1
-	google-api-core>=2.7.0,<3.0.0
+	google-api-core==2.8.2
 	google-api-python-client>=1.6.0,<2.0.0
 	google-auth-httplib2>=0.0.1
+	google-auth-oauthlib<1.0.0,>=0.3.0
 	google-auth>=1.0.0
 	google-cloud-aiplatform>=1.7.1,<2.0.0
 	google-cloud-automl>=2.1.0
 	google-cloud-bigquery-datatransfer>=3.0.0
-	google-cloud-bigtable>=1.0.0,<2.0.0
+	google-cloud-bigtable>=2.0.0,<3.0.0
 	google-cloud-build>=3.0.0
 	google-cloud-compute>=0.1.0,<2.0.0
 	google-cloud-container>=2.2.0,<3.0.0
 	google-cloud-datacatalog>=3.0.0
-	google-cloud-dataflow-client>=0.5.2,<0.5.5
+	google-cloud-dataflow-client>=0.5.2
 	google-cloud-dataform>=0.2.0
 	google-cloud-dataplex>=0.1.0
 	google-cloud-dataproc-metastore>=1.2.0,<2.0.0
 	google-cloud-dataproc>=3.1.0
-	google-cloud-dlp>=0.11.0,<2.0.0
+	google-cloud-dlp>=3.0.0
 	google-cloud-kms>=2.0.0
 	google-cloud-language>=1.1.1,<2.0.0
 	google-cloud-logging>=2.1.1
 	google-cloud-memcache>=0.2.0
 	google-cloud-monitoring>=2.0.0
 	google-cloud-orchestration-airflow>=1.0.0,<2.0.0
 	google-cloud-os-login>=2.0.0
@@ -87,22 +88,25 @@
 	google-cloud-storage>=1.30,<3.0.0
 	google-cloud-tasks>=2.0.0
 	google-cloud-texttospeech>=0.4.0,<2.0.0
 	google-cloud-translate>=1.5.0,<2.0.0
 	google-cloud-videointelligence>=1.7.0,<2.0.0
 	google-cloud-vision>=0.35.2,<2.0.0
 	google-cloud-workflows>=0.1.0,<2.0.0
+	googleapis-common-protos<2.0.0,>=1.5.8
 	grpcio-gcp>=0.2.2
+	grpcio-status<2.0.0,>=1.38.1
+	grpcio<2.0.0,>=1.38.1
 	httpx
 	json-merge-patch>=0.2
 	looker-sdk>=22.2.0
 	pandas-gbq
 	pandas>=0.17.1
-	proto-plus>=1.19.6
-	protobuf<=3.20.0
+	proto-plus==1.19.6
+	protobuf!=3.18.*,!=3.19.*,<=3.20.0,>=3.12.0
 	sqlalchemy-bigquery>=1.2.1
 
 [options.entry_points]
 apache_airflow_provider = 
 	provider_info=airflow.providers.google.get_provider_info:get_provider_info
 
 [files]
```

### Comparing `apache-airflow-providers-google-8.9.0rc1/setup.py` & `apache-airflow-providers-google-9.0.0rc1/setup.py`

 * *Files 19% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 # IF YOU WANT TO MODIFY IT, YOU SHOULD MODIFY THE TEMPLATE
 # `SETUP_TEMPLATE.py.jinja2` IN the `dev/provider_packages` DIRECTORY
 
 """Setup.py for the apache-airflow-providers-google package."""
 
 from setuptools import find_namespace_packages, setup
 
-version = "8.9.0"
+version = "9.0.0"
 
 
 def do_setup():
     """Perform the package apache-airflow-providers-google setup."""
     setup(
         version=version,
         extras_require={
@@ -48,13 +48,20 @@
             "presto": ["apache-airflow-providers-presto"],
             "salesforce": ["apache-airflow-providers-salesforce"],
             "sftp": ["apache-airflow-providers-sftp"],
             "ssh": ["apache-airflow-providers-ssh"],
             "trino": ["apache-airflow-providers-trino"],
             "leveldb": ["plyvel"],
         },
-        packages=find_namespace_packages(include=["airflow.providers.google", "airflow.providers.google.*"]),
+        packages=find_namespace_packages(
+            include=[
+                "airflow.providers.google",
+                "airflow.providers.google.*",
+                "airflow.providers.google_vendor",
+                "airflow.providers.google_vendor.*",
+            ],
+        ),
     )
 
 
 if __name__ == "__main__":
     do_setup()
```

