# Comparing `tmp/mdapy-0.8.4-cp39-cp39-win_amd64.whl.zip` & `tmp/mdapy-0.8.5-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,42 +1,42 @@
-Zip file size: 565139 bytes, number of entries: 40
--rw-rw-rw-  2.0 fat   124416 b- defN 23-Mar-30 14:38 _cluster_analysis.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   123392 b- defN 23-Mar-30 14:39 _neigh.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   208896 b- defN 23-Mar-30 14:38 _poly.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   331776 b- defN 23-Mar-30 14:39 _ptm.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   126976 b- defN 23-Mar-30 14:39 _rdf.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   193536 b- defN 23-Mar-30 14:38 _voronoi_analysis.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat     3552 b- defN 23-Mar-24 14:59 mdapy/__init__.py
--rw-rw-rw-  2.0 fat     7826 b- defN 23-Feb-16 05:14 mdapy/ackland_jones_analysis.py
+Zip file size: 560581 bytes, number of entries: 40
+-rw-rw-rw-  2.0 fat   121856 b- defN 23-Apr-09 10:34 _cluster_analysis.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   120832 b- defN 23-Apr-09 10:34 _neigh.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   205824 b- defN 23-Apr-09 10:34 _poly.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   329728 b- defN 23-Apr-09 10:34 _ptm.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   124928 b- defN 23-Apr-09 10:34 _rdf.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat   191488 b- defN 23-Apr-09 10:34 _voronoi_analysis.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     3552 b- defN 23-Apr-01 12:59 mdapy/__init__.py
+-rw-rw-rw-  2.0 fat     7836 b- defN 23-Apr-01 12:38 mdapy/ackland_jones_analysis.py
 -rw-rw-rw-  2.0 fat    10839 b- defN 23-Jan-20 06:31 mdapy/calculator.py
--rw-rw-rw-  2.0 fat     7370 b- defN 23-Mar-27 06:54 mdapy/centro_symmetry_parameter.py
--rw-rw-rw-  2.0 fat     4422 b- defN 23-Jan-20 06:31 mdapy/cluser_analysis.py
--rw-rw-rw-  2.0 fat     9766 b- defN 23-Mar-26 15:57 mdapy/common_neighbor_analysis.py
+-rw-rw-rw-  2.0 fat     7380 b- defN 23-Apr-01 12:39 mdapy/centro_symmetry_parameter.py
+-rw-rw-rw-  2.0 fat     4432 b- defN 23-Apr-01 12:41 mdapy/cluser_analysis.py
+-rw-rw-rw-  2.0 fat    10198 b- defN 23-Apr-09 08:41 mdapy/common_neighbor_analysis.py
 -rw-rw-rw-  2.0 fat     6576 b- defN 23-Feb-22 06:10 mdapy/common_neighbor_parameter.py
--rw-rw-rw-  2.0 fat    25858 b- defN 23-Feb-13 07:24 mdapy/create_polycrystalline.py
--rw-rw-rw-  2.0 fat     5518 b- defN 23-Jan-20 06:31 mdapy/eam_average.py
+-rw-rw-rw-  2.0 fat    26758 b- defN 23-Apr-01 12:53 mdapy/create_polycrystalline.py
+-rw-rw-rw-  2.0 fat     5528 b- defN 23-Apr-01 13:00 mdapy/eam_average.py
 -rw-rw-rw-  2.0 fat    21039 b- defN 23-Jan-20 06:31 mdapy/eam_generate.py
 -rw-rw-rw-  2.0 fat     9960 b- defN 23-Jan-20 06:31 mdapy/entropy.py
--rw-rw-rw-  2.0 fat    10861 b- defN 23-Mar-19 07:38 mdapy/identify_SFs_TBs.py
+-rw-rw-rw-  2.0 fat    11015 b- defN 23-Apr-01 13:00 mdapy/identify_SFs_TBs.py
 -rw-rw-rw-  2.0 fat     6831 b- defN 23-Mar-11 08:28 mdapy/kdtree.py
--rw-rw-rw-  2.0 fat     7576 b- defN 23-Jan-20 06:31 mdapy/lattice_maker.py
--rw-rw-rw-  2.0 fat     8463 b- defN 23-Jan-20 06:31 mdapy/lindemann_parameter.py
--rw-rw-rw-  2.0 fat     7130 b- defN 23-Mar-29 03:52 mdapy/mean_squared_displacement.py
--rw-rw-rw-  2.0 fat    11359 b- defN 23-Mar-27 14:45 mdapy/neighbor.py
--rw-rw-rw-  2.0 fat     9063 b- defN 23-Mar-26 12:59 mdapy/pair_distribution.py
+-rw-rw-rw-  2.0 fat    10077 b- defN 23-Apr-01 06:40 mdapy/lattice_maker.py
+-rw-rw-rw-  2.0 fat     8475 b- defN 23-Apr-01 13:02 mdapy/lindemann_parameter.py
+-rw-rw-rw-  2.0 fat     7154 b- defN 23-Apr-01 13:07 mdapy/mean_squared_displacement.py
+-rw-rw-rw-  2.0 fat    11369 b- defN 23-Apr-01 13:08 mdapy/neighbor.py
+-rw-rw-rw-  2.0 fat     9048 b- defN 23-Apr-01 13:09 mdapy/pair_distribution.py
 -rw-rw-rw-  2.0 fat     3082 b- defN 23-Jan-24 04:17 mdapy/plotset.py
--rw-rw-rw-  2.0 fat     5244 b- defN 23-Mar-20 06:56 mdapy/polyhedral_template_matching.py
--rw-rw-rw-  2.0 fat    11522 b- defN 23-Jan-20 06:31 mdapy/potential.py
--rw-rw-rw-  2.0 fat    10467 b- defN 23-Jan-20 11:27 mdapy/spatial_binning.py
--rw-rw-rw-  2.0 fat    28700 b- defN 23-Mar-12 07:59 mdapy/steinhardt_bond_orientation.py
--rw-rw-rw-  2.0 fat    71920 b- defN 23-Mar-24 14:53 mdapy/system.py
+-rw-rw-rw-  2.0 fat     5227 b- defN 23-Apr-01 13:11 mdapy/polyhedral_template_matching.py
+-rw-rw-rw-  2.0 fat    11532 b- defN 23-Apr-01 13:12 mdapy/potential.py
+-rw-rw-rw-  2.0 fat    10755 b- defN 23-Apr-01 13:13 mdapy/spatial_binning.py
+-rw-rw-rw-  2.0 fat    28837 b- defN 23-Apr-01 13:14 mdapy/steinhardt_bond_orientation.py
+-rw-rw-rw-  2.0 fat    73683 b- defN 23-Apr-06 13:42 mdapy/system.py
 -rw-rw-rw-  2.0 fat     7962 b- defN 23-Jan-20 06:31 mdapy/temperature.py
 -rw-rw-rw-  2.0 fat      562 b- defN 23-Jan-20 06:31 mdapy/timer.py
--rw-rw-rw-  2.0 fat     9186 b- defN 23-Jan-20 06:31 mdapy/void_distribution.py
--rw-rw-rw-  2.0 fat     2955 b- defN 23-Feb-13 07:11 mdapy/voronoi_analysis.py
--rw-rw-rw-  2.0 fat     6647 b- defN 23-Jan-20 06:31 mdapy/warren_cowley_parameter.py
--rw-rw-rw-  2.0 fat     1594 b- defN 23-Mar-30 14:39 mdapy-0.8.4.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     9416 b- defN 23-Mar-30 14:39 mdapy-0.8.4.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 23-Mar-30 14:39 mdapy-0.8.4.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       65 b- defN 23-Mar-30 14:39 mdapy-0.8.4.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     3269 b- defN 23-Mar-30 14:39 mdapy-0.8.4.dist-info/RECORD
-40 files, 1455692 bytes uncompressed, 560025 bytes compressed:  61.5%
+-rw-rw-rw-  2.0 fat     9171 b- defN 23-Apr-01 13:16 mdapy/void_distribution.py
+-rw-rw-rw-  2.0 fat     2965 b- defN 23-Apr-01 13:17 mdapy/voronoi_analysis.py
+-rw-rw-rw-  2.0 fat     6650 b- defN 23-Apr-01 13:19 mdapy/warren_cowley_parameter.py
+-rw-rw-rw-  2.0 fat     1594 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    10304 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      100 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       65 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     3272 b- defN 23-Apr-09 11:08 mdapy-0.8.5.dist-info/RECORD
+40 files, 1448484 bytes uncompressed, 555467 bytes compressed:  61.7%
```

## zipnote {}

```diff
@@ -99,23 +99,23 @@
 
 Filename: mdapy/voronoi_analysis.py
 Comment: 
 
 Filename: mdapy/warren_cowley_parameter.py
 Comment: 
 
-Filename: mdapy-0.8.4.dist-info/LICENSE
+Filename: mdapy-0.8.5.dist-info/LICENSE
 Comment: 
 
-Filename: mdapy-0.8.4.dist-info/METADATA
+Filename: mdapy-0.8.5.dist-info/METADATA
 Comment: 
 
-Filename: mdapy-0.8.4.dist-info/WHEEL
+Filename: mdapy-0.8.5.dist-info/WHEEL
 Comment: 
 
-Filename: mdapy-0.8.4.dist-info/top_level.txt
+Filename: mdapy-0.8.5.dist-info/top_level.txt
 Comment: 
 
-Filename: mdapy-0.8.4.dist-info/RECORD
+Filename: mdapy-0.8.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mdapy/__init__.py

```diff
@@ -1,12 +1,12 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 __author__ = "mushroomfire aka HerrWu"
-__version__ = "0.8.4"
+__version__ = "0.8.5"
 __license__ = "BSD License"
 
 from .ackland_jones_analysis import AcklandJonesAnalysis
 from .calculator import Calculator
 from .centro_symmetry_parameter import CentroSymmetryParameter
 from .cluser_analysis import ClusterAnalysis
 from .common_neighbor_analysis import CommonNeighborAnalysis
```

## mdapy/ackland_jones_analysis.py

```diff
@@ -1,17 +1,17 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 
-try:
-    from .kdtree import kdtree
-except Exception:
+if __name__ == "__main__":
     from kdtree import kdtree
+else:
+    from .kdtree import kdtree
 
 
 @ti.data_oriented
 class AcklandJonesAnalysis:
     """This class applies Ackland Jones Analysis (AJA) method to identify the lattice structure.
 
     The AJA method can recgonize the following structure:
```

## mdapy/centro_symmetry_parameter.py

```diff
@@ -1,16 +1,16 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
-try:
-    from .kdtree import kdtree
-except Exception:
+if __name__ == "__main__":
     from kdtree import kdtree
+else:
+    from .kdtree import kdtree
 
 
 @ti.data_oriented
 class CentroSymmetryParameter:
     """This class is used to compute the CentroSymmetry Parameter (CSP), 
     which is heluful to recgonize the structure in lattice, such as FCC and BCC.
     The  CSP is given by:
```

## mdapy/cluser_analysis.py

```diff
@@ -1,15 +1,15 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import numpy as np
 
-try:
+if __name__ == "__main__":
     from cluster import _cluster_analysis
-except Exception:
+else:
     import _cluster_analysis
 
 
 class ClusterAnalysis:
     """This class is used to divide atoms connected within a given cutoff distance into a cluster.
     It is helpful to recognize the reaction products or fragments under shock loading.
```

## mdapy/common_neighbor_analysis.py

```diff
@@ -1,13 +1,16 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 
+vec3f32 = ti.types.vector(3, ti.f32)
+vec3f64 = ti.types.vector(3, ti.f64)
+
 
 @ti.data_oriented
 class CommonNeighborAnalysis:
 
     """This class use Common Neighbor Analysis (CNA) method to recgonize the lattice structure, based
     on which atoms can be divided into FCC, BCC, HCP and Other structure.
 
@@ -83,45 +86,58 @@
     """
 
     def __init__(self, rc, verlet_list, neighbor_number, pos, box, boundary=[1, 1, 1]):
 
         self.rc = rc
         self.verlet_list = verlet_list
         self.neighbor_number = neighbor_number
-        self.box = ti.Vector.field(box.shape[1], dtype=ti.f64, shape=(box.shape[0]))
-        self.box.from_numpy(box)
-        self.boundary = ti.Vector(boundary)
+        self.box = box
+        self.boundary = ti.Vector([boundary[i] for i in range(3)], int)
+        assert pos.dtype in [
+            np.float64,
+            np.float32,
+        ], "Dtype of pos must in [float64, float32]."
         self.pos = pos
-
+        if self.pos.dtype == np.float64:
+            self.box_length = vec3f64([box[i, 1] - box[i, 0] for i in range(3)])
+        elif self.pos.dtype == np.float32:
+            self.box_length = vec3f32([box[i, 1] - box[i, 0] for i in range(3)])
         self.N = self.verlet_list.shape[0]
         self.MAXNEAR = 14
         self.MAXCOMMON = 7
 
         self.structure = ["other", "fcc", "hcp", "bcc", "ico"]
 
     @ti.func
     def _pbc(self, rij):
-        for i in ti.static(range(rij.n)):
-            if self.boundary[i] == 1:
-                box_length = self.box[i][1] - self.box[i][0]
-                rij[i] = rij[i] - box_length * ti.round(rij[i] / box_length)
+
+        for m in ti.static(range(3)):
+            if self.boundary[m]:
+                dx = rij[m]
+                x_size = self.box_length[m]
+                h_x_size = x_size * 0.5
+                if dx > h_x_size:
+                    dx = dx - x_size
+                if dx <= -h_x_size:
+                    dx = dx + x_size
+                rij[m] = dx
         return rij
 
     @ti.kernel
     def _compute(
         self,
-        pos: ti.types.ndarray(),
+        pos: ti.types.ndarray(dtype=ti.math.vec3),
         verlet_list: ti.types.ndarray(),
         neighbor_number: ti.types.ndarray(),
         cna: ti.types.ndarray(),
         common: ti.types.ndarray(),
         bonds: ti.types.ndarray(),
         pattern: ti.types.ndarray(),
     ):
-
+        rcsq = self.rc * self.rc
         for i in range(self.N):
             if neighbor_number[i] == 12 or neighbor_number[i] == 14:
                 for m in range(neighbor_number[i]):
                     j = verlet_list[i, m]
                     ncommon = 0
                     for inear in range(neighbor_number[i]):
                         for jnear in range(neighbor_number[j]):
@@ -136,20 +152,16 @@
                         bonds[i, n] = 0
 
                     nbonds = 0
                     for jj in range(ncommon - 1):
                         j = common[i, jj]
                         for kk in range(jj + 1, ncommon):
                             k = common[i, kk]
-
-                            r_j = ti.Vector([pos[j, 0], pos[j, 1], pos[j, 2]])
-                            r_k = ti.Vector([pos[k, 0], pos[k, 1], pos[k, 2]])
-
-                            rjk = self._pbc(r_j - r_k)
-                            if rjk.norm() < self.rc:
+                            rjk = self._pbc(pos[j] - pos[k])
+                            if rjk.norm_sqr() < rcsq:
                                 nbonds += 1
                                 bonds[i, jj] += 1
                                 bonds[i, kk] += 1
 
                     cna[i, m, 1] = nbonds
                     maxbonds = 0
                     minbonds = self.MAXCOMMON
```

## mdapy/create_polycrystalline.py

```diff
@@ -1,31 +1,25 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
-try:
-    from polygon import _poly
-
-except Exception:
-    import _poly
-
+from time import time
 import numpy as np
 import taichi as ti
+import pandas as pd
+import pyarrow as pa
+from pyarrow import csv
 
-try:
-    from .lattice_maker import LatticeMaker
-except Exception:
+if __name__ == "__main__":
+    from polygon import _poly
     from lattice_maker import LatticeMaker
-
-try:
-    from .neighbor import Neighbor
-except Exception:
     from neighbor import Neighbor
-
-
-from time import time
+else:
+    import _poly
+    from .lattice_maker import LatticeMaker
+    from .neighbor import Neighbor
 
 
 class Cell:
     def __init__(
         self, face_vertices, vertices, volume, cavity_radius, face_areas, pos
     ) -> None:
         self._face_vertices = face_vertices
@@ -131,15 +125,17 @@
         seed=None,
         if_rotation=True,
         theta_list=None,
         face_threshold=5.0,
         output_name=None,
     ) -> None:
 
-        self.box = box
+        self._real_box = np.array(box, float)
+        self._lower = self._real_box[:, 0]
+        self.box = np.c_[np.zeros(3), self._real_box[:, 1] - self._real_box[:, 0]]
         self.seednumber = seednumber
         self.metal_latttice_constant = metal_latttice_constant
         self.metal_lattice_type = metal_lattice_type
         assert self.metal_lattice_type in [
             "FCC",
             "BCC",
             "HCP",
@@ -147,19 +143,21 @@
         if randomseed is None:
             self.randomseed = np.random.randint(0, 10000000)
         else:
             self.randomseed = randomseed
 
         if metal_overlap_dis is None:
             if self.metal_lattice_type == "FCC":
-                self.metal_overlap_dis = self.metal_latttice_constant / 2**0.5
+                self.metal_overlap_dis = self.metal_latttice_constant / 2**0.5 - 0.001
             elif self.metal_lattice_type == "BCC":
-                self.metal_overlap_dis = self.metal_latttice_constant * (0.5 * 3**0.5)
+                self.metal_overlap_dis = (
+                    self.metal_latttice_constant * (0.5 * 3**0.5) - 0.001
+                )
             elif self.metal_lattice_type == "HCP":
-                self.metal_overlap_dis = self.metal_latttice_constant
+                self.metal_overlap_dis = self.metal_latttice_constant - 0.001
         else:
             self.metal_overlap_dis = metal_overlap_dis
         self.add_graphene = add_graphene
         self.gra_lattice_constant = gra_lattice_constant
         self.metal_gra_overlap_dis = metal_gra_overlap_dis
         self.gra_overlap_dis = gra_overlap_dis
         if seed is None:
@@ -383,17 +381,21 @@
                         # if np.isclose(abs(np.dot(gra_vector, plane_vector)), 0):
                         #     delete = self._points_in_polygon(
                         #         vertices[:, [0, 2]], pos[:, [0, 2]]
                         #     )
                         # else:
                         #     delete = self._points_in_polygon(vertices[:, :2], pos[:, :2])
                         vertices_temp = np.dot(
-                            vertices, self._rotate_pos(10, [1, 0, 0])
+                            vertices,
+                            self._rotate_pos(10, np.array([1, 1, 1]) / np.sqrt(3.0)),
+                        )
+                        pos_temp = np.dot(
+                            pos,
+                            self._rotate_pos(10, np.array([1, 1, 1]) / np.sqrt(3.0)),
                         )
-                        pos_temp = np.dot(pos, self._rotate_pos(10, [1, 0, 0]))
                         delete = self._points_in_polygon(vertices_temp, pos_temp)
                         pos = pos[delete]
                         pos = np.c_[pos, np.ones(pos.shape[0]) * i]
                         gra_pos.append(pos)
 
         metal_pos = np.concatenate(metal_pos)
         if self.add_graphene:
@@ -510,22 +512,28 @@
             for j in range(neighbor_number[i]):
                 j_index = verlet_list[i, j]
                 if distance_list[i, j] <= metal_overlap_dis and j_index > i:
                     delete_id[j_index] = 0
 
     def _write_dump(self, pos):
         # save position to DUMP file.
-        with open(self.output_name, "w") as op:
-            op.write("ITEM: TIMESTEP\n0\nITEM: NUMBER OF ATOMS\n")
-            op.write(f"{pos.shape[0]}\nITEM: BOX BOUNDS pp pp pp\n")
+        pos[:, 2:5] += self._lower
+        df = pd.DataFrame(pos, columns=["id", "type", "x", "y", "z", "grainid"])
+        df[["id", "type", "grainid"]] = df[["id", "type", "grainid"]].astype(int)
+        df[["x", "y", "z"]] = df[["x", "y", "z"]].astype(np.float32)
+        table = pa.Table.from_pandas(df)
+        with pa.OSFile(self.output_name, "wb") as op:
+            op.write("ITEM: TIMESTEP\n0\nITEM: NUMBER OF ATOMS\n".encode())
+            op.write(f"{pos.shape[0]}\nITEM: BOX BOUNDS pp pp pp\n".encode())
             op.write(
-                f"{self.box[0, 0]} {self.box[0, 1]}\n{self.box[1, 0]} {self.box[1, 1]}\n{self.box[2, 0]} {self.box[2, 1]}\n"
+                f"{self._real_box[0, 0]} {self._real_box[0, 1]}\n{self._real_box[1, 0]} {self._real_box[1, 1]}\n{self._real_box[2, 0]} {self._real_box[2, 1]}\n".encode()
             )
-            op.write("ITEM: ATOMS id type x y z grainid\n")
-            np.savetxt(op, pos, delimiter=" ", fmt="%d %d %f %f %f %d")
+            op.write("ITEM: ATOMS id type x y z grainid\n".encode())
+            write_options = csv.WriteOptions(delimiter=" ", include_header=False)
+            csv.write_csv(table, op, write_options=write_options)
 
     def compute(self):
         """Do the real polycrystalline structure building."""
         start = time()
         print("Generating voronoi polygon...")
         self.cntr = Container(self.seed, self.box, [1, 1, 1])
         ave_grain_volume = np.mean([cell.volume() for cell in self.cntr])
@@ -619,15 +627,16 @@
     # for i in cntr:
     #     print(i)
     # print(cntr[0].cavity_radius())
     # print(cntr[:1])
     # print(len(cntr))
     # print(cntr[0].face_vertices())
     # # print(cntr[0].vertices())
-    ti.init(ti.cpu)
-    box = np.array([[0.0, 200.0], [0.0, 200.0], [0.0, 200.0]])
-    # polycry = CreatePolycrystalline(box, 20, 3.615, "FCC")
+    # ti.init(ti.cpu)
+    # box = np.array([[-100, 100], [-100, 100], [-100, 100]])
+    # # polycry = CreatePolycrystalline(box, 20, 3.615, "FCC")
+    # # polycry.compute()
+    # polycry = CreatePolycrystalline(
+    #     box, 10, 2.615, "FCC", add_graphene=True, if_rotation=True
+    # )
     # polycry.compute()
-    polycry = CreatePolycrystalline(
-        box, 20, 3.615, "FCC", add_graphene=True, if_rotation=False
-    )
-    polycry.compute()
+    print("test")
```

## mdapy/eam_average.py

```diff
@@ -1,15 +1,15 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
-try:
-    from .potential import EAM
-except Exception:
-    from potential import EAM
 import numpy as np
+if __name__ == "__main__":
+    from potential import EAM
+else:
+    from .potential import EAM
 
 
 class EAMAverage(EAM):
 
     """This class is used to generate the average EAM (A-atom) potential, which is useful in alloy investigation.
     The A-atom potential has the similar formula with the original EAM potential:
```

## mdapy/identify_SFs_TBs.py

```diff
@@ -1,7 +1,10 @@
+# Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
+# This file is from the mdapy project, released under the BSD 3-Clause License.
+
 import taichi as ti
 import numpy as np
 
 
 @ti.data_oriented
 class IdentifySFTBinFCC:
     """This class is used to identify the stacking faults (SFs) and coherent twin boundaries (TBs) in FCC structure based on the `Polyhedral Template Matching (PTM) <https://mdapy.readthedocs.io/en/latest/mdapy.html#module-mdapy.polyhedral_template_matching>`_.
```

## mdapy/lattice_maker.py

```diff
@@ -1,12 +1,15 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
+import pandas as pd
+import pyarrow as pa
+from pyarrow import csv
 
 
 @ti.data_oriented
 class LatticeMaker:
     """This class is used to create some standard lattice structure.
 
     Args:
@@ -173,41 +176,99 @@
         """
         if not self.if_computed:
             self.compute()
 
         if output_name is None:
             output_name = f"{self.lattice_type}-{self.x}-{self.y}-{self.z}.data"
         if type_list is None:
-            type_list = [1] * self.N
+            type_list = np.ones(self.N, int)
             Ntype = 1
         else:
             assert len(type_list) == self.N
+            type_list = np.array(type_list, int)
             Ntype = len(np.unique(type_list))
-
-        with open(output_name, "w") as op:
-            op.write("# LAMMPS data file written by mdapy@HerrWu.\n\n")
-            op.write(f"{self.N} atoms\n{Ntype} atom types\n\n")
+        df = pd.DataFrame(
+            {
+                "id": np.arange(1, self.N + 1),
+                "type": type_list,
+                "x": self.pos[:, 0].astype(np.float32),
+                "y": self.pos[:, 1].astype(np.float32),
+                "z": self.pos[:, 2].astype(np.float32),
+            }
+        )
+        table = pa.Table.from_pandas(df)
+        with pa.OSFile(output_name, "wb") as op:
+            op.write("# LAMMPS data file generated by mdapy@HerrWu.\n\n".encode())
+            op.write(f"{self.N} atoms\n{Ntype} atom types\n\n".encode())
             for i, j in zip(range(3), ["x", "y", "z"]):
-                op.write(f"{self.box[i,0]} {self.box[i,1]} {j}lo {j}hi\n")
-            op.write("\n")
-            op.write(r"Atoms # atomic")
-            op.write("\n\n")
-            for i in range(self.N):
-                op.write(
-                    f"{i+1} {type_list[i]} {self.pos[i,0]:.6f} {self.pos[i,1]:.6f} {self.pos[i,2]:.6f}\n"
-                )
+                op.write(f"{self.box[i,0]} {self.box[i,1]} {j}lo {j}hi\n".encode())
+            op.write("\n".encode())
+            op.write(r"Atoms # atomic".encode())
+            op.write("\n\n".encode())
+            write_options = csv.WriteOptions(delimiter=" ", include_header=False)
+            csv.write_csv(table, op, write_options=write_options)
+
+    def write_dump(self, type_list=None, output_name=None):
+        """This function writes position into a DUMP file.
+
+        Args:
+            type_list (np.ndarray, optional): (:math:`N_p`) atom type list. If not given, the atom type is set as 1.
+
+            output_name (str, optional): filename of generated DUMP file.
+        """
+        if not self.if_computed:
+            self.compute()
+
+        if output_name is None:
+            output_name = f"{self.lattice_type}-{self.x}-{self.y}-{self.z}.dump"
+        if type_list is None:
+            type_list = np.ones(self.N, int)
+        else:
+            assert len(type_list) == self.N
+            type_list = np.array(type_list, int)
+        df = pd.DataFrame(
+            {
+                "id": np.arange(1, self.N + 1),
+                "type": type_list,
+                "x": self.pos[:, 0].astype(np.float32),
+                "y": self.pos[:, 1].astype(np.float32),
+                "z": self.pos[:, 2].astype(np.float32),
+            }
+        )
+
+        table = pa.Table.from_pandas(df)
+        with pa.OSFile(output_name, "wb") as op:
+            op.write("ITEM: TIMESTEP\n0\n".encode())
+            op.write("ITEM: NUMBER OF ATOMS\n".encode())
+            op.write(f"{self.N}\n".encode())
+            op.write(f"ITEM: BOX BOUNDS pp pp pp\n".encode())
+            op.write(f"{self.box[0, 0]} {self.box[0, 1]}\n".encode())
+            op.write(f"{self.box[1, 0]} {self.box[1, 1]}\n".encode())
+            op.write(f"{self.box[2, 0]} {self.box[2, 1]}\n".encode())
+            op.write("ITEM: ATOMS id type x y z\n".encode())
+            write_options = csv.WriteOptions(delimiter=" ", include_header=False)
+            csv.write_csv(table, op, write_options=write_options)
 
 
 if __name__ == "__main__":
     ti.init(ti.gpu)
+    from time import time
+
     # FCC = LatticeMaker(1.42, "GRA", 10, 20, 3)
-    FCC = LatticeMaker(1.42, "GRA", 10, 10, 10)
-    print(FCC.N)
-    # FCC.compute()
-    # FCC.write_data()
+    FCC = LatticeMaker(3.615, "FCC", 10, 10, 10)
+    FCC.compute()
+    print("Atom number is:", FCC.N)
+    start = time()
+    FCC.write_data()
+    print(f"write data time {time()-start} s.")
+
+    start = time()
+    FCC.write_dump()
+    print(f"write dump time {time()-start} s.")
+
     # print(FCC.basis_atoms.to_numpy())
     # print(FCC.basis_vector.to_numpy())
     # print(FCC.basis_vector.to_numpy() * np.array([FCC.x, FCC.y, FCC.z]))
     print(FCC.box)
     # print(FCC.pos)
     # print(pos.dtype)
     # FCC.write_data()
```

## mdapy/lindemann_parameter.py

```diff
@@ -1,19 +1,20 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 
-try:
-    from .plotset import pltset, cm2inch
-except Exception:
-    from plotset import pltset, cm2inch
 import matplotlib.pyplot as plt
 
+if __name__ == "__main__":
+    from plotset import pltset, cm2inch
+else:
+    from .plotset import pltset, cm2inch
+
 
 @ti.data_oriented
 class LindemannParameter:
     """This class is used to calculate the `Lindemann index <https://en.wikipedia.org/wiki/Lindemann_index>`_,
     which is useful to distinguish the melt process and determine the melting points of nano-particles.
     The Lindemann index is defined as the root-mean-square bond-length fluctuation with following mathematical expression:
```

## mdapy/mean_squared_displacement.py

```diff
@@ -1,17 +1,17 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import numpy as np
+import matplotlib.pyplot as plt
 
-try:
-    from .plotset import pltset, cm2inch
-except Exception:
+if __name__ == "__main__":
     from plotset import pltset, cm2inch
-import matplotlib.pyplot as plt
+else:
+    from .plotset import pltset, cm2inch
 
 try:
     import pyfftw
 
     def fft(x, n, axis):
         # FFT wrapper of pyfftw.
         a = pyfftw.empty_aligned(x.shape, "complex64")
@@ -169,14 +169,15 @@
     start = time()
     MSD = MeanSquaredDisplacement(pos_list=pos_list, mode="direct")
     MSD.compute()
     end = time()
     msd_d = MSD.msd
     print(f"direct mode costs: {end-start} s.")
     # MSD.plot()
+    pltset()
     fig = plt.figure(figsize=(cm2inch(10), cm2inch(7)), dpi=150)
     plt.subplots_adjust(left=0.16, bottom=0.16, right=0.95, top=0.97)
     plt.plot(msd_w, "o-", label="windows")
     plt.plot(msd_d, "o-", label="direct")
     plt.plot(np.arange(Nframe) * 6, label="theoritical")
     plt.legend()
     plt.xlabel("$\mathregular{N_{frames}}$")
```

## mdapy/neighbor.py

```diff
@@ -1,16 +1,16 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 
-try:
+if __name__ == "__main__":
     from neigh._neigh import _build_cell
-except Exception:
+else:
     from _neigh import _build_cell
 
 vec3f32 = ti.types.vector(3, ti.f32)
 vec3f64 = ti.types.vector(3, ti.f64)
 
 
 @ti.data_oriented
```

## mdapy/pair_distribution.py

```diff
@@ -1,21 +1,19 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import numpy as np
+import matplotlib.pyplot as plt
 
-try:
+if __name__ == "__main__":
     from rdf._rdf import _rdf, _rdf_single_species
-except Exception:
+    from plotset import pltset, cm2inch
+else:
     from _rdf import _rdf, _rdf_single_species
-try:
     from .plotset import pltset, cm2inch
-except Exception:
-    from plotset import pltset, cm2inch
-import matplotlib.pyplot as plt
 
 
 class PairDistribution:
     """This class is used to calculate the radiul distribution function (RDF),which
     reflects the probability of finding an atom at distance r. The seperate pair-wise
     combinations of particle types can also be computed:
```

## mdapy/polyhedral_template_matching.py

```diff
@@ -1,21 +1,18 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 # We highly thanks to Dr. Peter M Larsen for the help on parallelism of this module.
 
 import numpy as np
 
-try:
+if __name__ == "__main__":
     from ptm import _ptm
-except Exception:
-    import _ptm
-
-try:
     from kdtree import kdtree
-except Exception:
+else:
+    import _ptm
     from .kdtree import kdtree
 
 
 class PolyhedralTemplateMatching:
     """This class identifies the local structural environment of particles using the Polyhedral Template Matching (PTM) method, which shows greater reliability than e.g. `Common Neighbor Analysis (CNA) <https://mdapy.readthedocs.io/en/latest/mdapy.html#module-mdapy.common_neighbor_analysis>`_. It can identify the following structure:
 
     1. other = 0
```

## mdapy/potential.py

```diff
@@ -1,18 +1,18 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import numpy as np
 from scipy.interpolate import InterpolatedUnivariateSpline as spline
 import matplotlib.pyplot as plt
 
-try:
-    from .plotset import pltset, cm2inch
-except Exception:
+if __name__ == "__main__":
     from plotset import pltset, cm2inch
+else:
+    from .plotset import pltset, cm2inch
 
 
 class EAM:
     """This class is used to read/write a embedded-atom method (EAM) potentials.
     The energy of atom :math:`i` is given by:
 
     .. math:: E_i = F_\\alpha \\left(\\sum_{j \\neq i}\\rho_\\beta (r_{ij})\\right) + \\frac{1}{2} \\sum_{j \\neq i} \\phi_{\\alpha\\beta} (r_{ij}),
```

## mdapy/spatial_binning.py

```diff
@@ -1,18 +1,18 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 import matplotlib.pyplot as plt
 
-try:
-    from .plotset import pltset, cm2inch
-except Exception:
+if __name__ == "__main__":
     from plotset import pltset, cm2inch
+else:
+    from .plotset import pltset, cm2inch
 
 
 @ti.data_oriented
 class SpatialBinning:
     """This class is used to divide particles into different bins and operating on each bin.
     One-dimensional to Three-dimensional binning are supported.
 
@@ -111,18 +111,19 @@
             cindex = ti.floor((pos[i] - pos_min[0]) / self.wbin, dtype=ti.i32)
             if j == 0:
                 res[cindex, 0] += 1.0
             else:
                 res[cindex, j] += vbin[i, j - 1]
 
         for I in ti.grouped(res):
-            if I[I.n - 1] != 0:
+            if I[I.n - 1] != 0:  # do not divide number per bin
                 J = I
                 J[J.n - 1] = 0
-                res[I] /= res[J]
+                if res[J] > 0:
+                    res[I] /= res[J]
 
     @ti.kernel
     def _Binning_min(
         self,
         pos: ti.types.ndarray(),
         pos_min: ti.types.ndarray(),
         vbin: ti.types.ndarray(),
@@ -130,19 +131,21 @@
     ):
 
         # init res
         for i, j in ti.ndrange(self.N, (1, res.shape[-1])):
             cindex = ti.floor((pos[i] - pos_min[0]) / self.wbin, dtype=ti.i32)
             res[cindex, j] = vbin[i, j - 1]
         # get min
-        for i, j in ti.ndrange(self.N, (1, res.shape[-1])):
+        ti.loop_config(serialize=True)
+        for i in range(self.N):
             cindex = ti.floor((pos[i] - pos_min[0]) / self.wbin, dtype=ti.i32)
             res[cindex, 0] += 1.0
-            if vbin[i, j - 1] < res[cindex, j]:
-                res[cindex, j] = vbin[i, j - 1]
+            for j in range(1, res.shape[-1]):
+                if vbin[i, j - 1] < res[cindex, j]:
+                    res[cindex, j] = vbin[i, j - 1]
 
     @ti.kernel
     def _Binning_max(
         self,
         pos: ti.types.ndarray(),
         pos_min: ti.types.ndarray(),
         vbin: ti.types.ndarray(),
@@ -150,19 +153,21 @@
     ):
 
         # init res
         for i, j in ti.ndrange(self.N, (1, res.shape[-1])):
             cindex = ti.floor((pos[i] - pos_min[0]) / self.wbin, dtype=ti.i32)
             res[cindex, j] = vbin[i, j - 1]
         # get max
-        for i, j in ti.ndrange(self.N, (1, res.shape[-1])):
+        ti.loop_config(serialize=True)
+        for i in range(self.N):
             cindex = ti.floor((pos[i] - pos_min[0]) / self.wbin, dtype=ti.i32)
             res[cindex, 0] += 1.0
-            if vbin[i, j - 1] > res[cindex, j]:
-                res[cindex, j] = vbin[i, j - 1]
+            for j in range(1, res.shape[-1]):
+                if vbin[i, j - 1] > res[cindex, j]:
+                    res[cindex, j] = vbin[i, j - 1]
 
     def compute(self):
         """Do the real binning calculation."""
         xyz2dim = {
             "x": [0],
             "y": [1],
             "z": [2],
@@ -288,20 +293,22 @@
 if __name__ == "__main__":
     from lattice_maker import LatticeMaker
     from time import time
 
     ti.init(ti.cpu)
     FCC = LatticeMaker(4.05, "FCC", 100, 50, 50)
     FCC.compute()
+    pos = FCC.pos
+    pos = pos[(pos[:, 0] < 100) | (pos[:, 0] > 300)]
     start = time()
     binning = SpatialBinning(
-        FCC.pos,
-        "xz",
-        FCC.pos[:, 0],
-        operation="sum",
+        pos,
+        "x",
+        pos[:, 0] + pos[:, 1],
+        operation="max",
     )
     binning.compute()
     end = time()
     print(f"Binning time: {end-start} s.")
     print(binning.res[:, ..., 1].max())
     print(binning.coor["x"])
     # print(binning.coor)
```

## mdapy/steinhardt_bond_orientation.py

```diff
@@ -1,19 +1,19 @@
+# Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
+# This file is from the mdapy project, released under the BSD 3-Clause License.
+
 import numpy as np
 import taichi as ti
 
-try:
-    from .neighbor import Neighbor
-except Exception:
+if __name__ == "__main__":
     from neighbor import Neighbor
-
-try:
-    from .kdtree import kdtree
-except Exception:
     from kdtree import kdtree
+else:
+    from .neighbor import Neighbor
+    from .kdtree import kdtree
 
 nfac_table_numpy = np.array(
     [
         1,
         1,
         2,
         6,
```

## mdapy/system.py

```diff
@@ -1,97 +1,59 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 import pandas as pd
-from tqdm import tqdm
+import pyarrow as pa
+from pyarrow import csv
+
+if __name__ == "__main__":
 
-try:
-    from .ackland_jones_analysis import AcklandJonesAnalysis
-except Exception:
     from ackland_jones_analysis import AcklandJonesAnalysis
-try:
-    from .common_neighbor_analysis import CommonNeighborAnalysis
-except Exception:
     from common_neighbor_analysis import CommonNeighborAnalysis
-try:
-    from .common_neighbor_parameter import CommonNeighborParameter
-except Exception:
     from common_neighbor_parameter import CommonNeighborParameter
-try:
-    from .neighbor import Neighbor
-except Exception:
     from neighbor import Neighbor
-try:
-    from .temperature import AtomicTemperature
-except Exception:
     from temperature import AtomicTemperature
-try:
-    from .centro_symmetry_parameter import CentroSymmetryParameter
-except Exception:
     from centro_symmetry_parameter import CentroSymmetryParameter
-try:
-    from .entropy import AtomicEntropy
-except Exception:
     from entropy import AtomicEntropy
-try:
-    from .identify_SFs_TBs import IdentifySFTBinFCC
-except Exception:
     from identify_SFs_TBs import IdentifySFTBinFCC
-try:
-    from .pair_distribution import PairDistribution
-except Exception:
     from pair_distribution import PairDistribution
-try:
-    from .polyhedral_template_matching import PolyhedralTemplateMatching
-except Exception:
     from polyhedral_template_matching import PolyhedralTemplateMatching
-try:
-    from .cluser_analysis import ClusterAnalysis
-except Exception:
     from cluser_analysis import ClusterAnalysis
-try:
-    from .potential import EAM
-except Exception:
     from potential import EAM
-try:
-    from .calculator import Calculator
-except Exception:
     from calculator import Calculator
-try:
-    from .void_distribution import VoidDistribution
-except Exception:
     from void_distribution import VoidDistribution
-try:
-    from .warren_cowley_parameter import WarrenCowleyParameter
-except Exception:
     from warren_cowley_parameter import WarrenCowleyParameter
-try:
-    from .voronoi_analysis import VoronoiAnalysis
-except Exception:
     from voronoi_analysis import VoronoiAnalysis
-try:
-    from .mean_squared_displacement import MeanSquaredDisplacement
-except Exception:
     from mean_squared_displacement import MeanSquaredDisplacement
-try:
-    from .lindemann_parameter import LindemannParameter
-except Exception:
     from lindemann_parameter import LindemannParameter
-
-try:
-    from .spatial_binning import SpatialBinning
-except Exception:
     from spatial_binning import SpatialBinning
-
-try:
-    from .steinhardt_bond_orientation import SteinhardtBondOrientation
-except Exception:
     from steinhardt_bond_orientation import SteinhardtBondOrientation
+else:
+    from .common_neighbor_analysis import CommonNeighborAnalysis
+    from .ackland_jones_analysis import AcklandJonesAnalysis
+    from .common_neighbor_parameter import CommonNeighborParameter
+    from .neighbor import Neighbor
+    from .temperature import AtomicTemperature
+    from .centro_symmetry_parameter import CentroSymmetryParameter
+    from .entropy import AtomicEntropy
+    from .identify_SFs_TBs import IdentifySFTBinFCC
+    from .pair_distribution import PairDistribution
+    from .polyhedral_template_matching import PolyhedralTemplateMatching
+    from .cluser_analysis import ClusterAnalysis
+    from .potential import EAM
+    from .calculator import Calculator
+    from .void_distribution import VoidDistribution
+    from .warren_cowley_parameter import WarrenCowleyParameter
+    from .voronoi_analysis import VoronoiAnalysis
+    from .mean_squared_displacement import MeanSquaredDisplacement
+    from .lindemann_parameter import LindemannParameter
+    from .spatial_binning import SpatialBinning
+    from .steinhardt_bond_orientation import SteinhardtBondOrientation
 
 
 @ti.kernel
 def _wrap_pos(
     pos: ti.types.ndarray(), box: ti.types.ndarray(), boundary: ti.types.ndarray()
 ):
     """This function is used to wrap particle positions into box considering periodic boundarys.
@@ -449,28 +411,52 @@
         self.data[["id", "type"]] = self.data[["id", "type"]].astype(int)
         self.pos = self.data[["x", "y", "z"]].values
         if if_vel:
             self.vel = self.data[["vx", "vy", "vz"]].values
 
     def _read_dump(self):
         self.dump_head = []
+        if_space = False
         with open(self.filename) as op:
-            for _ in range(9):
-                self.dump_head.append(op.readline())
+            for i in range(10):
+                if i < 9:
+                    self.dump_head.append(op.readline())
+                else:
+                    if op.readline()[-2] == " ":
+                        if_space = True
         self.boundary = [1 if i == "pp" else 0 for i in self.dump_head[4].split()[-3:]]
         self.box = np.array([i.split()[:2] for i in self.dump_head[5:8]]).astype(float)
         self.col_names = self.dump_head[8].split()[2:]
-        self.data = pd.read_csv(
-            self.filename,
-            skiprows=9,
-            index_col=False,
-            header=None,
-            sep=" ",
-            names=self.col_names,
-        )
+        try:
+            if if_space:
+                data = pd.read_csv(
+                    self.filename,
+                    skiprows=9,
+                    sep=" ",
+                    names=self.col_names + ["drop"],
+                    engine="pyarrow",
+                )
+                del data["drop"]
+                self.data = data
+            else:
+                self.data = pd.read_csv(
+                    self.filename,
+                    skiprows=9,
+                    sep=" ",
+                    names=self.col_names,
+                    engine="pyarrow",
+                )
+        except Exception:
+            self.data = pd.read_csv(
+                self.filename,
+                skiprows=9,
+                index_col=False,
+                sep=" ",
+                names=self.col_names,
+            )
 
         if self.sorted_id:
             self.data.sort_values("id", inplace=True)
         self.pos = self.data[["x", "y", "z"]].values
         self.Ntype = len(np.unique(self.data["type"]))
         try:
             self.vel = self.data[["vx", "vy", "vz"]].values
@@ -495,34 +481,35 @@
             else:
                 output_name = self.filename[:-4] + "output.dump"
         col_name = "ITEM: ATOMS "
         for i in data.columns:
             col_name += i
             col_name += " "
         col_name += "\n"
-        with open(output_name, "w") as op:
+
+        table = pa.Table.from_pandas(data)
+        with pa.OSFile(output_name, "wb") as op:
             if self.dump_head is None:
-                op.write("ITEM: TIMESTEP\n0\n")
-                op.write("ITEM: NUMBER OF ATOMS\n")
-                op.write(f"{self.N}\n")
+                op.write("ITEM: TIMESTEP\n0\n".encode())
+                op.write("ITEM: NUMBER OF ATOMS\n".encode())
+                op.write(f"{self.N}\n".encode())
                 boundary = ["pp" if i == 1 else "ss" for i in self.boundary]
                 op.write(
-                    f"ITEM: BOX BOUNDS {boundary[0]} {boundary[1]} {boundary[2]}\n"
+                    f"ITEM: BOX BOUNDS {boundary[0]} {boundary[1]} {boundary[2]}\n".encode()
                 )
-                op.write(f"{self.box[0, 0]} {self.box[0, 1]}\n")
-                op.write(f"{self.box[1, 0]} {self.box[1, 1]}\n")
-                op.write(f"{self.box[2, 0]} {self.box[2, 1]}\n")
-                op.write("".join(col_name))
+                op.write(f"{self.box[0, 0]} {self.box[0, 1]}\n".encode())
+                op.write(f"{self.box[1, 0]} {self.box[1, 1]}\n".encode())
+                op.write(f"{self.box[2, 0]} {self.box[2, 1]}\n".encode())
+                op.write("".join(col_name).encode())
             else:
                 self.dump_head[3] = f"{data.shape[0]}\n"
-                op.write("".join(self.dump_head[:-1]))
-                op.write("".join(col_name))
-        data.to_csv(
-            output_name, header=None, index=False, sep=" ", mode="a", na_rep="nan"
-        )
+                op.write("".join(self.dump_head[:-1]).encode())
+                op.write("".join(col_name).encode())
+            write_options = csv.WriteOptions(delimiter=" ", include_header=False)
+            csv.write_csv(table, op, write_options=write_options)
 
     def write_data(self, output_name=None, data_format=None):
         """Write data to a DATA file.
 
         Args:
             output_name (str, optional): filename of generated DATA file.
             data_format (str, optional): selected in ['atomic', 'charge'].
@@ -1215,34 +1202,43 @@
             self.verlet_list, self.distance_list, self.neighbor_number, self.rc = (
                 Neigh.verlet_list,
                 Neigh.distance_list,
                 Neigh.neighbor_number,
                 rc,
             )
             self.if_neigh = True
-        elif self.rc != rc:
-            Neigh = Neighbor(self.pos, self.box, rc, self.boundary, max_neigh)
-            Neigh.compute()
-            CommonNeighborAnalysi = CommonNeighborAnalysis(
-                rc,
-                Neigh.verlet_list,
-                Neigh.neighbor_number,
-                self.pos,
-                self.box,
-                self.boundary,
-            )
-        else:
             CommonNeighborAnalysi = CommonNeighborAnalysis(
                 rc,
                 self.verlet_list,
                 self.neighbor_number,
                 self.pos,
                 self.box,
                 self.boundary,
             )
+        else:
+            if self.rc != rc:
+                Neigh = Neighbor(self.pos, self.box, rc, self.boundary, max_neigh)
+                Neigh.compute()
+                CommonNeighborAnalysi = CommonNeighborAnalysis(
+                    rc,
+                    Neigh.verlet_list,
+                    Neigh.neighbor_number,
+                    self.pos,
+                    self.box,
+                    self.boundary,
+                )
+            else:
+                CommonNeighborAnalysi = CommonNeighborAnalysis(
+                    rc,
+                    self.verlet_list,
+                    self.neighbor_number,
+                    self.pos,
+                    self.box,
+                    self.boundary,
+                )
         CommonNeighborAnalysi.compute()
         self.data["cna"] = CommonNeighborAnalysi.pattern
 
     def cal_common_neighbor_parameter(self, rc=3.0, max_neigh=30):
         """Use Common Neighbor Parameter (CNP) method to recgonize the lattice structure.
 
         .. note:: If one use this module in publication, one should also cite the original paper.
@@ -1489,20 +1485,27 @@
     """
 
     def __init__(self, filename_list, unwrap=True, sorted_id=True, image_p=None):
 
         self.sorted_id = sorted_id
         self.unwrap = unwrap
         self.image_p = image_p
+        try:
+            from tqdm import tqdm
 
-        progress_bar = tqdm(filename_list)
-        for filename in progress_bar:
-            progress_bar.set_description(f"Reading {filename}")
-            system = System(filename, sorted_id=self.sorted_id)
-            self.append(system)
+            progress_bar = tqdm(filename_list)
+            for filename in progress_bar:
+                progress_bar.set_description(f"Reading {filename}")
+                system = System(filename, sorted_id=self.sorted_id)
+                self.append(system)
+        except Exception:
+            for filename in filename_list:
+                print(f"Reading {filename}", end="")
+                system = System(filename, sorted_id=self.sorted_id)
+                self.append(system)
 
         self.pos_list = np.array([system.pos for system in self])
         if self.unwrap:
             if self.image_p is None:
                 try:
                     self.image_p = np.array(
                         [system.data[["ix", "iy", "iz"]].values for system in self]
@@ -1517,21 +1520,25 @@
 
     def write_dumps(self, output_col=None):
         """Write all data to a series of DUMP files.
 
         Args:
             output_col (list, optional): columns to be saved, such as ['id', 'type', 'x', 'y', 'z'].
         """
-        progress_bar = tqdm(self)
-        for system in progress_bar:
-            try:
+        try:
+            from tqdm import tqdm
+
+            progress_bar = tqdm(self)
+            for system in progress_bar:
                 progress_bar.set_description(f"Saving {system.filename}")
-            except Exception:
-                progress_bar.set_description(f"Saving file...")
-            system.write_dump(output_col=output_col)
+                system.write_dump(output_col=output_col)
+        except Exception:
+            for system in self:
+                print(f"Saving {system.filename}", end="")
+                system.write_dump(output_col=output_col)
 
     def cal_mean_squared_displacement(self, mode="windows"):
         """Calculate the mean squared displacement MSD of system, which can be used to
         reflect the particle diffusion trend and describe the melting process. Generally speaking, MSD is an
         average displacement over all windows of length :math:`m` over the course of the simulation (so-called
         'windows' mode here) and defined by:
 
@@ -1637,24 +1644,35 @@
     #     amass=[2.3, 4.5],
     #     vel=vel,
     #     boundary=[1, 1, 0],
     #     data_format="charge",
     #     q=q,
     # )
     # system.wrap_pos()
-    system.cal_steinhardt_bond_orientation(
-        rc=3.0,
-        qlist=[6],
-        nnn=12,
-        wlflag=False,
-        wlhatflag=False,
-        solidliquid=True,
-        max_neigh=30,
-        threshold=0.7,
-        n_bond=7,
-    )
-    print(system.data)
-    print(system.neighbor_number, system.rc)
+    # system.cal_steinhardt_bond_orientation(
+    #     rc=3.0,
+    #     qlist=[6],
+    #     nnn=12,
+    #     wlflag=False,
+    #     wlhatflag=False,
+    #     solidliquid=True,
+    #     max_neigh=30,
+    #     threshold=0.7,
+    #     n_bond=7,
+    # )
+    # from time import time
+
+    # start = time()
+    # system = System(
+    #     r"C:\Users\Administrator\Desktop\python\MY_PACKAGE\MyPackage\test\new_pandas\Metal-FCC-100-2260622.dump"
+    # )
+    # print(f"read time is {time()-start} s.")
+    print(system.data.head())
+    # start = time()
+    # system.write_dump(output_col=["id", "x", "y", "z"])
+    # print(f"write time is {time()-start} s.")
+    # print(system.neighbor_number, system.rc)
     print(system.Ntype, system.N, system.format)
+    # print(system.pos)
     # print(system.data_head)
     # system.write_data(data_format="charge")
     # system.write_dump()
```

## mdapy/void_distribution.py

```diff
@@ -1,21 +1,19 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 
-try:
-    from .neighbor import Neighbor
-except Exception:
+if __name__ == "__main__":
     from neighbor import Neighbor
-try:
-    from .cluser_analysis import ClusterAnalysis
-except Exception:
     from cluser_analysis import ClusterAnalysis
+else:
+    from .neighbor import Neighbor
+    from .cluser_analysis import ClusterAnalysis
 
 
 @ti.data_oriented
 class VoidDistribution:
     """This class is used to detect the void distribution in solid structure.
     First we divid particles into three-dimensional grid and check the its
     neighbors, if all neighbor grid is empty we treat this grid is void, otherwise it is
```

## mdapy/voronoi_analysis.py

```diff
@@ -1,15 +1,15 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import numpy as np
 
-try:
+if __name__ == "__main__":
     from voronoi import _voronoi_analysis
-except Exception:
+else:
     import _voronoi_analysis
 
 
 class VoronoiAnalysis:
     """This class is used to calculate the Voronoi polygon, wchich can be applied to
     estimate the atomic volume. The calculation is conducted by the `voro++ <https://math.lbl.gov/voro++/>`_ package and
     this class only provides a wrapper.
```

## mdapy/warren_cowley_parameter.py

```diff
@@ -1,18 +1,18 @@
 # Copyright (c) 2022, mushroomfire in Beijing Institute of Technology
 # This file is from the mdapy project, released under the BSD 3-Clause License.
 
 import taichi as ti
 import numpy as np
 import matplotlib.pyplot as plt
 
-try:
-    from .plotset import pltset, cm2inch
-except Exception:
+if __name__ == "__main__":
     from plotset import pltset, cm2inch
+else:
+    from .plotset import pltset, cm2inch
 
 
 @ti.data_oriented
 class WarrenCowleyParameter:
     """This class is used to calculate the Warren Cowley parameter (WCP), which is useful to
     analyze the short-range order (SRO) in the 1st-nearest neighbor shell in alloy system and is given by:
 
@@ -137,22 +137,22 @@
                 ax.text(j, i, name, ha="center", va="center", color="k")
 
         ax.set_xlabel("Central element")
         ax.set_ylabel("Neighboring element")
 
         baraxes = fig.add_axes([0.83, 0.165, 0.03, 0.67])
         bar = fig.colorbar(h, ax=ax, cax=baraxes)
-        bar.set_ticks([vmin, 0, vmax], fontsize=8)
+        bar.set_ticks(ticks=[vmin, 0, vmax])
         bar.set_label("WCP")
         plt.show()
         return fig, ax
 
 
 if __name__ == "__main__":
-    from system import System
+    from mdapy import System
     from neighbor import Neighbor
     from time import time
 
     # ti.init(ti.gpu, device_memory_GB=2.0)
     ti.init(ti.cpu, offline_cache=True)
 
     # file = open("./example/CoCuFeNiPd-4M.data").readlines()
```

## Comparing `mdapy-0.8.4.dist-info/LICENSE` & `mdapy-0.8.5.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mdapy-0.8.4.dist-info/METADATA` & `mdapy-0.8.5.dist-info/METADATA`

 * *Files 11% similar despite different names*

```diff
@@ -1,55 +1,54 @@
 Metadata-Version: 2.1
 Name: mdapy
-Version: 0.8.4
-Summary: A simple and fast python library to handle the data generated from molecular dynamics simulations
+Version: 0.8.5
+Summary: A simple, fast and cross-platform python library to handle the data generated from molecular dynamics simulations
 Home-page: https://github.com/mushroomfire/mdapy
 Author: mushroomfire aka HerrWu
 Author-email: yongchao_wu@bit.edu.cn
 License: BSD 3-Clause License
 Project-URL: Homepage, https://github.com/mushroomfire/mdapy
 Project-URL: Documentation, https://mdapy.readthedocs.io/
-Project-URL: Source Code, https://github.com/mushroomfire/mdapy
 Project-URL: Issue Tracker, https://github.com/mushroomfire/mdapy/issues
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Operating System :: Microsoft :: Windows
 Classifier: Operating System :: POSIX :: Linux
+Classifier: Operating System :: MacOS
 Requires-Python: >=3.7,<3.11
 License-File: LICENSE
 Requires-Dist: taichi (>=1.4.0)
 Requires-Dist: numpy
 Requires-Dist: scipy
 Requires-Dist: pandas
+Requires-Dist: pyarrow
 Requires-Dist: matplotlib
-Requires-Dist: tqdm
 
 .. image:: https://img.pterclub.com/images/2023/01/06/logo.png
 
 *mdapy* : Molecular Dynamics Analysis with Python
 =====================================================
 
 Overview
 --------
 
-The **mdapy** is a python library developed by **Yong-Chao Wu & Jian-Li Shao Group in 
-Beijing Institute of Technology**, providing a set of simple, 
-flexible and powerful tools to analyze the atomic trajectories 
-generated from Molecular Dynamics (MD) simulations. 
-Benefit by the `TaiChi <https://github.com/taichi-dev/taichi>`_ project, 
-we can effectively accelerate the pure python code close to those written 
-in C++. Moreover, **mdapy** is highly parallelized to make full use of 
-resources of both multicore CPU and GPU. **mdapy** can directly handle the DUMP 
-and DATA format in `LAMMPS <https://www.lammps.org/>`_. All data in **mdapy** is 
-stored in NDARRAY format in `NumPy <https://numpy.org/>`_\ , enabling integration 
-with the scientific ecosystem in python and corporation with other post-progressing 
-codes, such as `OVITO <https://www.ovito.org/>`_ and `freud <https://github.com/glotzerlab/freud>`_.
+The **mdapy** python library is developed by the **Yong-Chao Wu & Jian-Li Shao Group at the 
+Beijing Institute of Technology**, which provides an array of powerful, flexible, and straightforward 
+tools to analyze atomic trajectories generated from Molecular Dynamics (MD) simulations. The library is fully 
+cross-platform, making it accessible to users in **Windows, Linux, and Mac OS**. 
+Benefited by the `TaiChi <https://github.com/taichi-dev/taichi>`_ project, 
+we can effectively accelerate the pure python code, bringing it closer to the speed of code written in C++. 
+Furthermore, **mdapy** is highly parallelized, allowing users to leverage the resources of both multicore CPU and GPU. 
+**mdapy** can directly handle the DUMP and DATA formats in `LAMMPS <https://www.lammps.org/>`_. 
+Besides, all data in **mdapy** is stored in NDARRAY format in `NumPy <https://numpy.org/>`_\ , which enables easy integration 
+with the scientific ecosystem in python and facilitates collaboration with other post-progressing 
+tools such as `OVITO <https://www.ovito.org/>`_ and `freud <https://github.com/glotzerlab/freud>`_.
 
 
 Resources
 ----------
 
 - Homepage: `https://github.com/mushroomfire/mdapy <https://github.com/mushroomfire/mdapy>`_
 - Documentation: `https://mdapy.readthedocs.io/ <https://mdapy.readthedocs.io/>`_
@@ -59,21 +58,22 @@
 ------------
 
 * `python <https://www.python.org/>`_ (3.7-3.10)
 * `taichi>=1.4.0 <https://github.com/taichi-dev/taichi>`_
 * `numpy <https://numpy.org/>`_
 * `scipy <https://scipy.org/>`_
 * `pandas <https://pandas.pydata.org/>`_
-* `tqdm <https://github.com/tqdm/tqdm>`_
+* `pyarrow <https://arrow.apache.org/docs/python/index.html>`_
 * `matplotlib <https://matplotlib.org/>`_
 
 Optional Dependencies
 ----------------------
 
 * `SciencePlots <https://github.com/garrettj403/SciencePlots>`_ (Optional, for plotting results)
+* `tqdm <https://github.com/tqdm/tqdm>`_ (Optional, for progress bar when reading/saving multi DUMP files)
 * `pyfftw <https://github.com/pyFFTW/pyFFTW>`_ (Optional, for fast FFT)
 * `pyfnntw>=0.4.1 <https://github.com/cavemanloverboy/FNNTW>`_ (Optional, for fast KNN search)
 
 
 Installation
 -------------
 
@@ -83,28 +83,30 @@
 .. code-block:: bash
 
    pip install mdapy
 
 Install from source code.
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 
-- You should install pybind11 and have a C++ compilation environment. Tested by MSVC in Windows and GCC in Ubuntu.
+- You should install pybind11 and have a C++ compilation environment (-std=c++11 or newer) and openmp supports. 
+  Tested by MSVC in Windows 10, GCC in Ubuntu, Clang in MAC OS M1.
 
    .. code-block:: bash
       
       pip install pybind11
 
-- Download source code
+- Download the source code and installation.
    
    .. code-block:: bash
 
       git clone https://github.com/mushroomfire/mdapy.git
       cd mdapy 
       pip install .
 
+
 Usage
 ------
 
 .. code-block:: python
 
    import mdapy as mp
    mp.init('cpu') # use cpu, mp.init('gpu') will use gpu to compute.
@@ -189,14 +191,23 @@
 
 .. code-block:: bash
 
    conda install -c conda-forge gxx_linux-64
 
 Release Notes
 --------------
+V0.8.5 (4/9/2023)
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+- Compile it on MAC OS with M1. Now **mdapy** is fully cross-platform.
+- Obviously improve the performance of **reading/writing DUMP with pyarrow**.
+- Add **pyarrow** as a dependency package.
+- Fix bug of **create_polycrystalline** module. One can give box with any number, the old version only works for positive float.
+- Fix bug of **spatial_binning** module for empty region.
+- Let **tqdm** as an Optional dependency. 
 
 V0.8.4 (3/30/2023)
 ^^^^^^^^^^^^^^^^^^^
 
 - Optimize **Pair Distribution** module.
 - Optimize **Neighbor** module.
 - Update many **Benchmark** cases.
```

## Comparing `mdapy-0.8.4.dist-info/RECORD` & `mdapy-0.8.5.dist-info/RECORD`

 * *Files 24% similar despite different names*

```diff
@@ -1,40 +1,40 @@
-_cluster_analysis.cp39-win_amd64.pyd,sha256=nAvQa8rOV2_uBGkf1_q-eyp_F3QacGREVmz5TXOq8kA,124416
-_neigh.cp39-win_amd64.pyd,sha256=fBT-RupYGyNrulOUqS0vLzIVSZV9yoW9PfvHHqVVB8Q,123392
-_poly.cp39-win_amd64.pyd,sha256=dNZRO0Tl5lxx9ttwsIWFBZCKIvCaZpoucDHBCmyxBeQ,208896
-_ptm.cp39-win_amd64.pyd,sha256=-gEYwtPsZodLgq-ylB5yXx-7icmqkGKbdeBHWfdF7m0,331776
-_rdf.cp39-win_amd64.pyd,sha256=AK1YW-ckFHHfaXSxE-LrF7M6CjKXbFZJBQFBDQtNUN8,126976
-_voronoi_analysis.cp39-win_amd64.pyd,sha256=dllAbM7i6ZttPfZUy0WhKq6jiqMG8WfSN428fIbSQTM,193536
-mdapy/__init__.py,sha256=QS7m7LJQwp1nNFLzGo4iqhugmXnRCz1qBWr4qBry7iI,3552
-mdapy/ackland_jones_analysis.py,sha256=XmMWIDnpQ1qcd9ov9LUjfkBVilBDPu7X0RSUj6NHnW4,7826
+_cluster_analysis.cp39-win_amd64.pyd,sha256=uiqMYQTSphCMmNQ9hl7cnGpoHdhxBRxChHG05WzXWhg,121856
+_neigh.cp39-win_amd64.pyd,sha256=4yn2zfno4CxQshmoRSjwo4jNJujigQ2DGZXj4FFjtm8,120832
+_poly.cp39-win_amd64.pyd,sha256=x9UMPFu6uDKl-oxWyb5e3BgeFYKxUwR8XU5T0_6TXT4,205824
+_ptm.cp39-win_amd64.pyd,sha256=daNBNzJgKETkCBWFTn6maSfdNVWKZy8XFTidsC6pY9s,329728
+_rdf.cp39-win_amd64.pyd,sha256=CWVCwcJds-7ueMQMAOilmFoVpIpu4Rscr92a1PSrdAs,124928
+_voronoi_analysis.cp39-win_amd64.pyd,sha256=QidUtUk-CVUgAMvejf1Nm54v0qd22zrwzgP2OR3Nqb8,191488
+mdapy/__init__.py,sha256=enZOlLxPO6i1B6MBWYSAwvBPisNf28F1mAeArXBxghw,3552
+mdapy/ackland_jones_analysis.py,sha256=BYqqB7r--tUzEI0FJ1zpyimu4Ol_zffj8-e5MRN3zP4,7836
 mdapy/calculator.py,sha256=X-sr0TXd4qWbnZAuIm_cvJxaRRzjL99cTmipgcLdTbk,10839
-mdapy/centro_symmetry_parameter.py,sha256=hXrEVezYRqTwCCo61Zkg1SG2X5zo57XZkxj9oHlV2KI,7370
-mdapy/cluser_analysis.py,sha256=lY73_4Bg9gA_KqyqBFZS1nSkwdObMf0E99arvTm9sIU,4422
-mdapy/common_neighbor_analysis.py,sha256=uzmOFI9rStI5birsHPBOuD5M1-teXRDODi3sHR9BJMM,9766
+mdapy/centro_symmetry_parameter.py,sha256=XFZgSCiLx6zRniAhSLlY_acf7jeq-rRsgIIOse0rdIA,7380
+mdapy/cluser_analysis.py,sha256=82suIL4Zb_7yFZFjCxSmoFwIPmZesqeJTUFcp1Wsdns,4432
+mdapy/common_neighbor_analysis.py,sha256=cdWmWN59N-OIAkv7Jl27cQQ7p7eI82gbSa1RpQ--rGQ,10198
 mdapy/common_neighbor_parameter.py,sha256=WOyNKfXCpiCT5xXO3LF1eoE_5ZXg-OonW1eXlGfNZUE,6576
-mdapy/create_polycrystalline.py,sha256=hqwDtm3J-6uVkd3f58-hzYR52vCZc-rODycGN4L-lU8,25858
-mdapy/eam_average.py,sha256=Sb55t8vwrbZJNgx4RwrpKJ0XAKkAAWa2XM08FlxTRZQ,5518
+mdapy/create_polycrystalline.py,sha256=L4qZx9Go6CGluYZCezJ-gbnXribNtJv2P_G7C0ZS7nU,26758
+mdapy/eam_average.py,sha256=lbAFzKlrVeirRTC6gNkWbQhpSi7BzmnJywNg2DxoySw,5528
 mdapy/eam_generate.py,sha256=IcX7JzkvZ_sdPWfnebsJitAeVJtX5tberxo28opYc6g,21039
 mdapy/entropy.py,sha256=lgvAKBrEtw58dnDUaIrViFaT_i8X5CDPfLKhmzkzrtI,9960
-mdapy/identify_SFs_TBs.py,sha256=96rcJmilwCjNUGPv20RjignHdNc83sHrOKHX4Alj1U8,10861
+mdapy/identify_SFs_TBs.py,sha256=EoSp1vPDkmOe8V9VEzD7Mw6Wv0C8XrYdfyUC8Dhb4Ko,11015
 mdapy/kdtree.py,sha256=rmUHjneSk90kom9hU3OnjRlSkciYP30FdCciTMVg3Lc,6831
-mdapy/lattice_maker.py,sha256=Dw1N-RkfL2jL5vB9llLi7VoJU1gI2L9msbhwoMctja0,7576
-mdapy/lindemann_parameter.py,sha256=6amE6szNUzIUrXqa6Fyb0nHbLVbuJxGqlS2yn-9vcXw,8463
-mdapy/mean_squared_displacement.py,sha256=YhZhnyhz1R3VB8El7SujYpDvh4gntCu3sP0qhBNQIYQ,7130
-mdapy/neighbor.py,sha256=Lw5xjoAWne5AtjyHNQ-0op5LKcz9kGDCFwUbqxpwDUg,11359
-mdapy/pair_distribution.py,sha256=XjTUoZX2LeQRcIho3c3dLqPeFU2WrKusuFln1K5kUsg,9063
+mdapy/lattice_maker.py,sha256=8drw-nyU12FvAHmfQTZjK-A8FSvfeC-X6xRTDokj5LY,10077
+mdapy/lindemann_parameter.py,sha256=CeYKjoSwmEI469onbVVQIGgn9Y-XPemg97fGxk7aYWA,8475
+mdapy/mean_squared_displacement.py,sha256=_siQGQWSVVRb2RrFQmx-acM6V9kRc3WOWZKjNs8W7O8,7154
+mdapy/neighbor.py,sha256=mxKu-XFLq00Y8Lt3htbpxi_coSV_7QSmUgkOoH5mLTE,11369
+mdapy/pair_distribution.py,sha256=XCS9rgJnxXpuhY_RRqmxPzb4Yqt1_uXgVtjXlFT-wCs,9048
 mdapy/plotset.py,sha256=Np6sbBB8mtiJU_crowYn1eGgHJ0LYkEOyBn-ImR_0pE,3082
-mdapy/polyhedral_template_matching.py,sha256=bgvVIkN4lDjsDpu-EFgMJxlPfugQPcBAekyrEJ-8lRg,5244
-mdapy/potential.py,sha256=CY51yQw9fC2C6487Pl9qIY9HkPOl-CfguvRZc2mXPFg,11522
-mdapy/spatial_binning.py,sha256=sGP7OEbhrVRWmg26fLwMmMeGI9Cp-Qx8ZdCESIjAoi0,10467
-mdapy/steinhardt_bond_orientation.py,sha256=i5461T0PB3cAwgJ5AAljH8rYZHQ8u1KXAdCgU6BFag0,28700
-mdapy/system.py,sha256=dL1-1BZr3uHS5h_kwerO625Ob6DnzlhN81MVPBYwsa0,71920
+mdapy/polyhedral_template_matching.py,sha256=E59tevHmMwxeN7648hBIpKdAJsWDiMMy92TnDz6-60g,5227
+mdapy/potential.py,sha256=mM9vkO3TYrj4iub72QcsC3nwBcsBJe1gAVscmSmGceI,11532
+mdapy/spatial_binning.py,sha256=SolPl_NWCAB1yig02Qs4STc6e7OfSuYiGyB_8Yaz2cU,10755
+mdapy/steinhardt_bond_orientation.py,sha256=EpUpvcef614Iz_vuduCcY6IXM6TovWY6ofOTvZXhgBk,28837
+mdapy/system.py,sha256=04XNVbiSBTk-qQFl2QQm24GLSzc6Z_i2G9u6Zp__vr0,73683
 mdapy/temperature.py,sha256=vBpbR-5Sypop5bWeYMFrUOrHIvSTCQiXdBYdxsNGbOI,7962
 mdapy/timer.py,sha256=utfs-GkunB7UQbYckK5Eb2_rUjlttjnG2Gty8asQZz4,562
-mdapy/void_distribution.py,sha256=HYj30wJGBBUNSrM2MQbaWutqb7Uw93BfZ51gP0xgJuU,9186
-mdapy/voronoi_analysis.py,sha256=i6uXeRLCSBKD4M_Y7FP011t0smcNbszxUWlKoOeBowA,2955
-mdapy/warren_cowley_parameter.py,sha256=ammXQLWUgdBgO3JawiFRHwZ3M0ln_ob-oZoh_IO0BVc,6647
-mdapy-0.8.4.dist-info/LICENSE,sha256=kiAKfZIqcnirr_wG_POuIYajY3Mm6HhFLyDsb-0vMYY,1594
-mdapy-0.8.4.dist-info/METADATA,sha256=ltn8k85KhMlCapkoXy7KaPw1nhnzPc6VlirHRnvYtY0,9416
-mdapy-0.8.4.dist-info/WHEEL,sha256=eep6QWEFiQfg2wcclssb_WY-D33AnLYLnEKGA9Rn-VU,100
-mdapy-0.8.4.dist-info/top_level.txt,sha256=wvvPUrNU8-8jCaJDIS6SgHBXwgAxluLKNmpzEpQMNHs,65
-mdapy-0.8.4.dist-info/RECORD,,
+mdapy/void_distribution.py,sha256=siUzzSWifZPIKLCBErEgK8dJPkk5lFtjHcUmKgJgJGc,9171
+mdapy/voronoi_analysis.py,sha256=zHhSdw_RRbO4pE2FJZ-lig6IOxfOUYTH84Z0v1R5-Do,2965
+mdapy/warren_cowley_parameter.py,sha256=LYK6aJN6aw34ZoO5qML6AhV-ozUPpGre30FiM-Nm1L0,6650
+mdapy-0.8.5.dist-info/LICENSE,sha256=kiAKfZIqcnirr_wG_POuIYajY3Mm6HhFLyDsb-0vMYY,1594
+mdapy-0.8.5.dist-info/METADATA,sha256=GK3PajplQNG0dnNrSHruiPuj9Vzi7X1WcbA5-00KKEc,10304
+mdapy-0.8.5.dist-info/WHEEL,sha256=eep6QWEFiQfg2wcclssb_WY-D33AnLYLnEKGA9Rn-VU,100
+mdapy-0.8.5.dist-info/top_level.txt,sha256=wvvPUrNU8-8jCaJDIS6SgHBXwgAxluLKNmpzEpQMNHs,65
+mdapy-0.8.5.dist-info/RECORD,,
```

